<!DOCTYPE html>
<html lang="en-US">
<head>
  <meta http-equiv="Content-Type" content="text/html; charset=utf-8">
  <meta name="language" content="EN">
  <title>harvesting-my-gists-from-github</title>

  <link rel="stylesheet" type="text/css"  href="/css/site.css" media="screen">
  <link title="RSS feed for rsdoiel's blog" rel="alternate" type="application/rss+xml" href="https://rsdoiel.github.io/rss.xml">
  <meta name="keywords" content="GitHub, Gists, JSON">
  <link rel="alternative" type="application/markdown" href="/blog/2017/12/10/harvesting-my-gists-from-github.md">
  <link rel="search" type="application/opensearchdescription+xml"
        title="Robert's Rambling Search Engine"
        href="search.osdx">
</head>
<body>
<nav>
<ul>
<li><a href="/" title="R. S. Doiel"><img class="blog-logo" src="/media/Wee-Free-Doiels-Summer-Reading.svg" alt="Wee Free Doiels, Summer Reading"></a></li>
<li><a href="/about.html">About</a></li>
<li><a href="/blog/">Blog</a></li>
<li><a href="/presentations.html">Presentations</a></li>
<li><a href="/series/">Series</a></li>
<li><a href="/search.html">Search</a></li>
<li><a href="https://github.com/rsdoiel">GitHub</a></li>
<li><a href="/rss.xml" title="RSS Feed">
<svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
<path d="M4 11a9 9 0 0 1 9 9"></path>
<path d="M4 4a16 16 0 0 1 16 16"></path>
<circle cx="5" cy="19" r="1"></circle> </svg> RSS </a></li>
</ul>
</nav>

<section>
  <article>
<h1 id="harvesting-my-gists-from-github">Harvesting my Gists from
GitHub</h1>
<p>By R. S. Doiel 2017-12-10</p>
<p>This is a just quick set of notes on harvesting my Gists on GitHub so
I have an independent copy for my own website.</p>
<h2><a name="assumptions">Assumptions</a></h2>
<p>In this gist I assume you are using Bash on a POSIX system
(e.g. Raspbian on a Raspberry Pi) with the standard compliment of Unix
utilities (e.g. cut, sed, curl). I also use Stephen Dolan’s <a
href="https://github.com/stedolan/jq">jq</a> as well as Caltech
Library’s <a
href="https://github.com/caltechlibrary/datatools">datatools</a>. See
the respective GitHub repositories for installation instructions. The
gist harvest process was developed against GitHub’s v3 API (see
developer.github.com).</p>
<p>In the following examples “USER” is assumed to hold your GitHub user
id (e.g. rsdoiel for https://github.com/rsdoiel).</p>
<h2><a name="getting-my-basic-profile">Getting my basic profile</a></h2>
<p>This retrieves the public view of your profile.</p>
<pre class="shell"><code>    curl -o USER &quot;https://api.github.com/users/USER&quot;</code></pre>
<h2><a name="find-the-url-for-your-gists">Find the urL for your gists</a></h2>
<p>Get the gists url from `USER.json.</p>
<pre class="shell"><code>    GISTS_URL=$(jq &quot;.gists_url&quot; &quot;USER.json&quot; | sed -E &#39;s/&quot;//g&#39; | cut -d &#39;{&#39; -f 1)
    curl -o gists.json &quot;${GISTS_URL}&quot;</code></pre>
<p>Now <code>gists.json</code> should hold a JSON array of objects
representing your Gists.</p>
<h2><a name="harvesting-the-individual-gists">Harvesting the individual Gists.</a></h2>
<p>When you look at <em>gists.json</em> you’ll see a multi-level JSON
structure. It has been formatted by the API so be easy to scrape. But
since this data is JSON and Caltech Library has some nice utilities for
working with JSON I’ll use <em>jsonrange</em> and <em>jq</em> to pull
out a list of individual Gists URLS.</p>
<pre class="shell"><code>    jsonrange -i gists.json | while read I; do 
        jq &quot;.[$I].files&quot; gists.json | sed -E &#39;s/&quot;//g&#39;
    done</code></pre>
<p>Expanding this we can now curl each individual gist metadata to find
URL to the raw file.</p>
<pre class="shell"><code>    jsonrange -i gists.json | while read I; do 
        jq &quot;.[$I].files&quot; gists.json | jsonrange -i - | while read FNAME; do
            jq &quot;.[$I].files[\&quot;$FNAME\&quot;].raw_url&quot; gists.json | sed -E &#39;s/&quot;//g&#39;; 
        done;
    done</code></pre>
<p>Now that we have URLs to the raw gist files we can use curl again to
fetch each.</p>
<p>What do we want to store with our harvested gists? The raw files,
metadata about the Gist (e.g. when it was created), the Gist ID. Putting
it all together we have the following script.</p>
<pre class="shell"><code>    #!/bin/bash
    if [[ &quot;$1&quot; = &quot;&quot; ]]; then
        echo &quot;USAGE: $(basename &quot;$0&quot;) GITHUB_USERNAME&quot;
        exit 1
    fi

    USER=&quot;$1&quot;
    curl -o &quot;$USER.json&quot; &quot;https://api.github.com/users/$USER&quot;
    if [[ ! -s &quot;$USER.json&quot; ]]; then
        echo &quot;Someting went wrong getting https://api.github.cm/users/${USER}&quot;
        exit 1
    fi

    GISTS_URL=$(jq &quot;.gists_url&quot; &quot;$USER.json&quot; | sed -E &#39;s/&quot;//g&#39; | cut -d &#39;{&#39; -f 1)
    curl -o gists.json &quot;${GISTS_URL}&quot;
    if [[ ! -s gists.json ]]; then
        echo &quot;Someting went wrong getting ${GISTS_URL}&quot;
        exit 1
    fi

    # For each gist harvest our file
    jsonrange -i gists.json | while read I; do
        GIST_ID=$(jq &quot;.[$I].id&quot; gists.json | sed -E &#39;s/&quot;//g&#39;)
        mkdir -p &quot;gists/$GIST_ID&quot;
        echo &quot;Saving gists/$GIST_ID/metadata.json&quot;
        jq &quot;.[$I]&quot; gists.json &gt; &quot;gists/$GIST_ID/metadata.json&quot;
        jq &quot;.[$I].files&quot; gists.json | jsonrange -i - | while read FNAME; do
            URL=$(jq &quot;.[$I].files[\&quot;$FNAME\&quot;].raw_url&quot; gists.json | sed -E &#39;s/&quot;//g&#39;)
            echo &quot;Saving gist/$GIST_ID/$FNAME&quot;
            curl -o &quot;gists/$GIST_ID/$FNAME&quot; &quot;$URL&quot;
        done;
    done</code></pre>
  </article>
</section>

<footer>
<p>copyright © 2016 - 2025 R. S. Doiel<br /> <a
href="/rssfeed.html">RSS</a> feeds and website built with <a
href="https://rsdoiel.github.io/pttk">pttk</a>, Bash, Make and <a
href="https://pandoc.org">Pandoc</a>.</p>
</footer>
<script type="module" src="/modules/copyToClipboard.js"></script>
<script type="module">
    await import('/pagefind/pagefind-highlight.js');
    new PagefindHighlight({ highlightParam: "highlight" });
</script>
</body>
</html>
