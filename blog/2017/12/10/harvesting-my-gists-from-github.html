<!doctype html>
<html lang="en-US">
<head>
  <meta charset="utf-8" >
  <meta name="generator" content="antenna/0.0.19" >
  <meta name="date" content="2025-12-06T22:41:36-08:00" >
  <meta content="text/html; charset=utf-8" http-equiv="Content-Type" >
  <meta content="EN" name="language" >
  <title>R. S. Doiel, Software Engineer/Analyst &mdash; Robert's ramblings</title>
  <link rel="altenate" type="text/markdown" title="R. S. Doiel, Software Engineer/Analyst &mdash; Robert's ramblings" href="harvesting-my-gists-from-github.md" >
  <link rel="stylesheet" type="text/css" href="/css/site.css" >
  <link rel="alternate" title="Recent Blog Post" type="application/rss+xml" href="index.xml" >
  <link href="archive.xml" rel="alternate" title="Archive of Blog Posts" type="application/rss+xml" >
  <link rel="alternate" title="Markdown source for page" type="application/markdown" href="index.md" >
  <link type="application/opensearchdescription+xml" title="Robert's Rambling Search Engine" href="osd.xml" rel="search" >
  <script type="module" src="/modules/copyToClipboard.js" ></script>
</head>
<body>
  <nav>
    <ul>
    <li><a href="/" title="R. S. Doiel"><img class="blog-logo" src="/media/Wee-Free-Doiels-Summer-Reading.svg" alt="Wee Free Doiels, Summer Reading"></a></li>
    <li><a href="/">R. S. Doiel</a></li>
    <li><a href="/about.html">About</a></li>
    <li><a href="/blog/">Blog</a></li>
    <li><a href="/presentations.html">Presentations</a></li>
    <li><a href="/series/">Series</a></li>
    <li><a href="/search.html">Search</a></li>
    <li><a href="https://github.com/rsdoiel">GitHub</a></li>
    <li><a href="/rss.xml" title="RSS Feed">
    <svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
    <path d="M4 11a9 9 0 0 1 9 9"></path>
    <path d="M4 4a16 16 0 0 1 16 16"></path>
    <circle cx="5" cy="19" r="1"></circle> </svg> RSS </a></li>
    </ul>
  </nav>

  <section>
    <article data-published="2017-12-10" data-link="https://rsdoiel.github.io/blog/2017/12/10/harvesting-my-gists-from-github.html">
      <h1>Harvesting my Gists from GitHub</h1>
      <p>By R. S. Doiel 2017-12-10</p>
      <p>This is a just quick set of notes on harvesting my Gists on GitHub so I
      have an independent copy for my own website.</p>
      <h2>Assumptions</h2>
      <p>In this gist I assume you are using Bash on a POSIX system (e.g. Raspbian
      on a Raspberry Pi) with the standard compliment of Unix utilities (e.g. cut,
      sed, curl). I also use Stephen Dolan's <a href="https://github.com/stedolan/jq">jq</a>
      as well as Caltech Library's <a href="https://github.com/caltechlibrary/datatools">datatools</a>.
      See the respective GitHub repositories for installation instructions.
      The gist harvest process was developed against GitHub's v3 API
      (see developer.github.com).</p>
      <p>In the following examples &quot;USER&quot; is assumed to hold your GitHub user id
      (e.g. rsdoiel for <a href="https://github.com/rsdoiel)">https://github.com/rsdoiel)</a>.</p>
      <h2>Getting my basic profile</h2>
      <p>This retrieves the public view of your profile.</p>
      <pre><code class="language-shell">    curl -o USER &quot;https://api.github.com/users/USER&quot;
      </code></pre>
      <h2>Find the urL for your gists</h2>
      <p>Get the gists url from `USER.json.</p>
      <pre><code class="language-shell">    GISTS_URL=$(jq &quot;.gists_url&quot; &quot;USER.json&quot; | sed -E 's/&quot;//g' | cut -d '{' -f 1)
          curl -o gists.json &quot;${GISTS_URL}&quot;
      </code></pre>
      <p>Now <code>gists.json</code> should hold a JSON array of objects representing your Gists.</p>
      <h2>Harvesting the individual Gists.</h2>
      <p>When you look at <em>gists.json</em> you'll see a multi-level JSON structure.  It has been
      formatted by the API so be easy to scrape.  But since this data is JSON and Caltech Library
      has some nice utilities for working with JSON I'll use <em>jsonrange</em> and <em>jq</em> to pull out a list
      of individual Gists URLS.</p>
      <pre><code class="language-shell">    jsonrange -i gists.json | while read I; do 
              jq &quot;.[$I].files&quot; gists.json | sed -E 's/&quot;//g'
          done
      </code></pre>
      <p>Expanding this we can now curl each individual gist metadata to find URL to the raw file.</p>
      <pre><code class="language-shell">    jsonrange -i gists.json | while read I; do 
              jq &quot;.[$I].files&quot; gists.json | jsonrange -i - | while read FNAME; do
                  jq &quot;.[$I].files[\&quot;$FNAME\&quot;].raw_url&quot; gists.json | sed -E 's/&quot;//g'; 
              done;
          done
      </code></pre>
      <p>Now that we have URLs to the raw gist files we can use curl again to fetch each.</p>
      <p>What do we want to store with our harvested gists?  The raw files, metadata
      about the Gist (e.g. when it was created), the Gist ID. Putting it all together
      we have the following script.</p>
      <pre><code class="language-shell">    #!/bin/bash
          if [[ &quot;$1&quot; = &quot;&quot; ]]; then
              echo &quot;USAGE: $(basename &quot;$0&quot;) GITHUB_USERNAME&quot;
              exit 1
          fi
      
          USER=&quot;$1&quot;
          curl -o &quot;$USER.json&quot; &quot;https://api.github.com/users/$USER&quot;
          if [[ ! -s &quot;$USER.json&quot; ]]; then
              echo &quot;Someting went wrong getting https://api.github.cm/users/${USER}&quot;
              exit 1
          fi
      
          GISTS_URL=$(jq &quot;.gists_url&quot; &quot;$USER.json&quot; | sed -E 's/&quot;//g' | cut -d '{' -f 1)
          curl -o gists.json &quot;${GISTS_URL}&quot;
          if [[ ! -s gists.json ]]; then
              echo &quot;Someting went wrong getting ${GISTS_URL}&quot;
              exit 1
          fi
      
          # For each gist harvest our file
          jsonrange -i gists.json | while read I; do
              GIST_ID=$(jq &quot;.[$I].id&quot; gists.json | sed -E 's/&quot;//g')
              mkdir -p &quot;gists/$GIST_ID&quot;
              echo &quot;Saving gists/$GIST_ID/metadata.json&quot;
              jq &quot;.[$I]&quot; gists.json &gt; &quot;gists/$GIST_ID/metadata.json&quot;
              jq &quot;.[$I].files&quot; gists.json | jsonrange -i - | while read FNAME; do
                  URL=$(jq &quot;.[$I].files[\&quot;$FNAME\&quot;].raw_url&quot; gists.json | sed -E 's/&quot;//g')
                  echo &quot;Saving gist/$GIST_ID/$FNAME&quot;
                  curl -o &quot;gists/$GIST_ID/$FNAME&quot; &quot;$URL&quot;
              done;
          done
      </code></pre>
      
    </article>
  </section>
  <footer>
    <p>copyright Â© 2016 - 2025 R. S. Doiel<br /> <a
    href="/rssfeed.html">RSS</a> feeds and website built with <a
    href="https://rsdoiel.github.io/antennaApp">antennaApp</a>.
    <script type="module">
      await import('/pagefind/pagefind-highlight.js');
      new PagefindHighlight({ highlightParam: "highlight" });
    </script>
  </footer>
</body>
</html>
