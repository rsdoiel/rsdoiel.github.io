{
  "page": 5,
  "total_pages": 5,
  "has_more": false,
  "next_page": null,
  "values": [
    {
      "content": "\n\n# Words Matter\n\nBy R. S. Doiel, 2020-07-08\n\nUPDATE (2020-08-15, RSD): When I added a post today I was VERY pleased to \nto see that GitHub now allows me to publish my blog via the \"main\" branch.\nIt's nice to see the change in the words we use.\n\n**Why does software development use the vocabulary of slavery and\nJim Crow to describe our creations?** What we call things matters.\nThis is especially true of the words we use day to day without thinking.\n\n```shell\n    git pull origin master\n```\n\n\"Naming things is a hard problem in computer science.\" That is\na phrase I remember from my student days. We name variables,\nprograms and algorithms. We name architectures. Naming is a choice.\nThe names convey meaning and intent. Names and terms are a human\ncommunication. They matter.\n\n```shell\n    git push origin master\n```\n\n\n## Names can change\n\nI remember the first time I encountered the terminology \"master/slave\"\ndescribing network and database architecture. I remember cringing at\nthe terms. I accepted the terminology because I was a student and\nnaively assumed that those terms were chosen innocently and did not\nmean what they did. I was wrong.\n\nExample MySQL command:\n\n```sql\n    CHANGE MASTER TO MASTER_HOST=host1,\n    MASTER_PORT=3002 FOR CHANNEL 'channel2';\n```\n\nWhen I did not challenge the use of those terms in computer science\nI became complicit in the status quo of systemic racism. I am not happy\nabout that. Not then and not now.  We need inclusive language\nin engineering. We need real diversity to find solutions to\ntoday's challenges.  In software engineering we very much control what\nwe call things. Software is an explicit form of written human\ncommunication. Words count. Words directly impact culture and our\ncommunity.\n\nExample MySQL commands:\n\n```sql\n    START SLAVE;\n    RESET SLAVE;\n    STOP SLAVE;\n```\n\nAs a direct benefactor of white male privilege I find the\nterminology of \"master/slave\" offensive.  I am certain those\nwords caused injury to those who did not benefit from the same white\nmale privilege.  Using \"master/slave\" terminology to describe database,\nreplication, network architectures or as used with version control\nsystems like Git is like polishing statues that glorify slavery.\nIt endorses inhumanity in a subtle and casual way.\n\nWe have a choice about how we communicate and what we communicate\nto convey meaning.  Let's use better words. It is time to change\nsome.\n\n\n## Practice Change\n\n**To change our community's vocabulary we need to thoughtfully choose terms**.\nMy friends and colleagues introduced me to using the term \"main\" as\na better descriptive word than \"master\" in Git repositories. When\nI started making the branch name changes in my Git repositories I ran\nacross a problem at GitHub.\n\n\n## Note the problem\n\nRecently GitHub made it possible to easily change the default branch.\nFor a number of years you could change the published documentation\nbranch from \"gh-pages\" to something you prefer.\nWhat you can't do is change the name of the branch used to publish\npersonal and group websites.  **GitHub explicitly states that the\npublication branch must be named \"master\".** I tested this and\nconfirmed the documentation is accurate as of today (2020-07-08, morning).\n\nWith the recent improvements in GitHub to allow default branches to\nbe named better it seems odd that you still have to publish\npersonal and group pages to \"master\" in order to publish a website. It\nnever made sense to me that person and group pages didn't use the default\nof \"gh-pages\" in the first place.\n\n\n## Taking action\n\nMorning (2020-07-08): I submitted a ticket to GitHub asking to have\nthe option of using another word besides \"master\" for the publication\nbranch in publishing my personal GitHub pages (i.e. this blog).\nUnfortunately the ticket doesn't have a public URL. I don't know how many\nother people have submitted similar requests. If only a few people\nhave requested this recently it will not be changed. Such is the nature\nof systemic problems.\n\nPlease help improve the words and names we use in software.\nI believe it can make a difference in creating a more inclusive and\nequitable community and profession. Raise the issue when it comes to\nyour attention. Silence becomes acceptance with systemic problems.\n\n## A reply\n\nEvening (2020-07-08): I got a reply today from Steve G of customer\nsupport. Not sure if the reply is a bot or human.  It was a nice polite\nreply (I wrote a nice polite ticket).  Steve mentioned that CEO Nat\nFriedman had addressed this on twitter and to follow the GitHub blog\nnews.  Steve said dropping master was a priority for GitHub but there\nis no time line for implementation.\n\nI am not sure how you can develop software with a priority in mind and\nnot have a sense of time it takes to implement it.  I mentioned that in my\nresponse to Steve G.\n\nAfter some Duck Duck searching I found a [BBC article](https://www.bbc.com/news/technology-53050955) dated June 15th, 2020 where Nat made the\nannouncement about Microsoft's GitHub making the change away from \"master\".\nNext week is July 15th. It will be interesting to see how much of an unscheduled priority this change is.\n\nI am skeptical.  If Steve G had indicated that they are actively working\nthe problem and provided a general time range I would be more inclined to\ngive Nat, GitHub and Microsoft the benefit of the doubt.  Given the rest\nof the content I read on Nat's twitter feed I don't think this is a priority\nbeyond press, publicity and stock price.\n\n\n## Where to go from here?\n\nJust as many sites have adopted more gender neutral terms in documentation\npractice we should encourage better descriptive terms for our algorithms,\nand architectures. If you run into terms perpetuating exclusion please\nspeak up.  Most of the web runs on web servers and databases.  Like GitHub\nthose software projects frequently use the terminology of \"master/slave\".\nIt is especially prevalent in documentation about replication. Blindly\nperpetuating the \"master/slave\" terminology to describe distributed\nsoftware and architectures is like polishing a statue to the old\nConfederacy. It can and should be change. We can communicate better\nwithout perpetuating the vocabulary of Jim Crow, segregation, slavery\nand oppression.\n\n",
      "data": {
        "author": "rsdoiel@gmail.com (R. S. Doiel)",
        "copyright": "copyright (c) 2020, R. S. Doiel",
        "date": "2020-07-08",
        "keywords": [
          "civil rights",
          "diversity",
          "equality"
        ],
        "license": "https://creativecommons.org/licenses/by-sa/4.0/",
        "title": "Words Matter"
      },
      "url": "posts/2020/07/08/words-matter.json"
    },
    {
      "content": "\n\n# Software Tools, Getting Started\n\n## Overview\n\nThis post is the first in a series revisiting the\nprograms described in the 1981 book by Brian W. Kernighan and\nP. J. Plauger's called [Software Tools in Pascal](https://archive.org/details/softwaretoolsinp00kern).\nThe book is available from the [Open Library](https://openlibrary.org/)\nand physical copies are still (2020) commonly available from used book\nsellers.  The book was an early text on creating portable command\nline programs.  \n\nIn this series I present the K & P (i.e. Software Tools in Pascal)\nprograms re-implemented in Oberon-07. I have testing my implementations\nusing Karl Landström's [OBNC](http://miasap.se/obnc/)\ncompiler and his implementation of the Oakwood Guide's modules\nfor portable Oberon programs. Karl also provides a few additional\nmodules for working in a POSIX environment (e.g. BSD, macOS, Linux,\nWindows 10 with Linux subsystem). I have also tested these\nprograms with Mike Spivey's [Oxford Oberon Compiler](http://spivey.oriel.ox.ac.uk/corner/Oxford_Oberon-2_compiler) an aside\nfrom the differences file extensions that both compilers use\nthe source code works the same. \n\nNOTE: OBNC compiler is the work of Karl Langström, it is portable across many systems where the C tool chain is available.\n\nNOTE: POSIX defines a standard of compatibility inspired by [UNIX](https://en.wikipedia.org/wiki/Unix), see <https://en.wikipedia.org/wiki/POSIX>\n\n\n## Getting Started.\n\nChapter one in K & P is the first chapter that presents code. It introduces\nsome challenges and constraints creating portable Pascal suitable for use\nacross hardware architectures and operating systems. In 1981 this included\nmainframes, minicomputers as well as the recent evolution of the microcomputer.\nThe programs presented build up from simple to increasingly complex as\nyou move through the book.  They provide example documentation and discuss\ntheir implementation choices. It is well worth reading the book for those\ndiscussions, while specific to the era, mirror the problems program authors\nface today in spite of the wide spread success of the POXIS model, the\nconsolidation of CPU types and improvements made in development tools in\nthe intervening decades.\n\nThrough out K & P you'll see the bones of many POSIX commands we have today.\n\nPrograms from this chapter include:\n\n1. **copyprog**, this is like \"cat\" in a POSIX system\n2. **charcount**, this is like the \"wc\" POSIX command using the \"-c\" option\n3. **linecount**, this is like the \"wc\" POSIX command using the \"-l\" option\n4. **wordcount**, this is like the \"wc\" POSIX command using the \"-w\" option\n5. **detab**, converts tabs to spaces using tab stops every four characters in a line\n\nAll programs in this chapter rely solely on standard input and output.\nToday's reader will notice an absence to common concepts in today's\ncommand line programs.  First is the lack of interaction with command line\nparameters, the second is no example take advantage of environment variables.\nThese operating system features were not always available across\noperating systems of the early 1980s. Finally I'd like to point out a\nreally nice feature included in the book. It is often left out as a topic\nin programming books.  K & P provide example documentation. It's structure\nlike an early UNIX man page. It very clear and short. This is something\nI wish all programming texts at least mentioned. Documentation is important\nto the program author because it clarifies scope of the problem being\ntackled and to the program user so they understand what they are using.\n\n\n### [1.1. File Copying](https://archive.org/details/softwaretoolsinp00kern/page/7/mode/1up)\n\nHere's how K & P describe \"copyprog.pas\" (referred to as \"copy\" in\nthe documentation).\n\n\n~~~\n\nPROGRAM\n\n    copy    copy input to output\n\nUSAGE\n\n    copy\n\nFUNCTION\n\n    copy copies its input to its output unchanged. It is useful for copying\n    from a terminal to a file, from file to file, or even from terminal to\n    terminal. It may be used for displaying the contents of a file, without\n    interpretation or formatting, by copying from the file to terminal.\n\nEXAMPLE\n\n    To echo lines type at your terminal.\n\n    copy\n    hello there, are you listening?\n    **hello there, are you listening?**\n    yes, I am.\n    **yes, I am.**\n    <ENDFILE>\n\n~~~\n\nThe source code for \"copyprog.pas\" is shown on\n[page 9](https://archive.org/details/softwaretoolsinp00kern/page/9/mode/1up)\nof K & P.  First the authors introduce the __copy__ procedure\nthen a complete the section introducing it in context of the complete Pascal\nprogram. After this first example K & P leave implementation of the full\nprogram up to the reader.\n\nThe body of the Pascal program invokes a procedure called\n[copy](https://archive.org/details/softwaretoolsinp00kern/page/8/mode/1up)\nwhich reads from standard input character by character and writes\nto standard output character by character without modification.  Two\nsupporting procedures are introduced, \"getc\" and \"putc\". These are shown\nin the complete program listing on page 9. They are repeatedly used\nthrough out the book. One of the really good aspects of this simple\nprogram is relying on the idea of standard input and output. This makes\n\"copyprog.pas\" a simple filter and template for writing many of the programs\nthat follow. K & P provide a good explanation for this simple approach.\nAlso note K & P's rational for working character by character versus\nline by line.\n\nMy Oberon-07 version takes a similar approach. The module looks remarkably\nsimilar to the Pascal but is shorter because reading and writing characters are\nprovided for by Oberon's standard modules \"In\" and \"Out\".\nI have chosen to use a \"REPEAT/UNTIL\" loop over the \"WHILE\"\nloop used by K & P is the attempt to read from standard input needs to happen\nat least once. Note in my \"REPEAT/UNTIL\" loop's terminating condition.\nThe value of `In.Done` is true on successful read and false\notherwise (e.g. you hit an end of the file). That means our loop must\nterminate on `In.Done # TRUE` rather than `In.Done = TRUE`. This appears\ncounter intuitive unless you keep in mind our loop stops when we having\nnothing more to read, rather than when we can continue to read.\nIt `In.Done` means the read was successful and does not\nmean \"I'm done and can exit now\". Likewise before writing out the character\nwe read, it is good practice to check the `In.Done` value. If `In.Done` is\nTRUE, I know can safely display the character using `Out.Char(c);`.\n\n~~~\n\nMODULE CopyProg;\nIMPORT In, Out;\n\nPROCEDURE copy;\nVAR\n  c : CHAR;\nBEGIN\n  REPEAT\n    In.Char(c);\n    IF In.Done THEN\n        Out.Char(c);\n    END;\n  UNTIL In.Done # TRUE;\nEND copy;\n\nBEGIN\n  copy();\nEND CopyProg.\n\n~~~\n\n#### Limitations\n\nThis program only works with standard input and output. A more generalized\nversion would work with named files.\n\n### [1.2 Counting Characters](https://archive.org/details/softwaretoolsinp00kern/page/13/mode/1up)\n\n~~~\n\nPROGRAM\n\n  charcount count characters in input\n\nUSAGE\n\n  charcount\n\nFUNCTION\n\n  charcount counts the characters in its input and writes the total\n  as a single line of text to the output. Since each line of text is\n  internally delimited by a NEWLINE character, the total count is the\n  number of lines plus the number of characters within each line.\n\nEXAMPLE\n\n  charcount\n  A single line of input.\n  <ENDFILE>\n  24\n\n~~~\n\n[On page 13](https://archive.org/details/softwaretoolsinp00kern/page/13/mode/1up)\nK & P introduces their second program, **charcount**. It is based on a single\nprocedure that reads from standard input and counts up the number of\ncharacters encountered then writes the total number found to standard out\nfollowed by a newline. In the text only the procedure is shown, it is\nassumed you'll write the outer wrapper of the program yourself as\nwas done with the **copyprog** program. My Oberon-07 version is very similar\nto the Pascal. Like in the our first \"CopyProg\" we will make use of the\n\"In\" and \"Out\" modules. Since we will\nneed to write an INTEGER value we'll also use \"Out.Int()\" procedure which\nis very similar to K & P's \"putdec()\". Aside from the counting this is very\nsimple  like our first program.\n\n~~~\n\nMODULE CharCount;\nIMPORT In, Out;\n\nPROCEDURE CharCount;\nVAR\n  nc : INTEGER;\n  c : CHAR;\nBEGIN\n  nc := 0;\n\n  REPEAT\n    In.Char(c);\n    IF In.Done THEN\n      nc := nc + 1;\n    END;\n  UNTIL In.Done # TRUE;\n  Out.Int(nc, 1);\n  Out.Ln();\nEND CharCount;\n\nBEGIN\n  CharCount();\nEND CharCount.\n\n~~~\n\n#### Limitations\n\nThe primary limitation in counting characters is most readers are\ninterested in visible character count. In our implementation\neven non-printed characters are counted. Like our first program\nthis only works on standard input and output. Ideally this should\nbe written so it works on any file including standard input and\noutput. If the reader implements that it could become part of a\npackage on statistical analysis of plain text files.\n\n### [1.3 Counting Lines](https://archive.org/details/softwaretoolsinp00kern/page/14/mode/1up)\n\n~~~\n\nPROGRAM\n\n  linecount count lines in input\n\nUSAGE\n\n  linecount\n\nFUNCTION\n\n  linecount counts the lines in its input and write the total as a\n  line of text to the output.\n\nEXAMPLE\n\n  linecount\n  A single line of input.\n  <ENDFILE>\n  1\n\n~~~\n\n**linecount**, from [page 15](https://archive.org/details/softwaretoolsinp00kern/page/15/mode/1up)\nis very similar to **charcount** except adding a\nconditional count in the loop for processing the file. In\nour Oberon-07 implementation we'll check if the `In.Char(c)`\ncall was successful but we'll add a second condition to see if the\ncharacter read was a NEWLINE. If it was I increment\nour counter variable.\n\n~~~\n\nMODULE LineCount;\nIMPORT In, Out;\n\nPROCEDURE LineCount;\nCONST\n  NEWLINE = 10;\n\nVAR\n  nl : INTEGER;\n  c : CHAR;\nBEGIN\n  nl := 0;\n  REPEAT\n    In.Char(c);\n    IF In.Done & (ORD(c) = NEWLINE) THEN\n      nl := nl + 1;\n    END;\n  UNTIL In.Done # TRUE;\n  Out.Int(nl, 1);\n  Out.Ln();\nEND LineCount;\n\nBEGIN\n  LineCount();\nEND LineCount.\n\n~~~\n\n#### Limitations\n\nThis program assumes that NEWLINE is ASCII value 10. Line delimiters\nvary between operating systems.  If your OS used carriage returns\nwithout a NEWLINE then this program would not count lines correctly.\nThe reader could extend the checking to support carriage returns,\nnew lines, and carriage return with new lines and cover most versions\nof line endings.\n\n\n### [1.4 Counting Words](https://archive.org/details/softwaretoolsinp00kern/page/14/mode/1up)\n\n~~~\n\nPROGRAM\n\n  wordcount count words in input\n\nUSAGE\n\n  wordcount\n\nFUNCTION\n\n  wordcount counts the words in its input and write the total as a\n  line of text to the output. A \"word\" is a maximal sequence of characters\n  not containing a blank or tab or newline.\n\nEXAMPLE\n\n  wordcount\n  A single line of input.\n  <ENDFILE>\n  5\n\nBUGS\n\n  The definition of \"word\" is simplistic.\n\n~~~\n\n[Page 17](https://archive.org/details/softwaretoolsinp00kern/page/17/mode/1up)\nbrings us to the **wordcount** program. Counting words can be\nvery nuanced but here K & P have chosen a simple definition\nwhich most of the time is \"good enough\" for languages like English.\nA word is defined simply as an run of characters separated by\na space, tab or newline characters.  In practice most documents\nwill work with this minimal definition. It also makes the code\nstraight forward.  This is a good example of taking the simple\nroad if you can. It keeps this program short and sweet.\n\nIf you follow along in the K & P book note their rational\nand choices in arriving at there solutions. There solutions\nwill often balance readability and clarity over machine efficiency.\nWhile the code has progressed from \"if then\" to \"if then else if\"\nlogical sequence, the solution's modeled remains\nclear. This means the person reading the source code can easily verify\nif the approach chosen was too simple to meet their needs or it was\n\"good enough\".\n\nMy Oberon-07 implementation is again very simple. Like in previous programs\nI still have an outer check to see if the read worked (i.e. \"In.Done = TRUE\"),\notherwise the conditional logic is the same as the Pascal implementation.\n\n~~~\n\nMODULE WordCount;\nIMPORT In, Out;\n\nPROCEDURE WordCount;\nCONST\n  NEWLINE = 10;\n  BLANK = 32;\n  TAB = 9;\n\nVAR\n  nw : INTEGER;\n  c : CHAR;\n  inword : BOOLEAN;\nBEGIN\n  nw := 0;\n  inword := FALSE;\n  REPEAT\n    In.Char(c);\n    IF In.Done THEN\n      IF ((ORD(c) = BLANK) OR (ORD(c) = NEWLINE) OR (ORD(c) = TAB)) THEN\n        inword := FALSE;\n      ELSIF (inword = FALSE) THEN\n        inword := TRUE;\n        nw := nw + 1;\n      END;\n    END;\n  UNTIL In.Done # TRUE;\n  Out.Int(nw, 1);\n  Out.Ln();\nEND WordCount;\n\nBEGIN\n  WordCount();\nEND WordCount.\n\n~~~\n\n## [1.5 Removing Tabs](https://archive.org/details/softwaretoolsinp00kern/page/20/mode/1up)\n\n~~~\n\nPROGRAM\n\n  detab convert tabs into blanks\n\nUSAGE\n\n  detab\n\nFUNCTION\n\n  detab copies its input to its output, expanding the horizontal\n  tabs to blanks along the way, so that the output is visually\n  the same as the input, but contains no tab characters. Tab stops\n  are assumed to be set every four columns (i.e. 1, 5, 9, ...), so\n  each tab character is replaced by from one to four blanks.\n\nEXAMPLE\n\n  Usaing \"->\" as a visible tab:\n\n  detab\n  ->col 1->2->34->rest\n      col 1   2   34  rest\n\nBUGS\n\n  detab is naive about backspaces, vertical motions, and\n  non-printing characters.\n\n~~~\n\nThe source code for \"detab\" can be found on\n[page 24](https://archive.org/details/softwaretoolsinp00kern/page/24/mode/1up)\nin the last section of chapter 1. **detab** removes\ntabs and replaces them with spaces. Rather than a simple \"tab\"\nreplaced with four spaces **detab** preserves a concept found on\ntypewriters called \"tab stops\". In 1981 typewrites were still widely\nused though word processing software would become common. Supporting the\n\"tab stop\" model means the program works with what office workers would\nexpect from older tools like the typewriter or even the computer's\nteletype machine. I think this shows an important aspect of writing\nprograms. Write the program for people, support existing common concepts\nthey will likely know.\n\nK & P implementation includes separate source files\nfor setting tab stops and checking a tab stop.  The Pascal K & P\nwrote for didn't support separate source files or program modules. Recent Pascal\nversions did support the concept of modularization (e.g. UCSD Pascal). Since\nand significant goal of K & P was portability they needed to come up\nwith a solution that worked on the \"standard\" Pascal compilers available on\nminicomputers and mainframes and not write their solution to a specific\nPascal system like UCSD Pascal (see Appendix, \"IMPLEMENTATION\nPRIMITIVES [page 315](https://archive.org/stream/softwaretoolsinp00kern?ref=ol#page/315/mode/1up)).\nModularization facilitates code reuse and like information hiding is an\nimport software technique. Unfortunately the preprocessor approach doesn't\nsupport information hiding.\n\nTo facilitate code reuse the K & P book includes a preprocessor as part\nof the Pascal development tools (see [page 71](https://archive.org/stream/softwaretoolsinp00kern?ref=ol#page/71/mode/1up)\nfor implementation). The preprocessor written\nin Pascal was based on the early versions of the \"C\" preprocessor\nthey had available in the early UNIX systems. Not terribly Pascal\nlike but it worked and allowed the two files to be shared between\nthis program and one in the next chapter.\n\nOberon-07 of course benefits from all of Wirth's language improvements\nthat came after Pascal. Oberon-07 supports modules and as such\nthere is no need for a preprocessor.  Because of Oberon-07's module\nsupport I've implemented the Oberon version using two files\nrather than three. My main program file is \"Detab.Mod\",\nthe supporting library module is \"Tabs.Mod\". \"Tabs\" is where I\ndefine our tab stop data structure as well as the\nprocedures that operating on that data structure.\n\nLet's look at the first part, \"Detab.Mod\". This is the module\nthat forms the program and it features an module level \"BEGIN/END\" block.\nIn that block I call \"Detab();\" which implements the program's functionality.\nI import \"In\", \"Out\" as before but I also import \"Tabs\" which I will show next.\nLike my previous examples I validate the read was successful before proceeding\nwith the logic presented in the original Pascal and deciding\nwhat to write to standard output.\n\n~~~\n\nMODULE Detab;\n  IMPORT In, Out, Tabs;\n\nCONST\n  NEWLINE = 10;\n  TAB = 9;\n  BLANK = 32;\n\nPROCEDURE Detab;\nVAR\n  c : CHAR;\n  col : INTEGER;\n  tabstops : Tabs.TabType;\nBEGIN\n  Tabs.SetTabs(tabstops); (* set initial tab stops *)\n  col := 1;\n  REPEAT\n    In.Char(c);\n    IF In.Done THEN\n      IF (ORD(c) = TAB) THEN\n        REPEAT\n          Out.Char(CHR(BLANK));\n          col := col + 1;\n        UNTIL Tabs.TabPos(col, tabstops);\n      ELSIF (ORD(c) = NEWLINE) THEN\n        Out.Char(c);\n        col := 1;\n      ELSE\n        Out.Char(c);\n        col := col + 1;\n      END;\n    END;\n  UNTIL In.Done # TRUE;\nEND Detab;\n\nBEGIN\n  Detab();\nEND Detab.\n\n~~~\n\nOur second module is \"Tabs.Mod\". It provides the supporting procedures\nand definition of the our \"TabType\" data structure. For us this\nis the first time we write a module which \"exports\" procedures\nand type definitions. If you are new to Oberon, expected constants,\nvariables and procedures names have a trailing \"*\". Otherwise the\nOberon compiler will assume a local use only. This is a very\npowerful information hiding capability and what allows you to\nevolve a modules' internal implementation independently of the\nprograms that rely on it.\n\n~~~\n\nMODULE Tabs;\n\nCONST\n  MAXLINE = 1000; (* or whatever *)\n\nTYPE\n  TabType* = ARRAY MAXLINE OF BOOLEAN;\n\n(* TabPos -- return TRUE if col is a tab stop *)\nPROCEDURE TabPos*(col : INTEGER; VAR tabstops : TabType) : BOOLEAN;\n  VAR res : BOOLEAN;\nBEGIN\n  res := FALSE; (* Initialize our internal default return value *)\n  IF (col >= MAXLINE) THEN\n    res := TRUE;\n  ELSE\n    res := tabstops[col];\n  END;\n  RETURN res\nEND TabPos;\n\n(* SetTabs -- set initial tab stops *)\nPROCEDURE SetTabs*(VAR tabstops: TabType);\nCONST\n  TABSPACE = 4; (* 4 spaces per tab *)\nVAR\n  i : INTEGER;\nBEGIN\n  (* NOTE: Arrays in Oberon start at zero, we want to\n     stop at the last cell *)\n  FOR i := 0 TO (MAXLINE - 1) DO\n    tabstops[i] := ((i MOD TABSPACE) = 0);\n  END;\nEND SetTabs;\n\nEND Tabs.\n\n~~~\n\nNOTE: This module is used by \"Detab.Mod\" and \"Entab.Mod\"\nand provides for common type definitions and code reuse.\nWe exported `TabType`, `TabPos` and `SetTabs`. Everything else\nis private to this module.\n\n## In closing\n\nThis post briefly highlighted ports of the programs\npresented in Chapter 1 of \"Software Tools in Pascal\".\nBelow are links to my source files of the my\nimplementations inspired by the K & P book. Included\nin each Oberon module source after the module definition\nis transcribed text of the program documentation as well\nas transcribed text of the K & P Pascal implementations.\nEach file should compiler without modification using the\nOBNC compiler.  By default the OBNC compiler will use the\nmodule's name as the name of the executable version. I\nI have used mixed case module names, if you prefer lower\ncase executable names use the \"-o\" option with the OBNC\ncompiler.\n\n~~~\n\n    obnc -o copy CopyProg.Mod\n    obnc -o charcount CharCount.Mod\n    obnc -o linecount LineCount.Mod\n    obnc -o wordcount WordCount.Mod\n    obnc -o detab Detab.Mod\n\n~~~\n\nIf you happen to be using The [Oxford Oberon Compiler](http://spivey.oriel.ox.ac.uk/corner/Oxford_Oberon-2_compiler)\nyou need to rename the files ending in \".Mod\" to \".m\" \nand you can compiler with the following command.\n\n~~~\n    obc -07 -o copyprog CopyProg.m\n    obc -07 -o charcount CharCount.m\n    obc -07 -o linecount LineCount.m\n    obc -07 -o wordcount WordCount.m\n    obc -07 -o detab Tabs.m Detab.m\n~~~\n\nNote the line for compiling \"Detab\" with **obc**, your\nlocal modules need to become before the module calling them.\n\n\n+ [CopyProg](CopyProg.Mod)\n+ [CharCount](CharCount.Mod)\n+ [LineCount](LineCount.Mod)\n+ [WordCount](WordCount.Mod)\n+ [Detab](Detab.Mod)\n    + [Tabs](Tabs.Mod), this one we'll revisit in next installment.\n\n\n# Next\n\n+ [Filters](../../10/31/Filters.html)\n\n\n",
      "data": {
        "author": "rsdoiel@gmail.com (R. S. Doiel)",
        "copyright": "copyright (c) 2020, R. S. Doiel",
        "date": "2020-09-29",
        "keywords": [
          "Oberon",
          "Pascal",
          "programming"
        ],
        "license": "https://creativecommons.org/licenses/by-sa/4.0/",
        "number": 1,
        "series": "Software Tools",
        "title": "Software Tools, Getting Started"
      },
      "url": "posts/2020/09/29/Software-Tools-1.json"
    },
    {
      "content": "\n\n# Portable Oberon-07\n\n## using OBNC modules\n\nThis is the eleventh post in the [Mostly Oberon](../../04/11/Mostly-Oberon.html) series.\nMostly Oberon documents my exploration of the Oberon Language, Oberon System and the\nvarious rabbit holes I will inevitably fall into.\n\n## Working with standard input\n\nBy R. S. Doiel, 2020-08-15 (updated: 2020-09-05)\n\nKarl Landström's [OBNC](https://miasap.se/obnc/), Oberon-07 compiler,\ncomes with an Oberon-2 inspired set of modules\ndescribed in the Oakwood Guidelines as well as\nseveral very useful additions making Oberon-07 suitable for\nwriting programs in a POSIX environment.  We're going to\nexplore three of the Oakwood modules and two of Karl's own additions\nin this post as we create a program called [SlowCat](SlowCat.Mod).\nI am using the term \"portable\" to mean the code can be compiled\nusing OBNC on macOS, Linux, and Raspberry Pi OS and Windows 10\n(i.e. wherever OBNC is available). The Oakwood Guideline modules\nfocus on portability between an Oberon System and other systems.\nI'll leave that discussion along with\n[POW!](http://www.fim.uni-linz.ac.at/pow/pow.htm)\nto the end of this post.\n\n\n### SlowCat\n\nRecently while I was reviewing logs at work using [cat](https://en.wikipedia.org/wiki/Cat_(Unix)), [grep](https://en.wikipedia.org/wiki/Grep)\nand [more](https://en.wikipedia.org/wiki/More_(command)) it\nstruck me that it would have been nice if **cat**\nor **more** came with a time delay so you could use them like a\nteleprompter. This would let you casually watch the file scroll\nby while still being able to read the lines. The program we'll build\nin this post is \"SlowCat\" which accepts a command line parameter\nindicating the delay in seconds between display each line read from\nstandard input.\n\n## Working with Standard Input and Output\n\nThe Oakwood guides for Oberon-2 describe two modules\nparticularly useful for working with standard input and output.\nThey are appropriately called `In` and `Out`. On many Oberon Systems\nthese have been implemented such that your code could run under Unix\nor Oberon System with a simple re-compile.  We've used `Out` in our\nfirst program of this series, \"Hello World\". It provides a means to\nwrite Oberon system base types to standard out.  We've used `In`\na few times too. But `In` is worth diving into a bit more.\n\n### In\n\nThe [In](http://miasap.se/obnc/obncdoc/basic/In.def.html) module provides\na mirror of inputs to those of [Out](http://miasap.se/obnc/obncdoc/basic/Out.def.html). In Karl's implementation we are interested in one procedure\nand module status variable.\n\n+ `In.Line(VAR line: ARRAY OF CHAR)` : Read a sequence of characters from standard input from the current position in the file to the end of line.\n+ `In.Done` : Is a status Boolean variable, if the last call to an procedure in `In` was successful then it is set TRUE, otherwise FALSE (e.g. we're at the end of a file)\n\nWe use Karl's `In.Line()` extension to the standard `In` implementation\nbefore and will do so again as it simplifies our code and keeps things\neasily readable.\n\nThere is one nuance with `In.Done` that is easy to get tripped up on.\n`In.Done` indicates if the last operation was successful.\nSo if you're using `In.Line()` then `In.Done`\nshould be true if reading the line was successful. If you hit the end of\nthe file then `In.Done` should be false.  When you write your loop\nthis can be counter intuitive.  Here is a example of testing `In.Done`\nwith a repeat until loop.\n\n\n~~~\n\n    REPEAT\n      In.Line(text);\n      IF In.Done THEN\n        Out.String(text);Out.Ln();\n      END;\n    UNTIL In.Done = FALSE;\n\n~~~\n\n\nSo when you read this it is easy to think of `In.Done` as you're\ndone reading from standard input but actually we need to check for `FALSE`.\nThe value of `In.Done` was indicating the success of reading our line.\nAn unsuccessful line read, meaning we're at the end of the file, sets\n`In.Done` to false!\n\n### Out\n\nAs mention `Out` provides our output functions. We'll be using\ntwo procedure from `Out`, namely `Out.String()` and `Out.Ln()`.\nWe've seen both before.\n\n### Input\n\n\"SlowCat\" needs to calculate how often to write a line of\ntext to standard output with the `Out` module.  To do that\nI need access to the system's current time.  There isn't an\nOakwood module for time. There is a module called \n`Input` which provides a \"Time\" procedure. As a result\nI need to import `Input` as well as `In` even though\nI am using `In` to manage reading the file I am processing\nwith \"SlowCat\".\n\nA note about Karl's implementation.  `Input` is an Oakwood\nmodule that provides access to three system resources -- \nmouse, keyboard and system time.  Karl \nprovides two versions `Input` and `Input0`, the first is\nintended to be used with the `XYPlane` module for graphical\napplications the second for POSIX shell based application.\nIn the case of \"SlowCat\" I've stuck with `Input` as I am \nonly accessing time I've stuck with `Input` to make my source\ncode more portable if you're using another Oberon compiler.\n\n## Working with Karl's extensions\n\nThis is the part of my code which is not portable\nbetween compiler implementations and with Oberon Systems.\nKarl provides a number of extension module wrapping various\nPOSIX calls.  We are going to use two,\n[extArgs](http://miasap.se/obnc/obncdoc/ext/extArgs.def.html)\nwhich provides access to command line arguments and\n[extConvert](http://miasap.se/obnc/obncdoc/ext/extConvert.def.html)\nwhich provides a means of converting strings to integers.\nIf you are using another Oberon compiler you'll need to \nfind their equivalents and change my code example. I\nuse `extArgs` to access the command line parameters\nincluded in my POSIX shell invocation and I've used\n`extConvert` to convert the string presentation of the\ndelay to an integer value for my delay.\n\n\n## Our Approach\n\nTo create \"SlowCat\" we need four procedures and one\nglobal variable.\n\n`Usage()`\n: display a help text if parameters don't make sense\n\n`ProcessArgs()`\n: to get our delay time from the command line\n\n`Delay(count : INTEGER)`\n: a busy wait procedure\n\n`SlowCat(count : INTEGER)`\n: take standard input and display like a teleprompter\n\n`count`\n: is an integer holding our delay value (seconds of waiting) which is set by ProcessArgs()\n\n### Usage\n\nUsage just wraps helpful text and display it to standard out.\n\n## ProcessArgs()\n\nThis a functional procedure. It uses two of Karl's extension\nmodules. It uses `extArgs` to retrieve the command line parameters\nand `extConvert` the string value retrieved into an integer.\n`ProcessArgs()` returns TRUE if we can successful convert the\ncommand line parameter and set the value of count otherwise return\nFALSE.\n\n## Delay(VAR count : INTEGER)\n\nThis procedure uses `Input0` to fetch the current epoch time\nand counts the number of seconds until we've reached our delay\nvalue. It's a busy loop which isn't ideal but does keep the\nprogram simple.\n\n## SlowCat(VAR count: INTEGER);\n\nThis is the heart of our command line program. It reads\na line of text from standard input, if successful writes it\nto standard out and then waits using delay before repeating\nthis process. The delay is only invoked when a reading a\nline was successful.\n\n## Putting it all together\n\nHere's a \"SlowCat\" program.\n\n\n~~~\n\n    MODULE SlowCat;\n      IMPORT In, Out, Input, Args := extArgs, Convert := extConvert;\n\n    CONST\n      MAXLINE = 1024;\n\n    VAR\n      count: INTEGER;\n\n    PROCEDURE Usage();\n    BEGIN\n      Out.String(\"USAGE:\");Out.Ln();\n      Out.Ln();\n      Out.String(\"SlowCat outputs lines of text delayed by\");Out.Ln();\n      Out.String(\"a number of seconds. It takes one parameter,\");Out.Ln();\n      Out.String(\"an integer, which is the number of seconds to\");Out.Ln();\n      Out.String(\"delay a line of output.\");Out.Ln();\n      Out.String(\"SlowCat works on standard input and output.\");Out.Ln();\n      Out.Ln();\n      Out.String(\"EXAMPLE:\");\n      Out.Ln();\n      Out.String(\"    SlowCat 15 < README.md\");Out.Ln();\n      Out.Ln();\n    END Usage;\n\n    PROCEDURE ProcessArgs() : BOOLEAN;\n      VAR i : INTEGER; ok : BOOLEAN; arg : ARRAY MAXLINE OF CHAR;\n          res : BOOLEAN;\n    BEGIN\n      res := FALSE;\n      IF Args.count = 1 THEN\n        Args.Get(0, arg, i);\n        Convert.StringToInt(arg, i, ok);\n        IF ok THEN\n           (* convert seconds to microseconds of clock *)\n           count := (i * 1000);\n           res := TRUE;\n        END;\n      END;\n      RETURN res\n    END ProcessArgs;\n\n    PROCEDURE Delay*(count : INTEGER);\n      VAR start, current, delay : INTEGER;\n    BEGIN\n       start := Input.Time();\n       REPEAT\n         current := Input.Time();\n         delay := (current - start);\n       UNTIL delay >= count;\n    END Delay;\n\n    PROCEDURE SlowCat(count : INTEGER);\n      VAR text : ARRAY MAXLINE OF CHAR;\n    BEGIN\n      REPEAT\n        In.Line(text);\n        IF In.Done THEN\n          Out.String(text);Out.Ln();\n          (* Delay by count *)\n          Delay(count);\n        END;\n      UNTIL In.Done = FALSE;\n    END SlowCat;\n\n    BEGIN\n      count := 0;\n      IF ProcessArgs() THEN\n        SlowCat(count);\n      ELSE\n        Usage();\n      END;\n    END SlowCat.\n\n~~~\n\n\n## Compiling and trying it out\n\nTo compile our program and try it out reading\nour source code do the following.\n\n\n~~~\n\n    obnc SlowCat.Mod\n    # If successful\n    ./SlowCat 2 < SlowCat.Mod\n\n~~~\n\n\n\n## Oakwood Guidelines and POW!\n\nOberon and Oberon-2 were both used in creating and enhancing the\nOberon System(s) as well as for writing programs on other operating\nsystems (e.g. Apple's Mac and Microsoft Windows).\nImplementing Oberon compilers on non Oberon Systems required clarification\nbeyond the specification. The Oakwood Guidelines were an agreement\nbetween some of the important Oberon-2 compiler implementers which\nattempted to fill in that gap while encouraging portability in\nsource code between operating systems. Portability was desirable\nbecause it allowed programmers (e.g. students) to compile\nand run their Oberon programs with minimal modification in any\nenvironment where an Oakwood compliant compiler was available.\n\nCitation for Oakwood can be found in [Oberon-2 Programming with Windows](https://archive.org/details/oberonprogrammin00mhlb/page/n363/mode/2up?q=Oakwood+Guidlines).\n\n> Kirk B.(ed): The Oakwood Guidelines for Oberon-2 Compiler Developers. Available via FTP from ftp.fim.uni-linz.ac.at, /pub/soft/pow-oberon/oakwood\n\nThe FTP machine doesn't exist any more and does not appear to have been included in JKU's preservation plans. Fortunately the POW! website has been preserved.\n\n[POW!](http://www.fim.uni-linz.ac.at/pow/pow.htm) was a\ndifferent approach. It was a compiler and IDE targeting\nother than Oberon Systems (e.g. Windows and later Java). It was\nintended to be used in a hybrid development environment and to\nfacilitate leveraging non-Oberon resources (e.g. Java classes,\nnative Windows API).  POW project proposed \"Opal\" which was a\nsuper set of modules that went beyond Oakwood. Having skimmed\n\"Oberon-2 Programming with Windows\" some may seem reasonable to\nport to Oberon-07, others less so.\n\nWhy Oakwood and POW? These efforts are of interest to Oberon-07\ndevelopers as a well worn path to write code that is easy to\ncompile on POSIX systems and on systems that are based on the\nmore recent [Project Oberon 2013](http://www.projectoberon.com/).\nIt enhances the opportunity to bring forward well written modules\nfrom prior systems like [A2](https://en.wikibooks.org/wiki/Oberon/A2)\nbut implemented for the next generation of Oberon Systems\nlike [Integrated Oberon](https://github.com/io-core/io).\n\n### Oakwood PDF\n\nFinding a PDF of the original Oakwood guidelines is going to become\ntricky in the future. It was created by Robinson Associates and the\ncopy I've read from 1995 includes a page saying not for distribution.\nWhich sorta makes sense in the era of closed source software\ndevelopment. It is problematic for those of us who want to explore\nhow systems evolved.  The term \"Oakwood Guidelines\" is bandied about\nafter 1993 and several of the modules have had influence on the language\nuse via book publications.  I was able to find a PDF of the 1995\nversion of the guidelines at\n[http://www.math.bas.bg/bantchev/place/oberon/oakwood-guidelines.pdf](http://www.math.bas.bg/bantchev/place/oberon/oakwood-guidelines.pdf).\n\nHere's a typical explanation of Oakwood from \n[http://www.edm2.com/index.php/The_Oakwood_Guidelines_for_Oberon-2_Compiler_Developers#The_Oakwood_Guidelines](http://www.edm2.com/index.php/The_Oakwood_Guidelines_for_Oberon-2_Compiler_Developers#The_Oakwood_Guidelines)\nfor a description of Oakwood.\n\n> __The Oakwood Guidelines for the Oberon-2 Compiler Developers /These guidelines have been produced by a group of Oberon-2 compiler developers, including ETH developers, after a meeting at the Oakwood Hotel in Croydon, UK in June 1993__\n\n[http://www.edm2.com/index.php/The_Oakwood_Guidelines_for_Oberon-2_Compiler_Developers#The_Oakwood_Guidelines](http://www.edm2.com/index.php/The_Oakwood_Guidelines_for_Oberon-2_Compiler_Developers#The_Oakwood_Guidelines)  \n(an OS/2 developer website) was helpful for providing details about Oakwood.\n\nIt would have been nice if the Oakwood document had made its way\ninto either ETH's or JKU's research libraries.\n\nLeveraging prior art opens doors to the past and future. Karl has\ndone with this with the modules he provides with his OBNC compiler\nproject.\n\n### Next and Previous\n\n+ Next [Oberon to Markdown](../../10/03/Oberon-to-markdown.html)\n+ Previous [Procedures in records](../..//07/07/Procedures-in-records.html)\n\n",
      "data": {
        "author": "rsdoiel@gmail.com (R. S. Doiel)",
        "copyright": "copyright (c) 2020, R. S. Doiel",
        "date": "2020-08-15",
        "keywords": [
          "Oberon",
          "portable",
          "stdin"
        ],
        "license": "https://creativecommons.org/licenses/by-sa/4.0/",
        "number": 11,
        "series": "Mostly Oberon",
        "title": "Portable Oberon-07"
      },
      "url": "posts/2020/08/15/Portable-Oberon-07.json"
    },
    {
      "content": "\n\n# Procedures as parameters\n\nBy R. S. Doiel, 2020-06-20\n\nThis is the ninth post in the [Mostly Oberon](../../04/11/Mostly-Oberon.html) series.\nMostly Oberon documents my exploration of the Oberon Language, Oberon System and the \nvarious rabbit holes I will inevitably fall into.\n\nOberon-07 supports the passing of procedures as parameters in a procedure. \nLet's create a module name [Noises.Mod](Noises.Mod) to explore this.\n\nThe key to supporting this is Oberon's type system.  We need to decide what our \ngeneric procedure will look like first. In our case our procedures that will display \nan animal noise will include the name of the animal speaking.  We'll call this type \nof procedure \"Noise\". It'll accept an ARRAY OF CHAR for the name as a parameter \nthen use the standard Out module to display the animal name and noise they make.\n\n\n~~~\n\n    TYPE\n      Noise = PROCEDURE (who : ARRAY OF CHAR);\n\n~~~\n\n\nThe two \"Noise\" procedures will be \"BarkBark\" and \"ChirpChirp\". They will\nimplement the same parameter signature as describe in the \"Noise\" type.\n\n\n~~~\n\n    PROCEDURE BarkBark(who : ARRAY OF CHAR);\n    BEGIN\n      Out.String(who);\n      Out.String(\": Bark, bark\");Out.Ln();\n    END BarkBark;\n\n    PROCEDURE ChirpChirp(who : ARRAY OF CHAR);\n    BEGIN\n      Out.String(who);\n      Out.String(\": Chirp, chirp\");Out.Ln();\n    END ChirpChirp;\n\n~~~\n\n\nWe'll also create a procedure, MakeNoise, that accepts the animal name and\nour \"Noise\" procedure name and it'll call the \"Noise\" type procedure \npassing in the animal name.\n\n\n~~~\n\n    PROCEDURE MakeNoise(name : ARRAY OF CHAR; noise : Noise);\n    BEGIN\n      (* Call noise with the animal name *)\n      noise(name);\n    END MakeNoise;\n\n~~~\n\n\nIf we invoke MakeNoise with our animal name and pass the name of the \nprocedure we want to do the MakeNoise procedure will generate our\nnoise output. Here' is what is looks like all together.\n\n\n~~~\n\n    MODULE Noises;\n      IMPORT Out;\n    \n    TYPE \n      Noise = PROCEDURE(who : ARRAY OF CHAR);\n    \n    PROCEDURE BarkBark(who : ARRAY OF CHAR);\n    BEGIN\n      Out.String(who);\n      Out.String(\": Bark, bark\");Out.Ln();\n    END BarkBark;\n    \n    PROCEDURE ChirpChirp(who : ARRAY OF CHAR);\n    BEGIN\n      Out.String(who);\n      Out.String(\": Chirp, chirp\");Out.Ln();\n    END ChirpChirp;\n    \n    PROCEDURE MakeNoise(name : ARRAY OF CHAR; noise : Noise);\n    BEGIN\n      (* Call noise with the animal name *)\n      noise(name);\n    END MakeNoise;\n    \n    BEGIN\n      MakeNoise(\"Fido\", BarkBark);\n      MakeNoise(\"Tweety\", ChirpChirp);\n      MakeNoise(\"Fido\", ChirpChirp);\n      MakeNoise(\"Tweety\", BarkBark);\n    END Noises.\n\n~~~\n\n\nNote when we pass the procedures we include their name **without** parenthesis.\nOur type definition tells the compiler that the procedure can be a parameter,\nany procedure with the same signature, e.g. `who : ARRAY OF CHAR` as the\nonly parameter will be treated as a \"Noise\" type procedures. \n\n### Next and Previous \n\n+ Next [Procedures in Records](../../07/07/Procedures-in-records.html)\n+ Previous [Dynamic types](../../05/25/Dynamic-types.html) \n\n\n",
      "data": {
        "author": "rsdoiel@gmail.com (R. S. Doiel)",
        "copyright": "copyright (c) 2020, R. S. Doiel",
        "date": "2020-06-20",
        "keywords": [
          "Oberon",
          "procedures",
          "passing procedures as parameters",
          "programming"
        ],
        "license": "https://creativecommons.org/licenses/by-sa/4.0/",
        "number": 9,
        "series": "Mostly Oberon",
        "title": "Procedures as parameters"
      },
      "url": "posts/2020/06/20/Procedures-as-parameters.json"
    },
    {
      "content": "\n\nSetting up a RetroFlag GPi Case\n===============================\n\nBy R. S. Doiel, 2020-12-24\n\nThese are my notes for setting up a RetroFlag GPi case using Recalbox\ndistribution for retro gaming.\n\n+ RetroFlag GPi Case Kit (including a Raspberry Pi Zero W and blank SD Card)\n+ A computer to setup the SD Card  and the Raspberry Pi Imager v1.5\n\nWe will be installing [Recalbox](https://www.recalbox.com/ \"the all-in-one retro gaming console\")\nv7.7.x for Raspberry Pi Zero W and GPi case.  Recalbox which is a Retro\nGaming Linux distribution.\n\nSteps\n=====\n\nPreparing the 32 GiB SD Card\n---------------------------\n\n1. Download the appropriate Raspberry Pi Imager 1.5 from \n   https://www.raspberrypi.org/software/ for your system\n2. Install and launch the Raspberry Pi Imager\n3. Click \"Operating System\"\n  a. Select \"Emulation and game OS\"\n  b. Select \"Recalbox\"\n  c. Select \"Recalbox 7.1.1-Reloaded (Pi 0/1/GPi Case)\"\n4. Click \"SD Card\" \", then select the bank 32 GiB SD Card\n5. Click \"Write\"\n6. You will be asked remove the SD Card when done, do so and and exit \n   Raspberry Pi Imager\n\nNOTE: The current release of Recalbox (7.7.1) doesn't require patching\nwith \"GPI_Case_patch.zip\" or installing the shutdown scripts as suggested\non the RetroFlag website. Applying the patches will prevent the GPi\nfrom booting. The website instructions appear to be for an earlier release\nof Recalbox.\n\n\nInstalling the Raspberry Pi Zero W in the GPi Case\n--------------------------------------------------\n\nThe RetroFlag comes with instructions to install the Raspberry Pi Zero W\nin the case. I found the pictorial instructions confusing. Doing a search\nfor \"RetroFlag GPi Case Setup\" yielded a link to [Howchoo's YouTube\nvideo](https://www.youtube.com/watch?v=NyJUlNifN1I&feature=youtu.be \"RetroFlag GPi CASE Setup and Usage\"),  This video also talks about setting up Retro Pi software,\nGPi case patches. Skip these. The instructions are now for software that\nis out of date (the video dates back to 2019). \n\nNOTE: Howchoo describes installing RetroPie not Recalbox. Don't install a\n\"wpa_supplicant.conf\" file or \"ssh\" file on the SD Card as suggested.\nIt is not needed and will cause problems.\n\nThe GPi case looks very much like a Game Boy. It includes a \"Game Pack\"\ntype module which will hold our Raspberry Pi once installed. I found the\nassembly instructions confusing but searching YouTube for \"RetroFlag GPi\nCase Setup\" listed several videos which describe the process of putting\nthe case together as well as how to install RetroPie or\nRecalbox Linux Distributions.\n\nBooting the Pi Zero W with the SD Card\n--------------------------------------\n\n1. Make sure the GPi Zero Case **IS NOT CONNECTED TO POWER**\n  a. the switch the case off\n  b. Disconnect the barrel to USB cable from a power source\n2. Remove the \"game pack\" element where you've installed the Raspberry Pi Zero W\n3. Insert the SD Card into the SD Card slot under the soft cover on the side of\n   the Game Pack case\n4. Re-insert \"Game Pack\" into side of the GPi case\n5. Plug the barrel USB cable into a USB Power supply , \n6. Turn the power switch to \"ON\" on the top of the GPi case\n7. Wait patiently, it's going to take several minutes to boot the first time\n\n\n\n\n\n",
      "data": {
        "author": "rsdoiel@gmail.com (R. S. Doiel)",
        "copyright": "copyright (c) 2020, R. S. Doiel",
        "date": "2020-12-24",
        "keywords": [
          "raspberry pi",
          "retro games",
          "case"
        ],
        "license": "https://creativecommons.org/licenses/by-sa/4.0/",
        "title": "RetroFlag GPi Case Setup"
      },
      "url": "posts/2020/12/24/gpi-case-setup.json"
    },
    {
      "content": "\n\n# Accessing Go from Julia\n\nBy R. S. Doiel, 2018-03-11\n\nThe problem: I've started exploring Julia and I would like to leverage existing\ncode I've written in Go. Essentially this is a revisit to the problem in my\nlast post [Go based Python Modules](https://rsdoiel.github.io/blog/2018/02/24/go-based-python-modules.html) \nbut with the language pairing of Go and Julia.\n\n\n## Example 1, libtwice.go, libtwice.jl and libtwice_test.jl\n\nIn out first example we send an integer value from\nJulia to Go and back via a C shared library (written in Go). While Julia doesn't\nrequire type declarations I will be using those for clarity. Like in my previous post\nI think this implementation this is a good starting point to see how Julia interacts with\nC shared libraries. Like before I will present our Go code, an explanation \nfollowed by the Julia code and commentary.\n\nOn the Go side we create a _libtwice.go_ file with an empty `main()` \nfunction.  Notice that we also import the *C* package and use \na comment decoration to indicate the function we are exporting\n(see https://github.com/golang/go/wiki/cgo and \nhttps://golang.org/cmd/cgo/\nfor full story about Go's _C_ package and _cgo_).\nPart of the what _cgo_ and the *C* package does is use the \ncomment decoration to build the signatures for the function calls\nin the shared C library.  The Go toolchain does all the heavy \nlifting in making a *C* shared library based on comment \ndirectives like \"//export\". We don't need much for our twice\nfunction.\n\n```Go\n    package main\n    \n    import (\n    \t\"C\"\n    )\n    \n    //export twice\n    func twice(i int) int {\n    \treturn i * 2\n    }\n    \n    func main() {}\n```\n\nLike in our previous Python implementation we need to build the C shared\nlibrary before using it from Julia. Here are some example Go build commands\nfor Linux, Windows and Mac OS X. You only need to run the one that applies\nto your operating system.\n\n```shell\n    go build -buildmode=c-shared -o libtwice.so libtwice.go\n    go build -buildmode=c-shared -o libtwice.dll libtwice.go\n    go build -buildmode=c-shared -o libtwice.dynlib libtwice.go\n```\n\nUnlike the Python implementation our Julia code will be split into two files. _libtwice.jl_ will\nhold our module definition and _libtwice_test.jl_ will hold our test code. In the\ncase of _libtwice.jl_ we will access the C exported function via a function named *ccall*. \nJulia doesn't require a separate module to be imported in order to access a C shared library.\nThat makes our module much simpler. We still need to be mindful of type conversion.  Both \nGo and Julia provide for rich data types and structs.  But between Go and Julia we have C \nand C's basic type system.  On the Julia side *ccall* and Julia's type system help us\nmanaging C's limitations.\n\nHere's the Julia module we'll call _libtwice.jl_.\n\n```Julia\n    module libtwice\n            \n    # We write our Julia idiomatic function\n    function twice(i::Integer)\n        ccall((:twice, \"./libtwice\"), Int32, (Int32,), i)\n    end\n\n    end\n```\n\nWe're will put the test code in a file named _libtwice\\_test.jl_. Since this isn't\nan establish \"Package\" in Julia we will use Julia's *include* statement to get bring the\ncode in then use an *import* statement to bring the module into our current name space.\n\n```Julia\n    include(\"libtwice.jl\")\n    import libtwice\n    # We run this test code for libtwice.jl\n    println(\"Twice of 2 is \", libtwice.twice(2))\n```\n\nOur test code can be run with\n\n```shell\n    julia libtwice_test.jl\n```\n\nNotice the amount of lifting that Julia's *ccall* does. The Julia code is much more compact\nas a result of not having to map values in a variable declaration. We still have the challenges \nthat Julia and Go both support richer types than C. In a practical case we should consider \nthe over head of running to two runtimes (Go's and Julia's) as well as whether or not \nimplementing as a shared library even makes sense. But if you want to leverage existing \nGo based code this approach can be useful.\n\nExample 1 is our base recipe. The next examples focus on handling\nother data types but follow the same pattern.\n\n\n## Example 2, libsayhi.go, libsayhi.jl and libsayhi_test.jl\n\nLike Python, passing strings passing to or from Julia and Go is nuanced. Go is expecting \nUTF-8 strings. Julia also supports UTF-8 but C still looks at strings as a pointer to an\naddress space that ends in a null value. Fortunately in Julia the *ccall* function combined with\nJulia's rich type system gives us straight forward ways to map those value. \nGo code remains unchanged from our Python example in the previous post. \nIn this example we use Go's *fmt* package to display the string. In the next example\nwe will round trip our string message.\n\n```go\n    package main\n    \n    import (\n    \t\"C\"\n    \t\"fmt\"\n    )\n    \n    //export say_hi\n    func say_hi(msg *C.char) {\n    \tfmt.Println(C.GoString(msg))\n    }\n    \n    func main() { }\n```\n\nThe Go source is the similar to our first recipe. No change from our\nprevious posts' Python example. It will need to be compiled to create our\nC shared library just as before. Run the go build line that applies to\nyour operating system (i.e., Linux, Windows and Mac OS X).\n\n```shell\n    go build -buildmode=c-shared -o libsayhi.so libsayhi.go\n    go build -buildmode=c-shared -o libsayhi.dll libsayhi.go\n    go build -buildmode=c-shared -o libsayhi.dylib libsayhi.go\n```\n\nOur Julia module looks like this.\n\n```julia\n    module libsayhi\n\n    # Now write our Julia idiomatic function using *ccall* to access the shared library\n    function say_hi(txt::AbstractString)\n        ccall((:say_hi, \"./libsayhi\"), Int32, (Cstring,), txt)\n    end\n\n    end\n```\n\nThis code is much more compact than our Python implementation.\n\nOur test code looks like\n\n```julia\n    include(\"./libsayhi.jl\")\n    import libsayhi\n    libsayhi.say_hi(\"Hello again!\")\n```\n\nWe run our tests with\n\n```shell\n    julia libsayhi_test.jl\n```\n\n\n## Example 3, libhelloworld.go and librhelloworld.cl and libhelloworld_test.jl\n\nIn this example we send a string round trip between Julia and Go. \nMost of the boiler plate we say in Python is gone due to Julia's type system. In\naddition to using Julia's *ccall* we'll add a *convert* and *bytestring* function calls\nto bring our __Cstring__ back to a __UTF8String__ in Julia.\n\nThe Go implementation remains unchanged from our previous Go/Python implementation. \nThe heavy lifting is done by the *C* package and the comment \n`//export`. We are using `C.GoString()` and `C.CString()` to flip between \nour native\nGo and C datatypes.\n\n```go\n    package main\n    \n    import (\n    \t\"C\"\n    \t\"fmt\"\n    )\n    \n    //export helloworld\n    func helloworld(name *C.char) *C.char {\n    \ttxt := fmt.Sprintf(\"Hello %s\", C.GoString(name))\n    \treturn C.CString(txt)\n    }\n    \n    func main() { }\n```\n\nAs always we must build our C shared library from the Go code. Below is\nthe go build commands for Linux, Windows and Mac OS X. Pick the line that\napplies to your operating system to build the C shared library.\n\n```shell\n    go build -buildmode=c-shared -o libhelloworld.so libhelloworld.go\n    go build -buildmode=c-shared -o libhelloworld.dll libhelloworld.go\n    go build -buildmode=c-shared -o libhelloworld.dylib libhelloworld.go\n```\n\nIn our Julia, _libhelloworld.jl_, the heavy lifting of type conversion\nhappens in Julia's type system and in the *ccall* function call. Additionally we need\nto handle the conversion from __Cstring__ Julian type to __UTF8String__ explicitly\nin our return value via a functions named *convert* and *bytestring*.\n\n```julia\n    module libhelloworld\n\n    # Now write our Julia idiomatic function\n    function helloworld(txt::AbstractString)\n        value = ccall((:helloworld, \"./libhelloworld\"), Cstring, (Cstring,), txt)\n        convert(UTF8String, bytestring(value))\n    end\n\n    end\n```\n\nOur test code looks similar to our Python test implementation.\n\n```julia\n    include(\"libhelloworld.jl\")\n    import libhelloworld\n \n    if length(ARGS) > 0\n        println(libhelloworld.helloworld(join(ARGS, \" \")))\n    else\n        println(libhelloworld.helloworld(\"World\"))\n    end\n```\n\nAs before we see the Julia code is much more compact than Python's.\n\n\n## Example 4, libjsonpretty.go, libjsonpretty.jl and libjsonpretty_test.jl\n\nIn this example we send JSON encode text to the Go package,\nunpack it in Go's runtime and repack it using the `MarshalIndent()`\nfunction in Go's JSON package before sending it back to Julia\nin C string form.  You'll see the same encode/decode patterns as \nin our *libhelloworld* example.\n\nGo code\n\n```go\n    package main\n    \n    import (\n    \t\"C\"\n    \t\"encoding/json\"\n    \t\"fmt\"\n    \t\"log\"\n    )\n    \n    //export jsonpretty\n    func jsonpretty(rawSrc *C.char) *C.char {\n    \tdata := new(map[string]interface{})\n    \terr := json.Unmarshal([]byte(C.GoString(rawSrc)), &data)\n    \tif err != nil {\n    \t\tlog.Printf(\"%s\", err)\n    \t\treturn C.CString(\"\")\n    \t}\n    \tsrc, err := json.MarshalIndent(data, \"\", \"    \")\n    \tif err != nil {\n    \t\tlog.Printf(\"%s\", err)\n    \t\treturn C.CString(\"\")\n    \t}\n    \ttxt := fmt.Sprintf(\"%s\", src)\n    \treturn C.CString(txt)\n    }\n    \n    func main() {}\n```\n\nBuild commands for Linux, Windows and Mac OS X are as before, pick the one that matches\nyour operating system.\n\n```shell\n    go build -buildmode=c-shared -o libjsonpretty.so libjsonpretty.go\n    go build -buildmode=c-shared -o libjsonpretty.dll libjsonpretty.go\n    go build -buildmode=c-shared -o libjsonpretty.dylib libjsonpretty.go\n```\n\nOur Julia module code\n\n```Julia\n    module libjsonpretty\n\n    # Now write our Julia idiomatic function\n    function jsonpretty(txt::AbstractString)\n        value = ccall((:jsonpretty, \"./libjsonpretty\"), Cstring, (Cstring,), txt)\n        convert(UTF8String, bytestring(value))\n    end\n    \n    end\n```\n\nOur Julia test code\n\n```Julia\n    include(\"./libjsonpretty.jl\")\n    import libjsonpretty\n\n    src = \"\"\"{\"name\":\"fred\",\"age\":25,\"height\":75,\"units\":\"inch\",\"weight\":\"239\"}\"\"\"\n    println(\"Our origin JSON src\", src)\n    value = libjsonpretty.jsonpretty(src)\n    println(\"And out pretty version\\n\", value)\n```\n\nAs before you can run your tests with `julia libjsonpretty_test.jl`.\n\nIn closing I would like to note that to use these examples I am assuming your\nJulia code is in the same directory as your shared C library. Julia, like Python3,\nhas a feature rich module and Package system. If you are creating a serious Julia\nproject then you need to be familiar with how Julia's package and module system works\nand place your code and shared libraries appropriately.\n\n\n",
      "data": {
        "author": "rsdoiel@gmail.com (R. S. Doiel)",
        "copyright": "copyright (c) 2018, R. S. Doiel",
        "date": "2018-03-11",
        "keywords": [
          "Golang",
          "Julia",
          "shared libraries"
        ],
        "license": "https://creativecommons.org/licenses/by-sa/4.0/",
        "title": "Accessing Go from Julia"
      },
      "url": "posts/2018/03/11/accessing-go-from-julia.json"
    },
    {
      "content": "\n\n# Go, Bleve and Library oriented software\n\nBy R. S. Doiel, 2018-02-19\n(updated: 2018-02-22)\n\nIn 2016, Stephen Davison, asked me, \"Why use Go and Blevesearch for\nour library projects?\" After our conversation I wrote up some notes so\nI would remember. It is now 2018 and I am revising these notes. I\nthink our choice paid off.  What follows is the current state of my\nreflection on the background, rational, concerns, and risk mitigation\nstrategies so far for using [Go](https://golang.org) and\n[Blevesearch](https://blevesearch.com) for Caltech Library projects.\n\n## Background\n\nI first came across Go a few years back when it was announced as an\nOpen Source project by Google at an Google I/O event (2012). The\noriginal Go authors were Robert Griesemer, Rob Pike, and Ken\nThompson. What I remember from that presentation was Go was a rather\nconsistent language with the features you need but little else.  Go\ndeveloped at Google as a response to high development costs for C/C++\nand Java in addition to challenges with performance and slow\ncompilation times.  As a language I would put Go between C/C++ and\nJava. It comes the ease of writing and reading you find in languages\nlike Python. Syntax is firmly in the C/C++ family but heavily\nsimplified. Like Java it provides many modern features including rich basic\ndata structures and garbage collection. It has a very complete standard\nlibrary and provides very good tooling.  This makes it easy to\ngenerate code level documentation, format code, test, efficiently profile, \nand debug.\n\nOften programming languages develop around a specific set of needs.\nThis is true for Go. Given the Google origin it should not be\nsurprising to find that Go's primary strengths are working with \nstructured data, I/O and concurrency. The rich standard\nlibrary is organized around a package concept. These include packages\nsupporting network protocols, file and socket I/O as well as various\nencoding and compression scheme. It has particularly strong support\nfor XML, JSON, CSV formatted data out of the box. It has a template\nlibrary for working with plain text formats as well as generating safe\nHTML. You can browse Go's standard library https://golang.org/pkg/.\n\nAn additional feature is Go's consistency. Go code that compiles under\nversion 1.0 still compiles under 1.10. Even before 1.0 code changes\nthat were breaking came with tooling to automatically updates existing\ncode.  Running code is a strong element of Go's evolution.\n\nGo is unsurprising and has even been called boring.  This turns out to\nbe a strength when building sustainable projects in a small team.\n\n\n## Why do I write Go?\n\nFor me Go is a good way to write web services, assemble websites,\ncreate search appliances and write command line (cli) utilities. When\na shell script becomes unwieldy Go is often what I turn to.  Go is\nwell suited to building tools as well as systems.  Go based command\nline tools are very easy to orchestrate with shell and Python.\n\nGo runs on all the platforms I actively use - Windows, Mac OS X, Linux\non both Intel and ARM (e.g. Raspberry Pi, Pine64). It has experimental\nsupport for Android and iOS.  I've used a tool called\n[GopherJS](http://gopherjs.org) to write web browser applications that\ntransform my command line tools into web tools with a friendlier user\ninterface (see our [BibTeX Tools](https://caltechlibrary.github.io/bibtex/webapp/)).\n\nGo supports cross compiling out of the box. This means a production\nsystem running on AWS, Google's compute engine or Microsoft's Azure\ncan be compiled from Windows, Mac OS or even a Raspberry Pi!\nDeployment is a matter of copying the (self contained) compiled binary\nonto the production system. This contrasts with other\nplatforms like Perl, PHP, Python, NodeJS and Ruby where you need to\ninstall not only your application code but all dependencies. While\ninterpretive languages retain an advantage of having a REPL, Go\nbased programs have advantages of fast compile times and easy deployment.\n\nIn many of the projects I've written in Go I've only required a few\n(if any) 3rd party libraries (packages in Go's nomenclature). This is\nquite a bit different from my experience with Perl, PHP, Python,\nNodeJS and Ruby. This is in large part a legacy of having grown up at\nGoogle before become an open source project. While the Go standard\npackages are very good there is a rich ecosystem for 3rd party\npackages for specialized needs. I've found I tend to rely only on a\nfew of them. The one I've used the most is\n[Bleve](http://blevesearch.com).\n\nBleve is a Go package for building search engines. When I originally\ncame across Bleve (around 2014), it was described as \"Lucene lite\". \n\"Lucene lite\" was an apt description, but I find it easier\nto use than Lucene. When I first used Bleve I embedded its\nfunctionality into the tools I used to process data and present web\nservices. It did not have much in the way of stand alone command line\ntooling.  Today I increasingly think of Bleve as \"Elastic Search\nlite\". It ships with a set of command line tools that include support\nfor building Bleve's indexes.  My current practice is to only embed the search\nportion of the packages. I can use the Bleve command line for the\nrest.  In 2018, Bleve is being actively developed, has a small vibrant\ncommunity and is used by [Couchbase](https://couchbase.com), a well\nestablished NoSQL player.\n\n\n## Who is using Go?\n\nMany companies use Go. The short list includes\nGoogle, Amazon, Netflix, Dropbox, Box, eBay, Pearsons and even\nWalmart and Microsoft. This came to my attention at developer conferences\nback in 2014.  People from many of these companies started\npresenting at conferences on pilot projects that had been successful\nand moved to production. Part of what drove adoption was the ease\nof development in Go along with good system performance. I also think\nthere was a growing disenchantment with alternatives like C++, C sharp\nand Java as well as the weight of the LAMP, Tomcat, and OpenStack.\n\nHighly visible Go based projects include\n\n+ [Docker](http://docker.org) and [Rocket](http://www.docker.com) - Containerization for running process in the cloud\n+ [Kubernettes](http://kubernetes.io/) and [Terraform](https://www.terraform.io/) - Container orchestration systems\n+ [Hugo](http://hugo.io) - the fast/popular static website generator, an alternative to Jekyll, for those who want speed\n+ [Caddy](https://caddyserver.com/) - a Go based web server trying to unseat Apache/NGinX focusing on easy of use plus speed\n+ [IPFS](http://ipfs.io) - a cutting edge distributed storage system based on block chains\n\n\n### Who is using Blevesearch?\n\nHere's some larger projects using Bleve.\n\n+ [Couchbase](http://www.couchbase.com), a NoSQL database platform are replacing Lucene with Bleve.  Currently the creator of Bleve works for them.\n+ [Hugo](http://hugo.io) can integrate with Bleve for search and index generation\n+ [Caddy](https://caddyserver.com/) integrates with Bleve to provide an embedded search capability\n\n\n## Managing risks\n\nIn 2014 Go was moving from bleeding to leading edge. Serious capital\nwas behind its adoption and it stopped being an exotic conference\nitem. In 2014 Bleve was definitely bleeding edge. By late 2015 and early\n2016 the program level API stabilized. People were piloting projects\nwith it. This included our small group at Caltech Library. In 2015\nnon-English language support appeared followed by a growing list\nof non-European languages in 2016. By mid 2016 we started to see \nmissing features like alternative sorting added. While Bleve isn't\nyet 1.0 (Feb. 2018) it is reliable. The primary challenge for the Bleve\nproject is documentation targeting the novice and non-Programmer users.\nBleve has proven effective as an indexing and search platform for \narchival, library, and data repository content.\n\nAdopting new software comes with risk. We have mitigated this in two ways.\n\n1. Identify alternative technology (a plan B)\n2. Architect our systems for easy decomposition and re-composition\n\nIn the case of Go, packages can be compiled to a C-Shared\nlibrary. This allows us to share working Go packages with languages\nlike Python, R, and PHP. We have included shared Go/Python modules\non our current road map for projects.\n\nFor Blevesearch the two alternatives are Solr and Elastic\nSearch. Both are well known, documented, and solid.  The costs would be\nrecommitting to a Java stack and its resource requirements. We have\nalready identified what we want to index and that could be converted\nto either platform if needed.  If we stick with Go but dropped \nBlevesearch we would swap out the Bleve specific code for Go packages \nsupporting Solr and Elastic Search.\n\n\nThe greatest risk in adopting Go for library and archive projects was \nknowledge transfer. We addressed this \nby knowledge sharing and insuring the Go codebase can \nbe used via command line programs.  Additionally \nwe are adding support for Go based Python modules.\nTraining also is available in the form of books, websites and\nonline courses ([lynda.com](https://www.lynda.com/Go-tutorials/Up-Running-Go/412378-2.html) offers a \"Up Running Go\" course).\n\n\n## What are the benefits?\n\nFor library and archives software we have found Go's benefits include\nimproved back end systems performance at a lower cost, ease of development, \nease of deployment, a rich standard library focused on the types of things \nneeded in library and archival software.  Go plays nice with\nother systems (e.g. I create an API based service in Go that can easily\nbe consumed by a web browser running JavaScript or Perl/PHP/Python\ncode running under LAMP). In the library and archives setting Go \ncan become a high performance duck tape. We get the performance and \nreliability of C/Java type systems with code simplicity \nsimilar to Python.\n",
      "data": {
        "author": "rsdoiel@gmail.com (R. S. Doiel)",
        "copyright": "copyright (c) 2018, R. S. Doiel",
        "date": "2018-02-19",
        "keywords": [
          "Golang",
          "Bleve",
          "search"
        ],
        "license": "https://creativecommons.org/licenses/by-sa/4.0/",
        "title": "Go, Bleve and Library oriented software"
      },
      "url": "posts/2018/02/19/go-bleve-and-libraries.json"
    },
    {
      "content": "\n\n# Go based Python modules\n\nBy R. S. Doiel, 2018-02-24\n\nThe problem: I have written a number of Go packages at work.\nMy colleagues know Python and I'd like them to be able to use the\npackages without resorting to system calls from Python to the\ncommand line implementations. The solution is create a C-Shared\nlibrary from my Go packages, using Go's _C_ package and combine it\nwith Python's _ctypes_ package.  What follows is a series of \nsimple recipes I used to understand the details of how that worked.\n\n\n## Example 1, libtwice.go and twice.py\n\nMany of the the examples I've come across on the web start by \nshowing how to run a simple math operation on the Go side with\nnumeric values traveling round trip via the C shared library layer. \nIt is a good place to start as you only need to consider type \nconversion between both Python's runtime and Go's runtime.  It \nprovides a simple illustration of how the Go *C* package, Python's\n*ctypes* module and the toolchain work together.\n\nIn this example we have a function in Go called \"twice\" it takes\na single integer, doubles it and returns the new value.  On\nthe Go side we create a _libtwice.go_ file with an empty `main()` \nfunction.  Notice that we also import the *C* package and use \na comment decoration to indicate the function we are exporting\n(see https://github.com/golang/go/wiki/cgo and \nhttps://golang.org/cmd/cgo/\nfor full story about Go's _C_ package and _cgo_).\nPart of the what _cgo_ and the *C* package does is use the \ncomment decoration to build the signatures for the function calls\nin the shared C library.  The Go toolchain does all the heavy \nlifting in making a *C* shared library based on comment \ndirectives like \"//export\". We don't need much for our twice\nfunction.\n\n```Go\n    package main\n    \n    import (\n    \t\"C\"\n    )\n    \n    //export twice\n    func twice(i int) int {\n    \treturn i * 2\n    }\n    \n    func main() {}\n```\n\nOn the python side we need to wrap our calls to our shared library\nbringing them into the Python runtime in a useful and idiomatically\nPython way. Python provides a few ways of doing this. In my examples\nI am using the *ctypes* package.  _twice.py_ looks like this--\n\n```python\n    import ctypes\n    import os\n    \n    # Set our shared library's name\n    lib_name='libtwice'\n    \n    # Figure out shared library extension\n    uname = os.uname().sysname\n    ext = '.so'\n    if uname == 'Darwin':\n        ext = '.dylib'\n    if uname == 'Windows':\n        ext = '.dll'\n    \n    # Find our shared library and load it\n    dir_path = os.path.dirname(os.path.realpath(__file__))\n    lib = ctypes.cdll.LoadLibrary(os.path.join(dir_path, lib_name+ext))\n    \n    # Setup our Go functions to be nicely wrapped\n    go_twice = lib.twice\n    go_twice.argtypes = [ctypes.c_int]\n    go_twice.restype = ctypes.c_int\n    \n    # Now write our Python idiomatic function\n    def twice(i):\n        return go_twice(ctypes.c_int(i))\n    \n    # We run this test code if with: python3 twice.py\n    if __name__ == '__main__':\n        print(\"Twice of 2 is\", twice(2))\n```\n\nNotice the amount of lifting Python's *ctypes* does for us. It provides\nfor converting C based types to their Python counter parts. Indeed the\nadditional Python source here is focused around using that functionality\nto create a simple Python function called twice. This pattern of \nbringing in a low level version of our desired function and then \npresenting in a Pythonic one is common in more complex C based Python\nmodules.  In general we need *ctypes* to access and wrapping our \nshared library. The *os* module is used so we can find our C \nshared library based on the naming conventions of our host OS. \nFor simplicity I've kept the shared library (e.g. _libtwice.so_ \nunder Linux) in the same directory as the python module \ncode _twice.py_.\n\nThe build command for Linux looks like---\n\n```shell\n    go build -buildmode=c-shared -o libtwice.so libtwice.go\n```\n\nUnder Windows it would look like---\n\n```shell\n    go build -buildmode=c-shared -o libtwice.dll libtwice.go\n```\n\nand Mac OS X---\n\n```shell\n    go build -buildmode=c-shared -o libtwice.dynlib libtwice.go\n```\n\nYou can test the Python module with---\n\n```shell\n    python3 twice.py\n```\n\nNotice the filename choices. I could have called the Go shared\nlibrary anything as long as it wasn't called `twice.so`, `twice.dll`\nor `twice.dylib`. This constraint is to avoid a module name collision\nin Python.  If we had a Python script named `twice_test.py` and \nimport `twice.py` then Python needs to make a distinction between\n`twice.py` and our shared library. If you use a Python package\napproach to wrapping the shared library you would have other options\nfor voiding name collision.\n\nHere is an example of `twice_test.py` to make sure out import is\nworking.\n\n```python\n    import twice\n    print(\"Twice 3\", twice.twice(3))\n```\n\nExample 1 is our base recipe. The next examples focus on handling\nother data types but follow the same pattern.\n\n\n## Example 2, libsayhi.go and sayhi.py\n\nI found working with strings a little more nuanced. Go's concept of\nstrings are oriented to utf-8. Python has its own concept of strings \nand encoding.  Both need to pass through the C layer which assumes \nstrings are a char pointer pointing at contiguous memory ending \nin a null. The *sayhi* recipe is focused on moving a string from \nPython, to C, to Go (a one way trip this time). The example uses \nGo's *fmt* package to display the string. \n\n```go\n    package main\n    \n    import (\n    \t\"C\"\n    \t\"fmt\"\n    )\n    \n    //export say_hi\n    func say_hi(msg *C.char) {\n    \tfmt.Println(C.GoString(msg))\n    }\n    \n    func main() { }\n```\n\nThe Go source is similar to our first recipe but our Python modules\nneeds to use *ctypes* to get you Python string into shape to be\nunpacked by Go.\n\n```python\n   import ctypes\n   import os\n   \n   # Set the name of our shared library\n   lib_name = 'libsayhi'\n\n   # Figure out shared library extension\n   uname = os.uname().sysname\n   ext = '.so'\n   if uname == 'Darwin':\n       ext = '.dylib'\n   if uname == 'Windows':\n       ext = '.dll'\n   \n   # Find our shared library and load it\n   dir_path = os.path.dirname(os.path.realpath(__file__))\n   lib = ctypes.cdll.LoadLibrary(os.path.join(dir_path, lib_name+ext))\n   \n   # Setup our Go functions to be nicely wrapped\n   go_say_hi = lib.say_hi\n   go_say_hi.argtypes = [ctypes.c_char_p]\n   # NOTE: we don't have a return type defined here, the message is \n   # displayed from Go\n   \n   # Now write our Python idiomatic function\n   def say_hi(txt):\n       return go_say_hi(ctypes.c_char_p(txt.encode('utf8')))\n   \n   if __name__ == '__main__':\n       say_hi('Hello!')\n```\n\nPutting things together (if you are using Windows or Mac OS X\nyou'll adjust name output name, `libsayhi.so`, to match the\nfilename extension suitable for your operating system).\n\n```bash\n    go build -buildmode=c-shared -o libsayhi.so libsayhi.go\n```\n\nand testing.\n\n```bash\n    python3 sayhi.py\n```\n\n\n## Example 3, libhelloworld.go and helloworld.py\n\nIn this example we send a Python string to Go (which expects utf-8)\nbuild our \"hello world\" message and then send it back to Python\n(which needs to do additional conversion and decoding).\n\nLike in previous examples the Go side remains very simple. The heavy\nlifting is done by the *C* package and the comment `//export`. We\nare using `C.GoString()` and `C.CString()` to flip between our native\nGo and C datatypes.\n\n```go\n    package main\n    \n    import (\n    \t\"C\"\n    \t\"fmt\"\n    )\n    \n    //export helloworld\n    func helloworld(name *C.char) *C.char {\n    \ttxt := fmt.Sprintf(\"Hello %s\", C.GoString(name))\n    \treturn C.CString(txt)\n    }\n    \n    func main() { }\n```\n\nIn the python code below the conversion process is much more detailed.\nPython isn't explicitly utf-8 like Go. Plus we're sending our Python \nstring via C's char arrays (or pointer to chars). Finally when we \ncomeback from Go via C we have to put things back in order for Python. \nOf particular note is checking how the byte arrays work then \nencoding/decoding everything as needed. We also explicitly set the result \ntype from our Go version of the helloworld function.\n\n```python\n    import ctypes\n    import os\n    \n    # Set the name of our shared library\n    lib_name = 'libhelloworld'\n\n    # Figure out shared library extension\n    uname = os.uname().sysname\n    ext = '.so'\n    if uname == 'Darwin':\n        ext = '.dylib'\n    if uname == 'Windows':\n        ext = '.dll'\n    \n    # Find our shared library and load it\n    dir_path = os.path.dirname(os.path.realpath(__file__))\n    lib = ctypes.cdll.LoadLibrary(os.path.join(dir_path, lib_name+ext))\n    \n    # Setup our Go functions to be nicely wrapped\n    go_helloworld = lib.helloworld\n    go_helloworld.argtypes = [ctypes.c_char_p]\n    go_helloworld.restype = ctypes.c_char_p\n    \n    # Now write our Python idiomatic function\n    def helloworld(txt):\n        value = go_helloworld(ctypes.c_char_p(txt.encode('utf8')))\n        if not isinstance(value, bytes):\n            value = value.encode('utf-8')\n        return value.decode()\n    \n    \n    if __name__ == '__main__':\n        import sys\n        if len(sys.argv) > 1:\n            print(helloworld(sys.argv[1]))\n        else:\n            print(helloworld('World'))\n```\n\nThe build recipe remains the same as the two previous examples.\n\n```bash\n    go build -buildmode=c-shared -o libhelloworld.so libhelloworld.go\n```\n\nHere are two variations to test.\n\n```bash\n     python3 helloworld.py\n     python3 helloworld.py Jane\n```\n\n\n## Example 4, libjsonpretty.go and jsonpretty.py\n\nIn this example we send JSON encode text to the Go package,\nunpack it in Go's runtime and repack it using the `MarshalIndent()`\nfunction in Go's JSON package before sending it back as Python\nin string form.  You'll see the same encode/decode patterns as \nin our *helloworld* example.\n\nGo code\n\n```go\n    package main\n    \n    import (\n    \t\"C\"\n    \t\"encoding/json\"\n    \t\"fmt\"\n    \t\"log\"\n    )\n    \n    //export jsonpretty\n    func jsonpretty(rawSrc *C.char) *C.char {\n    \tdata := new(map[string]interface{})\n    \terr := json.Unmarshal([]byte(C.GoString(rawSrc)), &data)\n    \tif err != nil {\n    \t\tlog.Printf(\"%s\", err)\n    \t\treturn C.CString(\"\")\n    \t}\n    \tsrc, err := json.MarshalIndent(data, \"\", \"    \")\n    \tif err != nil {\n    \t\tlog.Printf(\"%s\", err)\n    \t\treturn C.CString(\"\")\n    \t}\n    \ttxt := fmt.Sprintf(\"%s\", src)\n    \treturn C.CString(txt)\n    }\n    \n    func main() {}\n```\n\nPython code\n\n```python\n    import ctypes\n    import os\n    import json\n    \n    # Set the name of our shared library\n    lib_name = 'libjsonpretty'\n\n    # Figure out shared library extension\n    uname = os.uname().sysname\n    ext = '.so'\n    if uname == 'Darwin':\n        ext = '.dylib'\n    if uname == 'Windows':\n        ext = '.dll'\n\n    dir_path = os.path.dirname(os.path.realpath(__file__))\n    lib = ctypes.cdll.LoadLibrary(os.path.join(dir_path, lib_name+ext))\n    \n    go_jsonpretty = lib.jsonpretty\n    go_jsonpretty.argtypes = [ctypes.c_char_p]\n    go_jsonpretty.restype = ctypes.c_char_p\n    \n    def jsonpretty(txt):\n        value = go_jsonpretty(ctypes.c_char_p(txt.encode('utf8')))\n        if not isinstance(value, bytes):\n            value = value.encode('utf-8')\n        return value.decode()\n    \n    if __name__ == '__main__':\n        src = '''\n    {\"name\":\"fred\",\"age\":25,\"height\":75,\"units\":\"inch\",\"weight\":\"239\"}\n    '''\n        value = jsonpretty(src)\n        print(\"Pretty print\")\n        print(value)\n        print(\"Decode into dict\")\n        o = json.loads(value)\n        print(o)\n```\n\nBuild command\n\n```shell\n    go build -buildmode=c-shared -o libjsonpretty.so libjsonpretty.go\n```\n\nAs before you can run your tests with `python3 jsonpretty.py`.\n\nIn closing I would like to note that to use these examples you Python3\nwill need to be able to find the module and shared library. For \nsimplicity I've put all the code in the same directory. If your Python\ncode is spread across multiple directories you'll need to make some \nadjustments.\n\n",
      "data": {
        "author": "rsdoiel@gmail.com (R. S. Doiel)",
        "copyright": "copyright (c) 2018, R. S. Doiel",
        "date": "2018-02-24",
        "keywords": [
          "Golang",
          "Python",
          "shared libraries"
        ],
        "license": "https://creativecommons.org/licenses/by-sa/4.0/",
        "title": "Go based Python modules"
      },
      "url": "posts/2018/02/24/go-based-python-modules.json"
    },
    {
      "content": "\n\n# Review: Software Tools in Pascal\n\nBy R. S. Doiel, 2018-07-22\n(updated: 2018-07-22, 1:39 pm, PDT)\n\n\nThis book is by Brian W. Kernighan and P. J. Plauger. It is an\nexample of the type of books I find I re-read and want in my\npersonal library. The book covers software construction through \na series of programs written in pascal. It is about how these \nprograms work, how to approach problems and write sound software.\nI was surprised I did not know about this book when I was browsing \nthe [Open Library](https://openlibrary.org) this weekend.  While \nPascal was a popular in the 1980's it has faded for most people in the \nearly 21st century.  This review maybe a small bit of nostalgia. \nOn the other hand I suspect \n[\"Software Tools in Pascal\"](https://openlibrary.org/books/OL4258115M/Software_tools_in_Pascal)\nis one of the short list of computer books that will remain useful\nover the long run.\n\n\n## What's covered\n\nThe book is organized around specific programs and their implementations.\nThe implementations provided are simple and straight forward. Each\nsection is followed by a set of \"exercises\" that extend the ideas\nshown in the section. In this way you could derive the modern equivalent\nof these tools.\n\nThe topics you build tools for in the text are\nfilters, files, sorting, text patterns, editing, formatting, \nand macro processing.\n\nIf you want to follow the book along in Pascal then I think Free Pascal\navailable in many Debian distributions including Raspbian on the Raspberry\nPi is a good choice.  Likewise Wirth's Pascal is easy enough to port\nto other languages and indeed this would be a useful exercise when I\nre-read the book the next time.\n\nThe book presents a very nice set of text oriented programs to explore\nprogramming or re-connect with your programming roots.\n\n## Read the book\n\n<iframe width=\"165\" frameBorder=\"0\" height=\"400\" src=\"https://openlibrary.org/books/OL4258115M/Software_tools_in_Pascal/widget\"></iframe>\n",
      "data": {
        "author": "rsdoiel@gmail.com (R. S. Doiel)",
        "copyright": "copyright (c) 2018, R. S. Doiel",
        "date": "2018-07-22",
        "keywords": [
          "Pascal",
          "programming",
          "book review"
        ],
        "license": "https://creativecommons.org/licenses/by-sa/4.0/",
        "title": "Review: Software Tools in Pascal"
      },
      "url": "posts/2018/07/22/software-tools-in-pascal.json"
    },
    {
      "content": "\n\nOPML to Markdown and back\n=========================\n\nBy R. S. Doiel 2016-05-28\n\n## Overview\n\nI wrote a Go language package to sort [OPML](http://dev.opml.org/spec2.html) outlines. \nI wrote this because my preferred [feed reader ](http://goread.io) supports manual \nsorting but not automatic alpha sorting by the _outline_ element's _text_ attribute. \n\n## Observations\n\nOut of the box the OPML 2 Spec provides attributes indicating inclusion of other OPML files,\nscripts, basic metadata (create, modified, authorship), and even directory structures.\n\n[Fargo](http://fargo.io) allows user defined attributes to be applied to the _outline_ \nelement in OPML. This could be used in support some of the \n[Scrivener](https://www.literatureandlatte.com/scrivener.php)\nfeatures I miss such as describing how to render a project to various formats such as\nrtf, pdf, ePub, web pages or even [Final Draft fdx](https://www.finaldraft.com/) files.\n\nI write allot of Markdown formatted text.  Markdown is simple to index, \nsearch and convert into useful formats. Markdown is not good at expressing more\ncomplex structures such as metadata. Website generators that use markdown often\nrequire a preamble or _front matter_ in the markdown to provide any metadata. This\nleaves your document head cluttered and less human readable.\n\nAnother approach is to include a parallel document with the metadata.  It occurred to me \nthat an OPML file could easily hold that metadata. It can even hold Markdown content.\nThe trouble with OPML is that it is not quick to edit by hand.\n\n    Is there a round trip semantic mapping between OPML and Markdown?\n\n\n## Germination of an idea\n\nEntering a web link in Fargo the link is URL encoded and saved in the _text_ attribute of the \n_outline_ element.\n\nThe source view of a web links in Fargo's _outline_ element looks like\n\n```OPML\n    <outline text=\"&gt; href=&quot;http://example.org&quot;&lt;My example.org&gt;/a&lt;\" />\n```\n\nThat _outline_ element might render in Markdown as\n\n```\n    + [My element.org](http://example.org)\n```\n\nThe steps to create the Markdown view are simple\n\n1. URL decode the _text_ attribute\n2. Convert HTML to Markdown\n\nMaking a round trip could be done by\n\n3. Convert Markdown into HTML\n4. For each _li_ element covert to an _outline_ element URL encoding the inner HTML of the _li_\n\nSo far so good. What about something more complex?\n\n\nHere's an _outline_ element example from http://hosting.opml.org/dave/spec/directory.opml \n\n```OPML\n    <outline text=\"Scripting News sites\" created=\"Sun, 16 Oct 2005 05:56:10 GMT\" type=\"link\" url=\"http://hosting.opml.org/dave/mySites.opml\"/>\n```\n\nTo me that should look like \n\n```\n    + [Scripting News Sites](http://hosting.opml.org/dave/mySites.opml)\n```\n\nWhat about the _created_ attribute? Could we render this case as an additional set of anchors using data uri?\n\nThis suggest a rule like\n\n+ if the _text_ attribute contains HTML markup\n    + URL decode into HTML\n    + Convert HTML to Markdown\n+ else render attributes as additional anchors using data URI\n\nThis might work as follows. \n\n```OPML\n    <outline text=\"Scripting News sites\" \n        created=\"Sun, 16 Oct 2005 05:56:10 GMT\" \n        type=\"link\" \n        url=\"http://hosting.opml.org/dave/mySites.opml\"/>\n```\n\nWould become \n\n```Markdown\n    + [Scripting News Sites](http://hosting.opml.org/dave/mySites.opml) [type](data:text/plain;link) [created](data:text/date;Sun, 16 Oct 2005 05:56:10 GMT)\n```\n\nIn HTML this would look like\n\n```HTML\n    <li><a href=\"http://histing.opml.org/dave/mySites.opml\">Scripting News Sites</a>\n        <a href=\"data:text/plain;link\">type</a>\n        <a href=\"data:text/date;Sun, 16 Oct 2005 05:56:10 GMT\">created</a></li>\n```\n\n### Markdown to OPML\n\nComing back to OPML from Markdown then becomes\n\n+ Convert Markdown to HTML\n+ For each _li_ element inspect anchors, \n    + if anchors contain data URI then map _outline_ element\n    + else URL encode and embed in _outline_ _text_ attribute\n\nIs this viable? Does it have any advantages?\n\n",
      "data": {
        "author": "rsdoiel@gmail.com (R. S. Doiel)",
        "copyright": "copyright (c) 2016, R. S. Doiel",
        "date": "2016-05-28",
        "keywords": [
          "golang",
          "opml",
          "markdown"
        ],
        "license": "https://creativecommons.org/licenses/by-sa/4.0/",
        "title": "OPML to Markdown and back"
      },
      "url": "posts/2016/05/28/OPML-to-Markdown-and-back.json"
    },
    {
      "content": "\n\n# Instant Articles, Accelerated Mobile Pages, Twitter Cards and Open Graph\n\nBy R. S. Doiel 2016-05-30\n\n## The problem\n\nThe web has gotten slow. In [2016](http://httparchive.org/trends.php) the \naverage page weight is in multi-megabytes and the average number of network \nrequests needed to deliver the content is counted in \nthe hundreds. In the mix are saturated networks and a continued public \nexpectation of responsiveness (web wisdom suggests you have about 3 seconds \nbefore people give up).  The odd thing is we've known how to build fast \nwebsites for a [decade](https://www.stevesouders.com/) or so.  \nCollectively we don't build them [fast](https://www.sitepoint.com/average-page-weight-increased-another-16-2015/). \n\n\n## Meet the new abstractions\n\nCorporations believe they have the answer and they are providing us \nwith another set of abstractions. In a few years maybe these will \nget distilled down to a shared common view but in the mean time disc \ncosts remain reasonably priced and generating these new forms of \npages or feeds is a template or so away.\n\n+ [Twitter Cards](https://dev.twitter.com/cards/overview) and [Open Graph](http://ogp.me/)\n  + Exposing your content via social media, search results or embedded in pages via an aside element\n+ [Accelerated Mobile Pages](https://www.ampproject.org/) (also called AMP)\n  + A simplification in content delivery to improve web reading experience\n  + Its usefulness is it proscribes an approach to leverage what we have\n  + AMP works well with Twitter Cards, Open Graph and can leverage Web Components\n+ [Instant Articles](https://instantarticles.fb.com/)\n  + a format play to feed the walled garden of Facebook for iOS and Android devices\n\n\n## The players \n\n### Twitter Cards and Open Graph\n\nTwitter's Titter Cards and Facebook's Open Graph offer approaches to \nbuild off of our existing meta elements in an HTML page's document \nhead.  They are named space to avoid collisions but supporting both \nwill still result in some content duplication. The k-weight \ndifference in the resulting HTML pages isn't too bad. \n\nAdopting either or both is a matter of adjusting how your render your \nweb page's head block.  It is easy enough to do manually but easier \nstill using some sort of template system that renders the appropriate \nmeta elements based on the content type and contents in the page \nbeing rendered.  \n\nGoogle and other search engines can leverage this richer meta \ndata and integrate it into their results. Google's Now application can \nrender content cards based on either semantic. It also appears that \ncontent cards are being leverage selectively for an aside and related \ncontent on Google search results pages. You could even built this into \nyour own indexing process for use with the Solr or Elasticsearch.\n\nContent Cards offer intriguing opportunity for web crawlers and search \nengines.  This is particularly true when combined with mature feed \nformats like RSS, OPML, Atom and the maturing efforts in the linked \ndata community around JSON-LD.\n\n\n### AMP - Accelerated Mobile Pages\n\nThe backers of AMP (not to be confused with Apache+MySQL+PHP) are largely\npublishers including major news outlets and web media\ncompanies in the US and Europe. This is an abridged list from 2015--\n\n+ BBC\n+ Atlantic Media\n+ Vox Media\n+ Conde Nast\n+ New York Times\n+ Wall Street Journal\n+ The Daily Mail\n+ Huffington Post\n+ Gannet\n+ The Guardian\n+ The Economist\n+ The Financial Times\n\nIn additional to the publishers there is participation by tech companies\nsuch as Google, Pinterest, Twitter, LinkedIn and Wordpress.com.  Accelerated\nMobile Pages offer benefits for web crawlers and search engines supporting\nsurfacing content is clearly and enabling easier distinction from \nadvertisements. \n\n\n### Instant Articles\n\nIn additional to Open Graph Facebook has put forward [Instant Articles](https://developers.facebook.com/docs/instant-articles).\nLike AMP it is targeting content delivery for mobile. Unlike AMP Instant Articles is an\nexplicit binding into Facebook's walled garden only exposing the content on supported\nversions of iOS and Android. You don't see Instant Articles in your Facebook timeline or when  \nyou browse from a desktop web browser.  Unlike the previous\nexamples you actually need to sign up to participate in the Instant Article publishing\nprocess.  Sign up cost is having a Facebook account, being approved by Facebook and compliance\nwith their terms of service. Facebook does provide some publishing tools, publishing controls\nas well as some analytics. They do allow 3rd party ads as well as encourage access to\ntheir advertising network.  Once approved the burden on your content manage process \nappears manageable.  \n\nYou can submit Instant Articles via a modified RSS feed or directly through their API. \nIn this sense the overhead is about the same as that for implementing support for Twitter Cards\nOpen Graph, and AMP. Facebook does a good job of quickly propagating changes to your\nInstant Articles across their platform. That's nice.\n\nWhy go through the trouble? If you're a content producer and your audience lives on Facebook\nFacebook commands the attention of a lot of eye balls.  Instant Articles provides \nanother avenue to reach them.  For some Facebook effectively controls the public view of the \nweb much as America Online and Prodigy did decades ago. [Dave Winer](https://twitter.com/davewiner) \nhas written extensively on how he implemented Instant Article support along with \nsome very reasoned pros and cons for doing so. The landscape is evolving and \n[Dave's river of news](http://scripting.com) is worth following.\n\n\n## Impact on building content\n\nThese approaches require changes in your production of your HTML and RSS sent to the browser.\nTwitter Cards and Open Graph change what you put in the HEAD element of the HTML\npages.  AMP proscribes what you should put in the BODY element of the webpage.\nInstant Articles tweaks your RSS output.  Not surprisingly the major content management \nsystems Wordpress and Drupal have plugins for this.  All can be implemented via your template \nsystem or page generation process.\n\n\n## Whither adopt?\n\nBecause these approaches boil down to content assembly the adoption risk \nis low.  If your audience views Twitter, Facebook or Google search results \nthen it is probably worth doing.  All allow you to continue to publish your \nown content and own your URLs as opposed to being a tenant on one or another \nplatform. That benefits the open web.\n\n",
      "data": {
        "author": "rsdoiel@gmail.com (R. S. Doiel)",
        "copyright": "copyright (c) 2016, R. S. Doiel",
        "date": "2016-05-30",
        "keywords": [
          "structured data",
          "amp",
          "opengraph",
          "twitter",
          "google",
          "facebook",
          "instant pages"
        ],
        "license": "https://creativecommons.org/licenses/by-sa/4.0/",
        "title": "Instant Articles, Accelerated Mobile Pages, Twitter Cards and Open Graph"
      },
      "url": "posts/2016/05/30/amp-cards-and-open-graph.json"
    },
    {
      "content": "\n\nHow to make a Pi-Top more Raspbian\n==================================\n\nBy R. S. Doiel, 2016-07-04\n\nI have a first generation Pi-Top.  I like the idea but found I didn't use it much due to a preference for\nbasic Raspbian. With the recent Pi-TopOS upgrades I realized getting back to basic Raspbian was relatively\nstraight forward.\n\n## The recipe\n\n1. Make sure you're running the latest Pi-TopOS based on Jessie\n2. Login into your Pi-Top normally\n3. From the Pi-Top dashboard select the \"Desktop\" icon\n4. When you see the familiar Raspbian desktop click on the following things\n\t+ Click on the Raspberry Menu (upper left corner)\n\t+ Click on Preferences\n\t+ Click on Raspberry Pi Configuration\n5. I made the following changes to my System configuration\n\t+ Under *Boot* I selected \"To CLI\"\n\t+ I unchecked *login as user \"pi\"*\n6. Restart your Pi Top\n\t+ Click on Raspberry Menu in the upper left of the desktop\n\t+ Click on shutdown\n\t+ Select *reboot*\n7. When you restart you'll see an old school console login, login as the pi user using your Pi-Top password\n8. Remove the following program use the *apt* command\n\t+ ceed-universe\n\t+ pt-dashboard\n\t+ pt-splashscreen\n\n```\n    sudo apt purge ceed-universe pt-dashboard pt-splashscreen\n```\n\nNote: pi-battery, pt-hub-controller, pt-ipc, pt-speaker are hardware drivers specific to your Pi-Top so you probably\nwant to keep them.\n\n\n\n",
      "data": {
        "author": "rsdoiel@gmail.com (R. S. Doiel)",
        "copyright": "copyright (c) 2016, R. S. Doiel",
        "date": "2016-07-04",
        "keywords": [
          "Raspberry Pi",
          "Pi-Top",
          "Rasbian",
          "Raspberry Pi OS",
          ":operating systems"
        ],
        "license": "https://creativecommons.org/licenses/by-sa/4.0/",
        "title": "How to make a Pi-Top more Raspbian"
      },
      "url": "posts/2016/07/04/How-To-Make-A-PiTop-More-Raspbian.json"
    },
    {
      "content": "\n\n# Android, Termux and Dev Environment\n\nBy R. S. Doiel 2016-09-20\n\nRecently I got a new Android 6 tablet. I got a case with a tiny Bluetooth keyboard. I started wondering if I could use it as a development device when on the road. So this is my diary of that test.\n\n## Challenges\n\n1. Find a way to run Bash without rooting my device\n2. See if I could use my normal web toolkit\n\t+ curl\n\t+ jq\n\t+ sed\n\t+ grep\n3. See if I could compile or add my own custom Golang programs\n4. Test setup by running a local static file server, mkpage and update my website\n\n## Searching for Android packages and tools of my toolbox\n\nAfter searching with Duck Duck Go and Google I came across the [termux](https://termux.com). Termux provides a minimal Bash shell environment with support for adding\npackages with _apt_ and _dpkg_.  The repositories visible to *termux* include\nmost of the C tool chain (e.g. clang, make, autoconf, etc) as well as my old Unix favorites _curl_, _grep_, _sed_, _gawk_ and a new addition to my toolkit _jq_.  Additionally you'll find recent versions (as of Sept. 2016) versions of _Golang_, _PHP_, _python_, and _Ruby_.\n\nThis quickly brought me through step 3.  Installing _go_, _git_, and _openssh_ completed what I needed to test static site development with some of the tools in our incubator at [Caltech Library](https://caltechlibrary.github.io).\n\n## Setting up for static site development\n\nAfter configuring _git_, adding my public key to GitHub and running _go get_ on my\ncustom static site tools I confirmed I could build and test static websites from my Android tablet using *Termux*.\n\nHere's the list of packages I installed under *Termux* to provide a suitable shell environment for writing and website constructions.\n\n```shell\n    apt install autoconf automake bash-completion bc binutils-dev bison \\\n        bzip2 clang cmake coreutils ctags curl dialog diffutils dos2unix \\\n        expect ffmpeg findutils gawk git gnutls golang grep gzip \\\n\timagemagick jq less lynx m4 make-dev man-dev nano nodejs \\\n        openssh patch php-dev python readline-dev rlwrap rsync ruby-dev \\\n        sed sensible-utils sharutils sqlite tar texinfo tree unzip vim \\\n        w3m wget zip\n```\n\nThis then allowed me to setup my *golang* environment variables and install\nmy typical custom written tools\n\n```shell\n    export PATH=$HOME/bin:$PATH\n    export GOPATH=$HOME\n    export GOBIN=$HOME/bin\n    go get github.com/rsdoiel/shelltools/...\n    go get github.com/caltechlibrary/mkpage/...\n    go get github.com/caltechlibrary/md2slides/...\n    go get github.com/caltechlibrary/ws/...\n```\n\nFinally pulled down some content to test.\n\n```shell\n    cd\n    mkdir Sites\n    git clone https://github.com/rsdoiel/rsdoiel.github.io.git Sites/rsdoiel.github.io\n    cd  Sites/rsdoiel.github.io\n    ws\n```\n\nThis started the local static site webserver and I pointed by Firefox for Android at http://localhost:8000 and saw a local copy of my personal website. From there I wrote this article and updated it just as if I was working on a Raspberry Pi or standard Linux laptop.\n\n\n",
      "data": {
        "author": "rsdoiel@gmail.com (R. S. Doiel)",
        "copyright": "copyright (c) 2016, R. S. Doiel",
        "date": "2016-09-20",
        "keywords": [
          "Bash",
          "cURL",
          "jq",
          "sed",
          "grep",
          "search",
          "golang",
          "Android"
        ],
        "license": "https://creativecommons.org/licenses/by-sa/4.0/",
        "title": "Android, Termux and Dev Environment"
      },
      "url": "posts/2016/09/20/Android-Termux-Dev-environment.json"
    },
    {
      "content": "\n\nFrom Markdown and Bash to mkpage\n================================\n\nBy R. S. Doiel 2016-08-16\n\nWhen I started maintaining a website on GitHub a few years ago my needs\nwere so simple I hand coded the HTML.  Eventually I adopted \na markdown processor for maintaining the prose. My \"theme\" was a\nCSS file and some HTML fragments to wrap the markdown output. If I needed \ninteractivity I used JavaScript to access content via a web API. \nLife was simple, all I had to learn to get started was Git and how to\npopulate a branch called \"gh-pages\".\n\n\n## Deconstructing Content Management Systems\n\nRecently my website needs have grown. I started experimenting with static\nsite generators thinking an existing system would be the right fit. \nWhat I found were feature rich systems that varied primarily in \nimplementation language and template engine. Even though I wasn't\nrequired to run Apache, MySQL and PHP/Perl/Python/Ruby/Tomcat it felt \nlike the static site generators were racing to fill a complexity \nvacuum. In the end they were interesting to explore but far more\nthan I was willing to run. I believe modern content management systems can\nbe deconstruct into something simpler.\n\nSome of the core elements of modern content management systems are\n\n+ creation and curation of data sources (including metadata)\n+ transforming data sources if needed\n+ mapping a data source to appropriate template set\n+ rendering template sets to produce a final website\n\nModern static site generators leave creation and curation to your \ntext editor and revision control system (e.g. vi and git). \n\nMost static site generators use a simplified markup. A populate one is\ncalled [Markdown](https://en.wikipedia.org/wiki/Markdown). This \"markup\"\nis predictable enough that you can easily convert the results to HTML and\nother useful formats with tools like [pandoc](http://pandoc.org/). In most \nstatic site generators your content is curated in Markdown and when the \npages are built it is rendered to HTML for injection into your website's \ntemplate and theme.\n\nMapping the data sources to templates, combining the templates and rendering \nthe final website is where most systems introduce a large amount of complexity.\nThis is true of static site generators like [Jekill](https://jekyllrb.com) and \n[Hugo](https://gohugo.io).\n\n\n## An experimental deconstruction\n\nI wanted a simple command line tool that would make a single web page.\nIt would take a few data sources and formats and run them through a\ntemplate system. The template system needed to be simple but support\nthe case where data might not be available. It would be nice if it handled\nthe case of repetitious data like that used in tables or lists. Ideally\nI could render many pages from a single template assuming a simple website\nand layout.\n\n### A single page generator\n\n[mkpage](https://github.com/rsdoiel/mkpage) started as an experiment in\nbuilding a simple single page generator. It's responsibilities\ninclude mapping data sources to the template, transforming data if needed\nand rendering the results. After reviewing the websites I've setup in\nthe last year or two I realized I had three common types of data.\n\n1. Plain text or content that did not need further processing\n2. Markdown content (e.g. page content, navigation lists)\n3. Occasionally I include content from JSON feeds\n\nI also realized I only needed to handle three data sources.\n\n1. strings\n2. files\n3. web resources\n\nEach of these sources might provide plain text, markdown or JSON data formats.\n\nThat poses the question of how to express the data format and the data \nsource when mapping the content into a template. The web resources are\neasy in the sense that the web responses include content type information.\nFiles can be simple too as the file extension indicates their\nformat (e.g. \".md\" for Markdown, \".json\" for JSON documents). What remained\nwas how to identify a text string's format.  I opted for a prefix ending in \na colon (e.g. \"text:\" for plain text, \"markdown:\" for markdown \nand \"json:\" for JSON). This mapping allows for a simple key/value\nrelationship to be expressed easily on the command line.\n\n### mkpage in action\n\nDescribing how to build \"mypage.html\" from \"mypage.md\" and \"nav.md\" \n(containing links for navigating the website) is as easy as typing\n\n```shell\n    mkpage \"content=mypage.md\" \"navigation=nav.md\" page.tmpl > mypage.html\n```\n\nIn this example the template is called \"page.tmpl\" and we redirect the \noutput to \"mypage.html\".\n\n\nAdding a custom page title is easy too.\n\n```shell\n    mkpage \"title=text:My Page\" \\\n        \"content=mypage.md' \"navigation=nav.md\" \n        page.tmpl \\\n        > mypage.html\n```\n\nLikewise integrating some JSON data from weather.gov is relatively straight\nforward. The hardest part is discovering the [URL](http://forecast.weather.gov/MapClick.php?lat=34.0522&lon=118.2437&DFcstType=json) \nthat returns JSON!  Notice I have added a weather field and the URL. When data\nis received back from weather.gov it is JSON decoded and then passed to the\ntemplate for rendering using the \"range\" template function.\n\n```shell\n    mkpage \"title=My Page\" \\\n        \"content=mypage.md\" \\\n        \"navigation=nav.md\" \\\n        \"weather=http://forecast.weather.gov/MapClick.php?lat=34.0522&lon=118.2437&DFcstType=json\" \\\n        page.tmpl \\\n        > mypage.html\n```\n\nWhat is *mkpage* doing?\n\n1. Reading the data sources and formats from the command line\n2. Transforming the Markdown and JSON content appropriately\n3. Applying them to the template (e.g. page.tmpl)\n4. Render the results to stdout\n\nBuilding a website then is only a matter of maintaining navigation in\n*nav.md* and identifying the pages needing to be created. I can easily \nautomated that using the Unix find, grep, cut and sort. Also with find \nI can iteratively process each markdown file applying a \ntemplate and rendering the related HTML file.  This can be done for a site \nof a few pages (e.g. about, resume and cv) to more complex websites like \nblogs and repository activities.\n\nHere's an example template that would be suitable for the previous\ncommand line example. It's mostly just HTML and some curly bracket notation \nsprinkled in.\n\n```html\n    <!DOCTYPE html>\n    <html>\n    <head>\n        {{with .title}}<title>{{- . -}}</title>{{end}}\n        <link rel=\"stylesheet\" href=\"css/site.css\">\n    </head>\n    <body>\n        <nav>\n        {{ .navigation }}\n        </nav>\n        <section>\n        {{ .content }}\n        </section>\n        <aside>\n        Weather Demo<br />\n        <ul>\n        {{range .weather.data.text}}\n            <li>{{ . }}</li>\n        {{end}}\n        </ul>\n        </aside>\n\n    </body>\n    </html>\n```\n\nYou can find out more about [mkpage](https://github.com/rsdoiel/mkpage)\n[rsdoiel.github.io/mkpage](https://rsdoiel.github.io/mkpage).\n\nTo learn more about Go's text templates see \n[golang.org/pkg/text/template](https://golang.org/pkg/text/template/). \n\nIf your site generator needs are more than *mkpage* I suggest [Hugo](https://gohugo.io). \nIt's what I would probably reach for if I was building a large complex organizational\nsite or news site.\n\nIf you're looking for an innovative and rich author centric content system\nI suggest Dave Winer's [Fargo](http://fargo.io) outliner and [1999.io](https://1999.io).\n\n\n",
      "data": {
        "author": "rsdoiel@gmail.com (R. S. Doiel)",
        "copyright": "copyright (c) 2016, R. S. Doiel",
        "date": "2016-08-16",
        "keywords": [
          "Bash",
          "Markdown",
          "site generator",
          "mkpage",
          "pandoc"
        ],
        "license": "https://creativecommons.org/licenses/by-sa/4.0/",
        "title": "From Markdown and Bash to mkpage"
      },
      "url": "posts/2016/08/16/From-Markdown-and-Bash-to-mkpage.json"
    },
    {
      "content": "\n\n# Exploring Bash for Windows 10 Pro\n\nBy R. S. Doiel 2016-08-15\n\n    UPDATE (2016-10-27, RSD): Today trying to compile Go 1.7.3 under \n    Windows 10 Pro I've am getting compile errors when the \n    assembler is being built.  I can compile go1.4.3 but see errors \n    in some of the tests results.\n\n## Initial Setup and configuration\n\nI am running Windows 10 Pro (64bit) Anniversary edition under Virtual Box. The VM was upgraded from an earlier version of Windows 10 Pro (64bit). The VM was allocated 4G or ram, 200G disc and simulating 2 cores.  After the upgrade I took the following steps\n\n+ Search with Bing for \"Bash for Windows\" \n    + Bing returns http://www.howtogeek.com/249966/how-to-install-and-use-the-linux-bash-shell-on-windows-10/\n+ Switch on developer mode for Windows\n+ Turned on Linux Subsystem Beta (searched for \"Turning on Features\")\n+ Reboot\n+ Search for \"Bash\" and clicked on \"Run Bash command\"\n+ Answered \"y\"\n+ Waited for download and extracted file system\n+ When prompted setup developer account with username/password\n    + Documentation can be found at https://aka.ms/wsldocs\n+ Exit root install shell\n+ Search for \"Bash\" locally\n+ Launched \"Bash on Ubuntu on Windows\"\n+ Authenticate with your username/password\n\n\n## Setting up Go under Bash for Windows 10\n\nWith Bash installed these are the steps I took to compile Go\nunder Bash on Ubuntu on Windows.\n\n```shell\n    sudo apt-get update && sudo apt-get upgrade -y\n    sudo apt-get autoremove\n    sudo apt-get install build-essential clang git-core unzip zip -y\n    export CGO_ENABLE=0\n    git clone https://github.com/golang/go go1.4\n    git clone https://github.com/golang/go go\n    cd go1.4\n    git checkout go1.4.3\n    cd src\n    ./all.bash\n    cd\n    export PATH=$PATH:$HOME/go1.4/bin\n    cd go\n    git checkout go1.7\n    cd src\n    ./all.bash\n    cd\n    export PATH=$HOME/go/bin:$HOME/bin:$PATH\n    export GOPATH=$HOME\n```\n\nNote some tests failing during compilation in both 1.4.3 and 1.7. They mostly failed\naround network sockets.  This is probably a result of the limitations in the Linux subsystem\nunder Windows.\n\nIf successful you should be able to run `go version` as well as install additional Go based software\nwith the usual `go get ...` syntax.\n\nIn your `.bashrc` or `.profile` add the following\n\n```shell\n    export PATH=$HOME/go/bin:$HOME/bin:$PATH\n    export GOPATH=$HOME\n```\n\n\n## Improved vim setup\n\nI like the vim-go packages for editing Go code in vim. They are easy to setup.\n\n```shell\n     mkdir -p ~/.vim/autoload ~/.vim/bundle \n     curl -LSso ~/.vim/autoload/pathogen.vim https://tpo.pe/pathogen.vim\n     git clone https://github.com/fatih/vim-go.git ~/.vim/bundle/vim-go\n```\n\nExample $HOME/.vimrc\n\n```vimrc\n    execute pathogen#infect()\n    syntax on\n    filetype plugin on\n    set ai\n    set nu\n    set smartindent\n    set tabstop=4\n    set shiftwidth=4\n    set expandtab\n    let &background = ( &background == \"dark\"? \"light\" : \"dark\" )\n    let g:vim_markdown_folding_disabled=1\n```\n\nColor schemes are browsable at [vimcolors.com](http://vimcolors.com). They can be installed in\n$HOME/.vim/colors.\n\n1. git clone and place the colorscheme\n2. place the *.vim file holding the color scheme into $HOME/.vim/colors\n3. start vim and at the : do colorscheme NAME where NAME is the scheme you want to try\n\nYou can find the default shipped color schemes in /usr/share/vim/vimNN/colors where vimNN is the version number\ne.g. /usr/share/vim/vim74/colors.\n\n\n",
      "data": {
        "author": "rsdoiel@gmail.com (R. S. Doiel)",
        "copyright": "copyright (c) 2016, R. S. Doiel",
        "date": "2016-08-15",
        "keywords": [
          "Golang",
          "Windows",
          "Bash",
          "Linux Subsystem"
        ],
        "license": "https://creativecommons.org/licenses/by-sa/4.0/",
        "title": "Exploring Bash for Windows 10 Pro"
      },
      "url": "posts/2016/08/15/Setting-up-Go-under-Bash-for-Windows-10.json"
    },
    {
      "content": "\n### Recent Posts\n\n- [Rust tools for Web Work](/blog/2024/11/06/rust-tools-for-web-work.md), 2024-11-06\n- [SQLite3 json_patch is a jewel](/blog/2024/10/31/sqlite3_json_patch.md), 2024-10-31\n- [Limit and offset for row pruning](/blog/2024/10/31/limit_and_offset_for_row_pruning.md), 2024-10-31\n- [Quick tour of Deno 2.0.2](/blog/2024/10/18/a-quick-tour-of-deno-2.md), 2024-10-18\n- [Web GUI and Deno](/blog/2024/07/08/webgui_and_deno.md), 2024-07-08\n- [Transpiling with Deno](/blog/2024/07/03/transpiling_with_deno.md), 2024-07-03\n- [Bootstrapping a Text Oriented Web](/blog/2024/06/14/tow_bootstraping.md), 2024-06-14\n- [RISC OS 5.30, GCC 4.7 and Hello World](/blog/2024/06/08/riscos_gcc_and_hello.md), 2024-06-08\n- [Exploring RISC OS 5.30 on a Raspberry Pi Zero W](/blog/2024/06/04/exploring_riscos.md), 2024-06-04\n- [A quick review of Raspberry Pi Connect](/blog/2024/05/10/quick-review-rpi-connect.md), 2024-05-10\n- [Building Lagrange on Raspberry Pi OS](/blog/2024/05/10/building-lagrange-on-pi-os.md), 2024-05-10\n- [Getting Started with Miranda](/blog/2024/04/25/getting-started.md), 2024-04-25\n- [A Text Oriented Web](/blog/2024/02/25/text_oriented_web.md), 2024-02-25\n- [Two missing features from HTML5, an enhanced form.enctype and a list input type](/blog/2024/02/23/enhanced_form_handling.md), 2024-02-23\n- [Installing pgloader from source](/blog/2024/02/01/installing-pgloader-from-source.md), 2024-02-01\n- [vis for vi and fun](/blog/2024/01/31/vis-for-vi-and-fun.md), 2024-01-31\n- [Updated recipe, compiling PostgREST 12.0.2 (M1)](/blog/2024/01/04/updated-recipe-compiling-postgrest_v12.0.2.md), 2024-01-04\n\n2023\n----\n\n - 12-23, [Finding Bluesky RSS feeds](/blog/2023/12/23/finding-blue-sky-rss-feeds.md)\n - 12-07, [RSS and my web experience](/blog/2023/12/07/rss-and-my-web-experience.md)\n - 11-17, [Postgres Quick Notes, take two](/blog/2023/11/17/PostgreSQL-Quick-Notes.md)\n - 10-18, [Building A to Z list pages in Pandoc](/blog/2023/10/18/A-to-Z-lists.md)\n - 10-06, [Skimmer](/blog/2023/10/06/concept.md)\n - 07-05, [Quick recipe, compiling PostgREST (M1)](/blog/2023/07/05/quick-recipe-compiling-PostgREST-M1.md)\n - 07-05, [Quick recipe, compiling Pandoc (M1)](/blog/2023/07/05/quick-recipe-compiling-Pandoc-M1.md)\n - 05-20, [gsettings command](/blog/2023/05/20/gsettings-commands.md)\n - 03-10, [First Personal Search Engine Prototype](/blog/2023/03/10/first-prototype-pse.md)\n - 03-07, [Prototyping a personal search engine](/blog/2023/03/07/prototyping-a-personal-search-engine.md)\n - 01-03, [SQL query to CSV, a missing datatool](/blog/2023/01/03/sql-to-csv-a-missing-datatool.md)\n\n2022\n----\n\n - 12-12, [Go and MySQL timestamps](/blog/2022/12/12/Go-and-MySQL-Timestamps.md)\n - 12-05, [Progress and time remaining](/blog/2022/12/05/progress-and-time-remaining.md)\n - 11-28, [Pandoc, Pagefind and Make](/blog/2022/11/28/pandoc-pagefind-and-make.md)\n - 11-21, [Initial Impressions of Pagefind](/blog/2022/11/21/initial-impressions-pagefind.md)\n - 11-18, [Browser based site search](/blog/2022/11/18/browser-side-site-search.md)\n - 11-17, [Revealing the Pandoc AST](/blog/2022/11/17/revealing-pandoc-ast.md)\n - 11-11, [Twitter's pending implosion](/blog/2022/11/11/Twitter-implosion.md)\n - 11-07, [Compiling Pandoc from source](/blog/2022/11/07/compiling-pandoc-from-source.md)\n - 11-01, [Installing Cargo/Rust on Raspberry Pi 400](/blog/2022/11/01/installing-cargo-rust-r400.md)\n - 11-01, [feeds, formats and plain text](/blog/2022/11/01/Feeds-formats-and-plain-text.md)\n - 10-18, [7:30 AM, Oberon Language: A minimum SYSTEM module](/blog/2022/10/18/Wishlist-Oberon-in-2023-2022-10-18_070730.md)\n - 10-16, [Wish list for Oberon in 2023](/blog/2022/10/16/Wishlist-Oberon-in-2023.md)\n - 10-10, [7:30 AM, Gopher: Setup](/blog/2022/10/10/getting-things-setup-2022-10-10_070730.md)\n - 10-09, [Getting things setup](/blog/2022/10/09/getting-things-setup.md)\n - 09-28, [Thinking about Gopher](/blog/2022/09/28/thinking-about-gopher.md)\n - 09-27, [Rust development notes](/blog/2022/09/27/rust-development-notes.md)\n - 09-26, [7:30 AM, Golang: pttk](/blog/2022/09/26/golang-development-2022-09-26_070730.md)\n - 09-19, [12:30 PM, SQL: Postgres](/blog/2022/09/19/rosette-notes-2022-09-19_121230.md)\n - 09-19, [PostgreSQL dump and restore](/blog/2022/09/19/PostgreSQL-Dump-and-Restore.md)\n - 08-30, [Ordering front matter](/blog/2022/08/30/Ordering-Frontmatter.md)\n - 08-26, [10:30 AM, SQL: Postgres](/blog/2022/08/26/rosette-notes-2022-08-26_101030.md)\n - 08-26, [Postgres 14 on Ubuntu 22.04 LTS](/blog/2022/08/26/postgres-14-on-ubuntu-22.04-LTS.md)\n - 08-24, [12:00 PM, SQL: Postgres](/blog/2022/08/24/rosette-notes-2022-08-24_121200.md)\n - 08-24, [A Quick into to PL/pgSQL](/blog/2022/08/24/plpgsql-quick-intro.md)\n - 08-22, [11:30 AM, SQL: Postgres](/blog/2022/08/22/rosette-notes-2022-08-22_111130.md)\n - 08-19, [Rosette Notes: Postgres and MySQL](/blog/2022/08/19/rosette-notes.md)\n - 08-15, [PTTK and STN](/blog/2022/08/15/golang-development.md)\n - 08-15, [5:45 PM, Golang: ptdk,  stngo](/blog/2022/08/15/golang-development-2022-08-15_170545.md)\n - 08-14, [5:00 PM, Golang: pdtk,  stngo](/blog/2022/08/14/golang-development-2022-08-14_170500.md)\n - 08-12, [4:30 PM, Golang: stngo](/blog/2022/08/12/golang-development-2022-08-12_160430.md)\n - 07-30, [Turbo Oberon, the dream](/blog/2022/07/30/Turbo-Oberon.md)\n - 07-27, [Artemis Project Status, 2022](/blog/2022/07/27/Artemis-Status-Summer-2022.md)\n - 02-18, [Installing Golang from source on RPi-OS for arm64](/blog/2022/02/18/Installing-Go-from-Source-RPiOS-arm64.md)\n\n2021\n----\n\n - 12-18, [Notes on setting up a Mid-2010 Mac Mini](/blog/2021/12/18/Notes-on-setting-up-a-2010-Mac-Mini.md)\n - 11-27, [Setting up FreeDOS 1.3rc4 with Qemu](/blog/2021/11/27/FreeDOS-1.3rc4-with-Qemu.md)\n - 11-26, [Portable Conversions (Integers)](/blog/2021/11/26/Portable-Conversions-Integers.md)\n - 11-22, [Revisiting Files](/blog/2021/11/22/Revisiting-Files.md)\n - 06-14, [Combining Oberon-07 with C using Obc-3](/blog/2021/06/14/Combining-Oberon-07-with-C-using-Obc-3.md)\n - 05-16, [Beyond Oakwood, Modules and Aliases](/blog/2021/05/16/Beyond-Oakwood-Modules-and-Aliases.md)\n - 04-25, [Ofront on Raspberry Pi OS](/blog/2021/04/25/Ofront-on-Rasberry-Pi-OS.md)\n - 04-16, [Updating Schema in SQLite3](/blog/2021/04/16/Updating-Schema-in-SQLite3.md)\n - 04-02, [A2 Oberon on VirtualBox 6.1](/blog/2021/04/02/A2-Oberon-on-VirtualBox-6.1.md)\n - 03-17, [ETH Oberon System 3 on VirtualBox 6.1](/blog/2021/03/17/NativeOberon-VirtualBox.md)\n\n2020\n----\n\n - 12-24, [RetroFlag GPi Case Setup](/blog/2020/12/24/gpi-case-setup.md)\n - 11-27, [Dates](/blog/2020/11/27/Dates.md)\n - 11-27, [Dates & Clock](/blog/2020/11/27/Dates-and-Clock.md)\n - 11-27, [Clock](/blog/2020/11/27/Clock.md)\n - 11-27, [Chars](/blog/2020/11/27/Chars.md)\n - 11-11, [Pandoc & Metadata](/blog/2020/11/11/Pandoc-Metadata.md)\n - 11-09, [Pandoc Partials](/blog/2020/11/09/Pandoc-Partials.md)\n - 10-31, [Software Tools, Filters](/blog/2020/10/31/Filters.md)\n - 10-19, [Assembling Pages](/blog/2020/10/19/Assemble-pages.md)\n - 10-03, [Oberon to Markdown](/blog/2020/10/03/Oberon-to-markdown.md)\n - 09-29, [Software Tools, Getting Started](/blog/2020/09/29/Software-Tools-1.md)\n - 08-15, [Portable Oberon-07](/blog/2020/08/15/Portable-Oberon-07.md)\n - 07-08, [Words Matter](/blog/2020/07/08/words-matter.md)\n - 07-07, [Procedures in records](/blog/2020/07/07/Procedures-in-records.md)\n - 06-20, [Procedures as parameters](/blog/2020/06/20/Procedures-as-parameters.md)\n - 05-25, [Dynamic types](/blog/2020/05/25/Dynamic-types.md)\n - 05-09, [Oberon-07 and the file system](/blog/2020/05/09/Oberon-07-and-the-filesystem.md)\n - 05-06, [Compiling OBNC on macOS](/blog/2020/05/06/Compiling-OBNC-on-macOS.md)\n - 05-01, [Combining Oberon-07 and C with OBNC](/blog/2020/05/01/Combining-Oberon-and-C.md)\n - 04-19, [Oberon Loops and Conditions](/blog/2020/04/19/Mostly-Oberon-Loops-and-Conditions.md)\n - 04-18, [Oberon Basic Types](/blog/2020/04/18/Mostly-Oberon-Basic-Types.md)\n - 04-12, [Oberon Modules and Procedures](/blog/2020/04/12/Mostly-Oberon-Modules.md)\n - 04-11, [Mostly Oberon](/blog/2020/04/11/Mostly-Oberon.md)\n\n2019\n----\n\n - 07-28, [FreeDOS 1.2 to Oberon System 3](/blog/2019/07/28/freedos-to-oberon-system-3.md)\n\n2018\n----\n\n - 07-22, [Review: Software Tools in Pascal](/blog/2018/07/22/software-tools-in-pascal.md)\n - 03-11, [Accessing Go from Julia](/blog/2018/03/11/accessing-go-from-julia.md)\n - 02-24, [Go based Python modules](/blog/2018/02/24/go-based-python-modules.md)\n - 02-19, [Go, Bleve and Library oriented software](/blog/2018/02/19/go-bleve-and-libraries.md)\n\n2017\n----\n\n - 12-18, [Raspbian Stretch on DELL E4310 Laptop](/blog/2017/12/18/raspbian-stretch-on-amd64.md)\n - 12-10, [Harvesting my Gists from GitHub](/blog/2017/12/10/harvesting-my-gists-from-github.md)\n - 10-20, [NodeJS, NPM, Electron](/blog/2017/10/20/node-npm-electron.md)\n - 06-16, [Cross compiling Go 1.8.3 for Pine64 Pinebook](/blog/2017/06/16/cross-compiling-go.md)\n\n2016\n----\n\n - 09-20, [Android, Termux and Dev Environment](/blog/2016/09/20/Android-Termux-Dev-environment.md)\n - 08-16, [From Markdown and Bash to mkpage](/blog/2016/08/16/From-Markdown-and-Bash-to-mkpage.md)\n - 08-15, [Exploring Bash for Windows 10 Pro](/blog/2016/08/15/Setting-up-Go-under-Bash-for-Windows-10.md)\n - 07-04, [How to make a Pi-Top more Raspbian](/blog/2016/07/04/How-To-Make-A-PiTop-More-Raspbian.md)\n - 05-30, [Instant Articles, Accelerated Mobile Pages, Twitter Cards and Open Graph](/blog/2016/05/30/amp-cards-and-open-graph.md)\n - 05-28, [OPML to Markdown and back](/blog/2016/05/28/OPML-to-Markdown-and-back.md)\n\n",
      "data": {
        "title": "Robert's ramblings"
      },
      "url": "posts/index.json"
    }
  ]
}