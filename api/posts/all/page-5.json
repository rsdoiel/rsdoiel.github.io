{
  "page": 5,
  "total_pages": 5,
  "has_more": false,
  "next_page": null,
  "values": [
    {
      "content": "\n\n# Accessing Go from Julia\n\nBy R. S. Doiel, 2018-03-11\n\nThe problem: I've started exploring Julia and I would like to leverage existing\ncode I've written in Go. Essentially this is a revisit to the problem in my\nlast post [Go based Python Modules](https://rsdoiel.github.io/blog/2018/02/24/go-based-python-modules.html) \nbut with the language pairing of Go and Julia.\n\n\n## Example 1, libtwice.go, libtwice.jl and libtwice_test.jl\n\nIn out first example we send an integer value from\nJulia to Go and back via a C shared library (written in Go). While Julia doesn't\nrequire type declarations I will be using those for clarity. Like in my previous post\nI think this implementation this is a good starting point to see how Julia interacts with\nC shared libraries. Like before I will present our Go code, an explanation \nfollowed by the Julia code and commentary.\n\nOn the Go side we create a _libtwice.go_ file with an empty `main()` \nfunction.  Notice that we also import the *C* package and use \na comment decoration to indicate the function we are exporting\n(see https://github.com/golang/go/wiki/cgo and \nhttps://golang.org/cmd/cgo/\nfor full story about Go's _C_ package and _cgo_).\nPart of the what _cgo_ and the *C* package does is use the \ncomment decoration to build the signatures for the function calls\nin the shared C library.  The Go toolchain does all the heavy \nlifting in making a *C* shared library based on comment \ndirectives like \"//export\". We don't need much for our twice\nfunction.\n\n```Go\n    package main\n    \n    import (\n    \t\"C\"\n    )\n    \n    //export twice\n    func twice(i int) int {\n    \treturn i * 2\n    }\n    \n    func main() {}\n```\n\nLike in our previous Python implementation we need to build the C shared\nlibrary before using it from Julia. Here are some example Go build commands\nfor Linux, Windows and Mac OS X. You only need to run the one that applies\nto your operating system.\n\n```shell\n    go build -buildmode=c-shared -o libtwice.so libtwice.go\n    go build -buildmode=c-shared -o libtwice.dll libtwice.go\n    go build -buildmode=c-shared -o libtwice.dynlib libtwice.go\n```\n\nUnlike the Python implementation our Julia code will be split into two files. _libtwice.jl_ will\nhold our module definition and _libtwice_test.jl_ will hold our test code. In the\ncase of _libtwice.jl_ we will access the C exported function via a function named *ccall*. \nJulia doesn't require a separate module to be imported in order to access a C shared library.\nThat makes our module much simpler. We still need to be mindful of type conversion.  Both \nGo and Julia provide for rich data types and structs.  But between Go and Julia we have C \nand C's basic type system.  On the Julia side *ccall* and Julia's type system help us\nmanaging C's limitations.\n\nHere's the Julia module we'll call _libtwice.jl_.\n\n```Julia\n    module libtwice\n            \n    # We write our Julia idiomatic function\n    function twice(i::Integer)\n        ccall((:twice, \"./libtwice\"), Int32, (Int32,), i)\n    end\n\n    end\n```\n\nWe're will put the test code in a file named _libtwice\\_test.jl_. Since this isn't\nan establish \"Package\" in Julia we will use Julia's *include* statement to get bring the\ncode in then use an *import* statement to bring the module into our current name space.\n\n```Julia\n    include(\"libtwice.jl\")\n    import libtwice\n    # We run this test code for libtwice.jl\n    println(\"Twice of 2 is \", libtwice.twice(2))\n```\n\nOur test code can be run with\n\n```shell\n    julia libtwice_test.jl\n```\n\nNotice the amount of lifting that Julia's *ccall* does. The Julia code is much more compact\nas a result of not having to map values in a variable declaration. We still have the challenges \nthat Julia and Go both support richer types than C. In a practical case we should consider \nthe over head of running to two runtimes (Go's and Julia's) as well as whether or not \nimplementing as a shared library even makes sense. But if you want to leverage existing \nGo based code this approach can be useful.\n\nExample 1 is our base recipe. The next examples focus on handling\nother data types but follow the same pattern.\n\n\n## Example 2, libsayhi.go, libsayhi.jl and libsayhi_test.jl\n\nLike Python, passing strings passing to or from Julia and Go is nuanced. Go is expecting \nUTF-8 strings. Julia also supports UTF-8 but C still looks at strings as a pointer to an\naddress space that ends in a null value. Fortunately in Julia the *ccall* function combined with\nJulia's rich type system gives us straight forward ways to map those value. \nGo code remains unchanged from our Python example in the previous post. \nIn this example we use Go's *fmt* package to display the string. In the next example\nwe will round trip our string message.\n\n```go\n    package main\n    \n    import (\n    \t\"C\"\n    \t\"fmt\"\n    )\n    \n    //export say_hi\n    func say_hi(msg *C.char) {\n    \tfmt.Println(C.GoString(msg))\n    }\n    \n    func main() { }\n```\n\nThe Go source is the similar to our first recipe. No change from our\nprevious posts' Python example. It will need to be compiled to create our\nC shared library just as before. Run the go build line that applies to\nyour operating system (i.e., Linux, Windows and Mac OS X).\n\n```shell\n    go build -buildmode=c-shared -o libsayhi.so libsayhi.go\n    go build -buildmode=c-shared -o libsayhi.dll libsayhi.go\n    go build -buildmode=c-shared -o libsayhi.dylib libsayhi.go\n```\n\nOur Julia module looks like this.\n\n```julia\n    module libsayhi\n\n    # Now write our Julia idiomatic function using *ccall* to access the shared library\n    function say_hi(txt::AbstractString)\n        ccall((:say_hi, \"./libsayhi\"), Int32, (Cstring,), txt)\n    end\n\n    end\n```\n\nThis code is much more compact than our Python implementation.\n\nOur test code looks like\n\n```julia\n    include(\"./libsayhi.jl\")\n    import libsayhi\n    libsayhi.say_hi(\"Hello again!\")\n```\n\nWe run our tests with\n\n```shell\n    julia libsayhi_test.jl\n```\n\n\n## Example 3, libhelloworld.go and librhelloworld.cl and libhelloworld_test.jl\n\nIn this example we send a string round trip between Julia and Go. \nMost of the boiler plate we say in Python is gone due to Julia's type system. In\naddition to using Julia's *ccall* we'll add a *convert* and *bytestring* function calls\nto bring our __Cstring__ back to a __UTF8String__ in Julia.\n\nThe Go implementation remains unchanged from our previous Go/Python implementation. \nThe heavy lifting is done by the *C* package and the comment \n`//export`. We are using `C.GoString()` and `C.CString()` to flip between \nour native\nGo and C datatypes.\n\n```go\n    package main\n    \n    import (\n    \t\"C\"\n    \t\"fmt\"\n    )\n    \n    //export helloworld\n    func helloworld(name *C.char) *C.char {\n    \ttxt := fmt.Sprintf(\"Hello %s\", C.GoString(name))\n    \treturn C.CString(txt)\n    }\n    \n    func main() { }\n```\n\nAs always we must build our C shared library from the Go code. Below is\nthe go build commands for Linux, Windows and Mac OS X. Pick the line that\napplies to your operating system to build the C shared library.\n\n```shell\n    go build -buildmode=c-shared -o libhelloworld.so libhelloworld.go\n    go build -buildmode=c-shared -o libhelloworld.dll libhelloworld.go\n    go build -buildmode=c-shared -o libhelloworld.dylib libhelloworld.go\n```\n\nIn our Julia, _libhelloworld.jl_, the heavy lifting of type conversion\nhappens in Julia's type system and in the *ccall* function call. Additionally we need\nto handle the conversion from __Cstring__ Julian type to __UTF8String__ explicitly\nin our return value via a functions named *convert* and *bytestring*.\n\n```julia\n    module libhelloworld\n\n    # Now write our Julia idiomatic function\n    function helloworld(txt::AbstractString)\n        value = ccall((:helloworld, \"./libhelloworld\"), Cstring, (Cstring,), txt)\n        convert(UTF8String, bytestring(value))\n    end\n\n    end\n```\n\nOur test code looks similar to our Python test implementation.\n\n```julia\n    include(\"libhelloworld.jl\")\n    import libhelloworld\n \n    if length(ARGS) > 0\n        println(libhelloworld.helloworld(join(ARGS, \" \")))\n    else\n        println(libhelloworld.helloworld(\"World\"))\n    end\n```\n\nAs before we see the Julia code is much more compact than Python's.\n\n\n## Example 4, libjsonpretty.go, libjsonpretty.jl and libjsonpretty_test.jl\n\nIn this example we send JSON encode text to the Go package,\nunpack it in Go's runtime and repack it using the `MarshalIndent()`\nfunction in Go's JSON package before sending it back to Julia\nin C string form.  You'll see the same encode/decode patterns as \nin our *libhelloworld* example.\n\nGo code\n\n```go\n    package main\n    \n    import (\n    \t\"C\"\n    \t\"encoding/json\"\n    \t\"fmt\"\n    \t\"log\"\n    )\n    \n    //export jsonpretty\n    func jsonpretty(rawSrc *C.char) *C.char {\n    \tdata := new(map[string]interface{})\n    \terr := json.Unmarshal([]byte(C.GoString(rawSrc)), &data)\n    \tif err != nil {\n    \t\tlog.Printf(\"%s\", err)\n    \t\treturn C.CString(\"\")\n    \t}\n    \tsrc, err := json.MarshalIndent(data, \"\", \"    \")\n    \tif err != nil {\n    \t\tlog.Printf(\"%s\", err)\n    \t\treturn C.CString(\"\")\n    \t}\n    \ttxt := fmt.Sprintf(\"%s\", src)\n    \treturn C.CString(txt)\n    }\n    \n    func main() {}\n```\n\nBuild commands for Linux, Windows and Mac OS X are as before, pick the one that matches\nyour operating system.\n\n```shell\n    go build -buildmode=c-shared -o libjsonpretty.so libjsonpretty.go\n    go build -buildmode=c-shared -o libjsonpretty.dll libjsonpretty.go\n    go build -buildmode=c-shared -o libjsonpretty.dylib libjsonpretty.go\n```\n\nOur Julia module code\n\n```Julia\n    module libjsonpretty\n\n    # Now write our Julia idiomatic function\n    function jsonpretty(txt::AbstractString)\n        value = ccall((:jsonpretty, \"./libjsonpretty\"), Cstring, (Cstring,), txt)\n        convert(UTF8String, bytestring(value))\n    end\n    \n    end\n```\n\nOur Julia test code\n\n```Julia\n    include(\"./libjsonpretty.jl\")\n    import libjsonpretty\n\n    src = \"\"\"{\"name\":\"fred\",\"age\":25,\"height\":75,\"units\":\"inch\",\"weight\":\"239\"}\"\"\"\n    println(\"Our origin JSON src\", src)\n    value = libjsonpretty.jsonpretty(src)\n    println(\"And out pretty version\\n\", value)\n```\n\nAs before you can run your tests with `julia libjsonpretty_test.jl`.\n\nIn closing I would like to note that to use these examples I am assuming your\nJulia code is in the same directory as your shared C library. Julia, like Python3,\nhas a feature rich module and Package system. If you are creating a serious Julia\nproject then you need to be familiar with how Julia's package and module system works\nand place your code and shared libraries appropriately.\n\n\n",
      "data": {
        "author": "rsdoiel@gmail.com (R. S. Doiel)",
        "copyright": "copyright (c) 2018, R. S. Doiel",
        "date": "2018-03-11",
        "keywords": [
          "Golang",
          "Julia",
          "shared libraries"
        ],
        "license": "https://creativecommons.org/licenses/by-sa/4.0/",
        "title": "Accessing Go from Julia"
      },
      "url": "posts/2018/03/11/accessing-go-from-julia.json"
    },
    {
      "content": "\n\n# Go, Bleve and Library oriented software\n\nBy R. S. Doiel, 2018-02-19\n(updated: 2018-02-22)\n\nIn 2016, Stephen Davison, asked me, \"Why use Go and Blevesearch for\nour library projects?\" After our conversation I wrote up some notes so\nI would remember. It is now 2018 and I am revising these notes. I\nthink our choice paid off.  What follows is the current state of my\nreflection on the background, rational, concerns, and risk mitigation\nstrategies so far for using [Go](https://golang.org) and\n[Blevesearch](https://blevesearch.com) for Caltech Library projects.\n\n## Background\n\nI first came across Go a few years back when it was announced as an\nOpen Source project by Google at an Google I/O event (2012). The\noriginal Go authors were Robert Griesemer, Rob Pike, and Ken\nThompson. What I remember from that presentation was Go was a rather\nconsistent language with the features you need but little else.  Go\ndeveloped at Google as a response to high development costs for C/C++\nand Java in addition to challenges with performance and slow\ncompilation times.  As a language I would put Go between C/C++ and\nJava. It comes the ease of writing and reading you find in languages\nlike Python. Syntax is firmly in the C/C++ family but heavily\nsimplified. Like Java it provides many modern features including rich basic\ndata structures and garbage collection. It has a very complete standard\nlibrary and provides very good tooling.  This makes it easy to\ngenerate code level documentation, format code, test, efficiently profile, \nand debug.\n\nOften programming languages develop around a specific set of needs.\nThis is true for Go. Given the Google origin it should not be\nsurprising to find that Go's primary strengths are working with \nstructured data, I/O and concurrency. The rich standard\nlibrary is organized around a package concept. These include packages\nsupporting network protocols, file and socket I/O as well as various\nencoding and compression scheme. It has particularly strong support\nfor XML, JSON, CSV formatted data out of the box. It has a template\nlibrary for working with plain text formats as well as generating safe\nHTML. You can browse Go's standard library https://golang.org/pkg/.\n\nAn additional feature is Go's consistency. Go code that compiles under\nversion 1.0 still compiles under 1.10. Even before 1.0 code changes\nthat were breaking came with tooling to automatically updates existing\ncode.  Running code is a strong element of Go's evolution.\n\nGo is unsurprising and has even been called boring.  This turns out to\nbe a strength when building sustainable projects in a small team.\n\n\n## Why do I write Go?\n\nFor me Go is a good way to write web services, assemble websites,\ncreate search appliances and write command line (cli) utilities. When\na shell script becomes unwieldy Go is often what I turn to.  Go is\nwell suited to building tools as well as systems.  Go based command\nline tools are very easy to orchestrate with shell and Python.\n\nGo runs on all the platforms I actively use - Windows, Mac OS X, Linux\non both Intel and ARM (e.g. Raspberry Pi, Pine64). It has experimental\nsupport for Android and iOS.  I've used a tool called\n[GopherJS](http://gopherjs.org) to write web browser applications that\ntransform my command line tools into web tools with a friendlier user\ninterface (see our [BibTeX Tools](https://caltechlibrary.github.io/bibtex/webapp/)).\n\nGo supports cross compiling out of the box. This means a production\nsystem running on AWS, Google's compute engine or Microsoft's Azure\ncan be compiled from Windows, Mac OS or even a Raspberry Pi!\nDeployment is a matter of copying the (self contained) compiled binary\nonto the production system. This contrasts with other\nplatforms like Perl, PHP, Python, NodeJS and Ruby where you need to\ninstall not only your application code but all dependencies. While\ninterpretive languages retain an advantage of having a REPL, Go\nbased programs have advantages of fast compile times and easy deployment.\n\nIn many of the projects I've written in Go I've only required a few\n(if any) 3rd party libraries (packages in Go's nomenclature). This is\nquite a bit different from my experience with Perl, PHP, Python,\nNodeJS and Ruby. This is in large part a legacy of having grown up at\nGoogle before become an open source project. While the Go standard\npackages are very good there is a rich ecosystem for 3rd party\npackages for specialized needs. I've found I tend to rely only on a\nfew of them. The one I've used the most is\n[Bleve](http://blevesearch.com).\n\nBleve is a Go package for building search engines. When I originally\ncame across Bleve (around 2014), it was described as \"Lucene lite\". \n\"Lucene lite\" was an apt description, but I find it easier\nto use than Lucene. When I first used Bleve I embedded its\nfunctionality into the tools I used to process data and present web\nservices. It did not have much in the way of stand alone command line\ntooling.  Today I increasingly think of Bleve as \"Elastic Search\nlite\". It ships with a set of command line tools that include support\nfor building Bleve's indexes.  My current practice is to only embed the search\nportion of the packages. I can use the Bleve command line for the\nrest.  In 2018, Bleve is being actively developed, has a small vibrant\ncommunity and is used by [Couchbase](https://couchbase.com), a well\nestablished NoSQL player.\n\n\n## Who is using Go?\n\nMany companies use Go. The short list includes\nGoogle, Amazon, Netflix, Dropbox, Box, eBay, Pearsons and even\nWalmart and Microsoft. This came to my attention at developer conferences\nback in 2014.  People from many of these companies started\npresenting at conferences on pilot projects that had been successful\nand moved to production. Part of what drove adoption was the ease\nof development in Go along with good system performance. I also think\nthere was a growing disenchantment with alternatives like C++, C sharp\nand Java as well as the weight of the LAMP, Tomcat, and OpenStack.\n\nHighly visible Go based projects include\n\n+ [Docker](http://docker.org) and [Rocket](http://www.docker.com) - Containerization for running process in the cloud\n+ [Kubernettes](http://kubernetes.io/) and [Terraform](https://www.terraform.io/) - Container orchestration systems\n+ [Hugo](http://hugo.io) - the fast/popular static website generator, an alternative to Jekyll, for those who want speed\n+ [Caddy](https://caddyserver.com/) - a Go based web server trying to unseat Apache/NGinX focusing on easy of use plus speed\n+ [IPFS](http://ipfs.io) - a cutting edge distributed storage system based on block chains\n\n\n### Who is using Blevesearch?\n\nHere's some larger projects using Bleve.\n\n+ [Couchbase](http://www.couchbase.com), a NoSQL database platform are replacing Lucene with Bleve.  Currently the creator of Bleve works for them.\n+ [Hugo](http://hugo.io) can integrate with Bleve for search and index generation\n+ [Caddy](https://caddyserver.com/) integrates with Bleve to provide an embedded search capability\n\n\n## Managing risks\n\nIn 2014 Go was moving from bleeding to leading edge. Serious capital\nwas behind its adoption and it stopped being an exotic conference\nitem. In 2014 Bleve was definitely bleeding edge. By late 2015 and early\n2016 the program level API stabilized. People were piloting projects\nwith it. This included our small group at Caltech Library. In 2015\nnon-English language support appeared followed by a growing list\nof non-European languages in 2016. By mid 2016 we started to see \nmissing features like alternative sorting added. While Bleve isn't\nyet 1.0 (Feb. 2018) it is reliable. The primary challenge for the Bleve\nproject is documentation targeting the novice and non-Programmer users.\nBleve has proven effective as an indexing and search platform for \narchival, library, and data repository content.\n\nAdopting new software comes with risk. We have mitigated this in two ways.\n\n1. Identify alternative technology (a plan B)\n2. Architect our systems for easy decomposition and re-composition\n\nIn the case of Go, packages can be compiled to a C-Shared\nlibrary. This allows us to share working Go packages with languages\nlike Python, R, and PHP. We have included shared Go/Python modules\non our current road map for projects.\n\nFor Blevesearch the two alternatives are Solr and Elastic\nSearch. Both are well known, documented, and solid.  The costs would be\nrecommitting to a Java stack and its resource requirements. We have\nalready identified what we want to index and that could be converted\nto either platform if needed.  If we stick with Go but dropped \nBlevesearch we would swap out the Bleve specific code for Go packages \nsupporting Solr and Elastic Search.\n\n\nThe greatest risk in adopting Go for library and archive projects was \nknowledge transfer. We addressed this \nby knowledge sharing and insuring the Go codebase can \nbe used via command line programs.  Additionally \nwe are adding support for Go based Python modules.\nTraining also is available in the form of books, websites and\nonline courses ([lynda.com](https://www.lynda.com/Go-tutorials/Up-Running-Go/412378-2.html) offers a \"Up Running Go\" course).\n\n\n## What are the benefits?\n\nFor library and archives software we have found Go's benefits include\nimproved back end systems performance at a lower cost, ease of development, \nease of deployment, a rich standard library focused on the types of things \nneeded in library and archival software.  Go plays nice with\nother systems (e.g. I create an API based service in Go that can easily\nbe consumed by a web browser running JavaScript or Perl/PHP/Python\ncode running under LAMP). In the library and archives setting Go \ncan become a high performance duck tape. We get the performance and \nreliability of C/Java type systems with code simplicity \nsimilar to Python.\n",
      "data": {
        "author": "rsdoiel@gmail.com (R. S. Doiel)",
        "copyright": "copyright (c) 2018, R. S. Doiel",
        "date": "2018-02-19",
        "keywords": [
          "Golang",
          "Bleve",
          "search"
        ],
        "license": "https://creativecommons.org/licenses/by-sa/4.0/",
        "title": "Go, Bleve and Library oriented software"
      },
      "url": "posts/2018/02/19/go-bleve-and-libraries.json"
    },
    {
      "content": "\n\n# Go based Python modules\n\nBy R. S. Doiel, 2018-02-24\n\nThe problem: I have written a number of Go packages at work.\nMy colleagues know Python and I'd like them to be able to use the\npackages without resorting to system calls from Python to the\ncommand line implementations. The solution is create a C-Shared\nlibrary from my Go packages, using Go's _C_ package and combine it\nwith Python's _ctypes_ package.  What follows is a series of \nsimple recipes I used to understand the details of how that worked.\n\n\n## Example 1, libtwice.go and twice.py\n\nMany of the the examples I've come across on the web start by \nshowing how to run a simple math operation on the Go side with\nnumeric values traveling round trip via the C shared library layer. \nIt is a good place to start as you only need to consider type \nconversion between both Python's runtime and Go's runtime.  It \nprovides a simple illustration of how the Go *C* package, Python's\n*ctypes* module and the toolchain work together.\n\nIn this example we have a function in Go called \"twice\" it takes\na single integer, doubles it and returns the new value.  On\nthe Go side we create a _libtwice.go_ file with an empty `main()` \nfunction.  Notice that we also import the *C* package and use \na comment decoration to indicate the function we are exporting\n(see https://github.com/golang/go/wiki/cgo and \nhttps://golang.org/cmd/cgo/\nfor full story about Go's _C_ package and _cgo_).\nPart of the what _cgo_ and the *C* package does is use the \ncomment decoration to build the signatures for the function calls\nin the shared C library.  The Go toolchain does all the heavy \nlifting in making a *C* shared library based on comment \ndirectives like \"//export\". We don't need much for our twice\nfunction.\n\n```Go\n    package main\n    \n    import (\n    \t\"C\"\n    )\n    \n    //export twice\n    func twice(i int) int {\n    \treturn i * 2\n    }\n    \n    func main() {}\n```\n\nOn the python side we need to wrap our calls to our shared library\nbringing them into the Python runtime in a useful and idiomatically\nPython way. Python provides a few ways of doing this. In my examples\nI am using the *ctypes* package.  _twice.py_ looks like this--\n\n```python\n    import ctypes\n    import os\n    \n    # Set our shared library's name\n    lib_name='libtwice'\n    \n    # Figure out shared library extension\n    uname = os.uname().sysname\n    ext = '.so'\n    if uname == 'Darwin':\n        ext = '.dylib'\n    if uname == 'Windows':\n        ext = '.dll'\n    \n    # Find our shared library and load it\n    dir_path = os.path.dirname(os.path.realpath(__file__))\n    lib = ctypes.cdll.LoadLibrary(os.path.join(dir_path, lib_name+ext))\n    \n    # Setup our Go functions to be nicely wrapped\n    go_twice = lib.twice\n    go_twice.argtypes = [ctypes.c_int]\n    go_twice.restype = ctypes.c_int\n    \n    # Now write our Python idiomatic function\n    def twice(i):\n        return go_twice(ctypes.c_int(i))\n    \n    # We run this test code if with: python3 twice.py\n    if __name__ == '__main__':\n        print(\"Twice of 2 is\", twice(2))\n```\n\nNotice the amount of lifting Python's *ctypes* does for us. It provides\nfor converting C based types to their Python counter parts. Indeed the\nadditional Python source here is focused around using that functionality\nto create a simple Python function called twice. This pattern of \nbringing in a low level version of our desired function and then \npresenting in a Pythonic one is common in more complex C based Python\nmodules.  In general we need *ctypes* to access and wrapping our \nshared library. The *os* module is used so we can find our C \nshared library based on the naming conventions of our host OS. \nFor simplicity I've kept the shared library (e.g. _libtwice.so_ \nunder Linux) in the same directory as the python module \ncode _twice.py_.\n\nThe build command for Linux looks like---\n\n```shell\n    go build -buildmode=c-shared -o libtwice.so libtwice.go\n```\n\nUnder Windows it would look like---\n\n```shell\n    go build -buildmode=c-shared -o libtwice.dll libtwice.go\n```\n\nand Mac OS X---\n\n```shell\n    go build -buildmode=c-shared -o libtwice.dynlib libtwice.go\n```\n\nYou can test the Python module with---\n\n```shell\n    python3 twice.py\n```\n\nNotice the filename choices. I could have called the Go shared\nlibrary anything as long as it wasn't called `twice.so`, `twice.dll`\nor `twice.dylib`. This constraint is to avoid a module name collision\nin Python.  If we had a Python script named `twice_test.py` and \nimport `twice.py` then Python needs to make a distinction between\n`twice.py` and our shared library. If you use a Python package\napproach to wrapping the shared library you would have other options\nfor voiding name collision.\n\nHere is an example of `twice_test.py` to make sure out import is\nworking.\n\n```python\n    import twice\n    print(\"Twice 3\", twice.twice(3))\n```\n\nExample 1 is our base recipe. The next examples focus on handling\nother data types but follow the same pattern.\n\n\n## Example 2, libsayhi.go and sayhi.py\n\nI found working with strings a little more nuanced. Go's concept of\nstrings are oriented to utf-8. Python has its own concept of strings \nand encoding.  Both need to pass through the C layer which assumes \nstrings are a char pointer pointing at contiguous memory ending \nin a null. The *sayhi* recipe is focused on moving a string from \nPython, to C, to Go (a one way trip this time). The example uses \nGo's *fmt* package to display the string. \n\n```go\n    package main\n    \n    import (\n    \t\"C\"\n    \t\"fmt\"\n    )\n    \n    //export say_hi\n    func say_hi(msg *C.char) {\n    \tfmt.Println(C.GoString(msg))\n    }\n    \n    func main() { }\n```\n\nThe Go source is similar to our first recipe but our Python modules\nneeds to use *ctypes* to get you Python string into shape to be\nunpacked by Go.\n\n```python\n   import ctypes\n   import os\n   \n   # Set the name of our shared library\n   lib_name = 'libsayhi'\n\n   # Figure out shared library extension\n   uname = os.uname().sysname\n   ext = '.so'\n   if uname == 'Darwin':\n       ext = '.dylib'\n   if uname == 'Windows':\n       ext = '.dll'\n   \n   # Find our shared library and load it\n   dir_path = os.path.dirname(os.path.realpath(__file__))\n   lib = ctypes.cdll.LoadLibrary(os.path.join(dir_path, lib_name+ext))\n   \n   # Setup our Go functions to be nicely wrapped\n   go_say_hi = lib.say_hi\n   go_say_hi.argtypes = [ctypes.c_char_p]\n   # NOTE: we don't have a return type defined here, the message is \n   # displayed from Go\n   \n   # Now write our Python idiomatic function\n   def say_hi(txt):\n       return go_say_hi(ctypes.c_char_p(txt.encode('utf8')))\n   \n   if __name__ == '__main__':\n       say_hi('Hello!')\n```\n\nPutting things together (if you are using Windows or Mac OS X\nyou'll adjust name output name, `libsayhi.so`, to match the\nfilename extension suitable for your operating system).\n\n```bash\n    go build -buildmode=c-shared -o libsayhi.so libsayhi.go\n```\n\nand testing.\n\n```bash\n    python3 sayhi.py\n```\n\n\n## Example 3, libhelloworld.go and helloworld.py\n\nIn this example we send a Python string to Go (which expects utf-8)\nbuild our \"hello world\" message and then send it back to Python\n(which needs to do additional conversion and decoding).\n\nLike in previous examples the Go side remains very simple. The heavy\nlifting is done by the *C* package and the comment `//export`. We\nare using `C.GoString()` and `C.CString()` to flip between our native\nGo and C datatypes.\n\n```go\n    package main\n    \n    import (\n    \t\"C\"\n    \t\"fmt\"\n    )\n    \n    //export helloworld\n    func helloworld(name *C.char) *C.char {\n    \ttxt := fmt.Sprintf(\"Hello %s\", C.GoString(name))\n    \treturn C.CString(txt)\n    }\n    \n    func main() { }\n```\n\nIn the python code below the conversion process is much more detailed.\nPython isn't explicitly utf-8 like Go. Plus we're sending our Python \nstring via C's char arrays (or pointer to chars). Finally when we \ncomeback from Go via C we have to put things back in order for Python. \nOf particular note is checking how the byte arrays work then \nencoding/decoding everything as needed. We also explicitly set the result \ntype from our Go version of the helloworld function.\n\n```python\n    import ctypes\n    import os\n    \n    # Set the name of our shared library\n    lib_name = 'libhelloworld'\n\n    # Figure out shared library extension\n    uname = os.uname().sysname\n    ext = '.so'\n    if uname == 'Darwin':\n        ext = '.dylib'\n    if uname == 'Windows':\n        ext = '.dll'\n    \n    # Find our shared library and load it\n    dir_path = os.path.dirname(os.path.realpath(__file__))\n    lib = ctypes.cdll.LoadLibrary(os.path.join(dir_path, lib_name+ext))\n    \n    # Setup our Go functions to be nicely wrapped\n    go_helloworld = lib.helloworld\n    go_helloworld.argtypes = [ctypes.c_char_p]\n    go_helloworld.restype = ctypes.c_char_p\n    \n    # Now write our Python idiomatic function\n    def helloworld(txt):\n        value = go_helloworld(ctypes.c_char_p(txt.encode('utf8')))\n        if not isinstance(value, bytes):\n            value = value.encode('utf-8')\n        return value.decode()\n    \n    \n    if __name__ == '__main__':\n        import sys\n        if len(sys.argv) > 1:\n            print(helloworld(sys.argv[1]))\n        else:\n            print(helloworld('World'))\n```\n\nThe build recipe remains the same as the two previous examples.\n\n```bash\n    go build -buildmode=c-shared -o libhelloworld.so libhelloworld.go\n```\n\nHere are two variations to test.\n\n```bash\n     python3 helloworld.py\n     python3 helloworld.py Jane\n```\n\n\n## Example 4, libjsonpretty.go and jsonpretty.py\n\nIn this example we send JSON encode text to the Go package,\nunpack it in Go's runtime and repack it using the `MarshalIndent()`\nfunction in Go's JSON package before sending it back as Python\nin string form.  You'll see the same encode/decode patterns as \nin our *helloworld* example.\n\nGo code\n\n```go\n    package main\n    \n    import (\n    \t\"C\"\n    \t\"encoding/json\"\n    \t\"fmt\"\n    \t\"log\"\n    )\n    \n    //export jsonpretty\n    func jsonpretty(rawSrc *C.char) *C.char {\n    \tdata := new(map[string]interface{})\n    \terr := json.Unmarshal([]byte(C.GoString(rawSrc)), &data)\n    \tif err != nil {\n    \t\tlog.Printf(\"%s\", err)\n    \t\treturn C.CString(\"\")\n    \t}\n    \tsrc, err := json.MarshalIndent(data, \"\", \"    \")\n    \tif err != nil {\n    \t\tlog.Printf(\"%s\", err)\n    \t\treturn C.CString(\"\")\n    \t}\n    \ttxt := fmt.Sprintf(\"%s\", src)\n    \treturn C.CString(txt)\n    }\n    \n    func main() {}\n```\n\nPython code\n\n```python\n    import ctypes\n    import os\n    import json\n    \n    # Set the name of our shared library\n    lib_name = 'libjsonpretty'\n\n    # Figure out shared library extension\n    uname = os.uname().sysname\n    ext = '.so'\n    if uname == 'Darwin':\n        ext = '.dylib'\n    if uname == 'Windows':\n        ext = '.dll'\n\n    dir_path = os.path.dirname(os.path.realpath(__file__))\n    lib = ctypes.cdll.LoadLibrary(os.path.join(dir_path, lib_name+ext))\n    \n    go_jsonpretty = lib.jsonpretty\n    go_jsonpretty.argtypes = [ctypes.c_char_p]\n    go_jsonpretty.restype = ctypes.c_char_p\n    \n    def jsonpretty(txt):\n        value = go_jsonpretty(ctypes.c_char_p(txt.encode('utf8')))\n        if not isinstance(value, bytes):\n            value = value.encode('utf-8')\n        return value.decode()\n    \n    if __name__ == '__main__':\n        src = '''\n    {\"name\":\"fred\",\"age\":25,\"height\":75,\"units\":\"inch\",\"weight\":\"239\"}\n    '''\n        value = jsonpretty(src)\n        print(\"Pretty print\")\n        print(value)\n        print(\"Decode into dict\")\n        o = json.loads(value)\n        print(o)\n```\n\nBuild command\n\n```shell\n    go build -buildmode=c-shared -o libjsonpretty.so libjsonpretty.go\n```\n\nAs before you can run your tests with `python3 jsonpretty.py`.\n\nIn closing I would like to note that to use these examples you Python3\nwill need to be able to find the module and shared library. For \nsimplicity I've put all the code in the same directory. If your Python\ncode is spread across multiple directories you'll need to make some \nadjustments.\n\n",
      "data": {
        "author": "rsdoiel@gmail.com (R. S. Doiel)",
        "copyright": "copyright (c) 2018, R. S. Doiel",
        "date": "2018-02-24",
        "keywords": [
          "Golang",
          "Python",
          "shared libraries"
        ],
        "license": "https://creativecommons.org/licenses/by-sa/4.0/",
        "title": "Go based Python modules"
      },
      "url": "posts/2018/02/24/go-based-python-modules.json"
    },
    {
      "content": "\n\n# Review: Software Tools in Pascal\n\nBy R. S. Doiel, 2018-07-22\n(updated: 2018-07-22, 1:39 pm, PDT)\n\n\nThis book is by Brian W. Kernighan and P. J. Plauger. It is an\nexample of the type of books I find I re-read and want in my\npersonal library. The book covers software construction through \na series of programs written in pascal. It is about how these \nprograms work, how to approach problems and write sound software.\nI was surprised I did not know about this book when I was browsing \nthe [Open Library](https://openlibrary.org) this weekend.  While \nPascal was a popular in the 1980's it has faded for most people in the \nearly 21st century.  This review maybe a small bit of nostalgia. \nOn the other hand I suspect \n[\"Software Tools in Pascal\"](https://openlibrary.org/books/OL4258115M/Software_tools_in_Pascal)\nis one of the short list of computer books that will remain useful\nover the long run.\n\n\n## What's covered\n\nThe book is organized around specific programs and their implementations.\nThe implementations provided are simple and straight forward. Each\nsection is followed by a set of \"exercises\" that extend the ideas\nshown in the section. In this way you could derive the modern equivalent\nof these tools.\n\nThe topics you build tools for in the text are\nfilters, files, sorting, text patterns, editing, formatting, \nand macro processing.\n\nIf you want to follow the book along in Pascal then I think Free Pascal\navailable in many Debian distributions including Raspbian on the Raspberry\nPi is a good choice.  Likewise Wirth's Pascal is easy enough to port\nto other languages and indeed this would be a useful exercise when I\nre-read the book the next time.\n\nThe book presents a very nice set of text oriented programs to explore\nprogramming or re-connect with your programming roots.\n\n## Read the book\n\n<iframe width=\"165\" frameBorder=\"0\" height=\"400\" src=\"https://openlibrary.org/books/OL4258115M/Software_tools_in_Pascal/widget\"></iframe>\n",
      "data": {
        "author": "rsdoiel@gmail.com (R. S. Doiel)",
        "copyright": "copyright (c) 2018, R. S. Doiel",
        "date": "2018-07-22",
        "keywords": [
          "Pascal",
          "programming",
          "book review"
        ],
        "license": "https://creativecommons.org/licenses/by-sa/4.0/",
        "title": "Review: Software Tools in Pascal"
      },
      "url": "posts/2018/07/22/software-tools-in-pascal.json"
    },
    {
      "content": "\n\nOPML to Markdown and back\n=========================\n\nBy R. S. Doiel 2016-05-28\n\n## Overview\n\nI wrote a Go language package to sort [OPML](http://dev.opml.org/spec2.html) outlines. \nI wrote this because my preferred [feed reader ](http://goread.io) supports manual \nsorting but not automatic alpha sorting by the _outline_ element's _text_ attribute. \n\n## Observations\n\nOut of the box the OPML 2 Spec provides attributes indicating inclusion of other OPML files,\nscripts, basic metadata (create, modified, authorship), and even directory structures.\n\n[Fargo](http://fargo.io) allows user defined attributes to be applied to the _outline_ \nelement in OPML. This could be used in support some of the \n[Scrivener](https://www.literatureandlatte.com/scrivener.php)\nfeatures I miss such as describing how to render a project to various formats such as\nrtf, pdf, ePub, web pages or even [Final Draft fdx](https://www.finaldraft.com/) files.\n\nI write allot of Markdown formatted text.  Markdown is simple to index, \nsearch and convert into useful formats. Markdown is not good at expressing more\ncomplex structures such as metadata. Website generators that use markdown often\nrequire a preamble or _front matter_ in the markdown to provide any metadata. This\nleaves your document head cluttered and less human readable.\n\nAnother approach is to include a parallel document with the metadata.  It occurred to me \nthat an OPML file could easily hold that metadata. It can even hold Markdown content.\nThe trouble with OPML is that it is not quick to edit by hand.\n\n    Is there a round trip semantic mapping between OPML and Markdown?\n\n\n## Germination of an idea\n\nEntering a web link in Fargo the link is URL encoded and saved in the _text_ attribute of the \n_outline_ element.\n\nThe source view of a web links in Fargo's _outline_ element looks like\n\n```OPML\n    <outline text=\"&gt; href=&quot;http://example.org&quot;&lt;My example.org&gt;/a&lt;\" />\n```\n\nThat _outline_ element might render in Markdown as\n\n```\n    + [My element.org](http://example.org)\n```\n\nThe steps to create the Markdown view are simple\n\n1. URL decode the _text_ attribute\n2. Convert HTML to Markdown\n\nMaking a round trip could be done by\n\n3. Convert Markdown into HTML\n4. For each _li_ element covert to an _outline_ element URL encoding the inner HTML of the _li_\n\nSo far so good. What about something more complex?\n\n\nHere's an _outline_ element example from http://hosting.opml.org/dave/spec/directory.opml \n\n```OPML\n    <outline text=\"Scripting News sites\" created=\"Sun, 16 Oct 2005 05:56:10 GMT\" type=\"link\" url=\"http://hosting.opml.org/dave/mySites.opml\"/>\n```\n\nTo me that should look like \n\n```\n    + [Scripting News Sites](http://hosting.opml.org/dave/mySites.opml)\n```\n\nWhat about the _created_ attribute? Could we render this case as an additional set of anchors using data uri?\n\nThis suggest a rule like\n\n+ if the _text_ attribute contains HTML markup\n    + URL decode into HTML\n    + Convert HTML to Markdown\n+ else render attributes as additional anchors using data URI\n\nThis might work as follows. \n\n```OPML\n    <outline text=\"Scripting News sites\" \n        created=\"Sun, 16 Oct 2005 05:56:10 GMT\" \n        type=\"link\" \n        url=\"http://hosting.opml.org/dave/mySites.opml\"/>\n```\n\nWould become \n\n```Markdown\n    + [Scripting News Sites](http://hosting.opml.org/dave/mySites.opml) [type](data:text/plain;link) [created](data:text/date;Sun, 16 Oct 2005 05:56:10 GMT)\n```\n\nIn HTML this would look like\n\n```HTML\n    <li><a href=\"http://histing.opml.org/dave/mySites.opml\">Scripting News Sites</a>\n        <a href=\"data:text/plain;link\">type</a>\n        <a href=\"data:text/date;Sun, 16 Oct 2005 05:56:10 GMT\">created</a></li>\n```\n\n### Markdown to OPML\n\nComing back to OPML from Markdown then becomes\n\n+ Convert Markdown to HTML\n+ For each _li_ element inspect anchors, \n    + if anchors contain data URI then map _outline_ element\n    + else URL encode and embed in _outline_ _text_ attribute\n\nIs this viable? Does it have any advantages?\n\n",
      "data": {
        "author": "rsdoiel@gmail.com (R. S. Doiel)",
        "copyright": "copyright (c) 2016, R. S. Doiel",
        "date": "2016-05-28",
        "keywords": [
          "golang",
          "opml",
          "markdown"
        ],
        "license": "https://creativecommons.org/licenses/by-sa/4.0/",
        "title": "OPML to Markdown and back"
      },
      "url": "posts/2016/05/28/OPML-to-Markdown-and-back.json"
    },
    {
      "content": "\n\n# Instant Articles, Accelerated Mobile Pages, Twitter Cards and Open Graph\n\nBy R. S. Doiel 2016-05-30\n\n## The problem\n\nThe web has gotten slow. In [2016](http://httparchive.org/trends.php) the \naverage page weight is in multi-megabytes and the average number of network \nrequests needed to deliver the content is counted in \nthe hundreds. In the mix are saturated networks and a continued public \nexpectation of responsiveness (web wisdom suggests you have about 3 seconds \nbefore people give up).  The odd thing is we've known how to build fast \nwebsites for a [decade](https://www.stevesouders.com/) or so.  \nCollectively we don't build them [fast](https://www.sitepoint.com/average-page-weight-increased-another-16-2015/). \n\n\n## Meet the new abstractions\n\nCorporations believe they have the answer and they are providing us \nwith another set of abstractions. In a few years maybe these will \nget distilled down to a shared common view but in the mean time disc \ncosts remain reasonably priced and generating these new forms of \npages or feeds is a template or so away.\n\n+ [Twitter Cards](https://dev.twitter.com/cards/overview) and [Open Graph](http://ogp.me/)\n  + Exposing your content via social media, search results or embedded in pages via an aside element\n+ [Accelerated Mobile Pages](https://www.ampproject.org/) (also called AMP)\n  + A simplification in content delivery to improve web reading experience\n  + Its usefulness is it proscribes an approach to leverage what we have\n  + AMP works well with Twitter Cards, Open Graph and can leverage Web Components\n+ [Instant Articles](https://instantarticles.fb.com/)\n  + a format play to feed the walled garden of Facebook for iOS and Android devices\n\n\n## The players \n\n### Twitter Cards and Open Graph\n\nTwitter's Titter Cards and Facebook's Open Graph offer approaches to \nbuild off of our existing meta elements in an HTML page's document \nhead.  They are named space to avoid collisions but supporting both \nwill still result in some content duplication. The k-weight \ndifference in the resulting HTML pages isn't too bad. \n\nAdopting either or both is a matter of adjusting how your render your \nweb page's head block.  It is easy enough to do manually but easier \nstill using some sort of template system that renders the appropriate \nmeta elements based on the content type and contents in the page \nbeing rendered.  \n\nGoogle and other search engines can leverage this richer meta \ndata and integrate it into their results. Google's Now application can \nrender content cards based on either semantic. It also appears that \ncontent cards are being leverage selectively for an aside and related \ncontent on Google search results pages. You could even built this into \nyour own indexing process for use with the Solr or Elasticsearch.\n\nContent Cards offer intriguing opportunity for web crawlers and search \nengines.  This is particularly true when combined with mature feed \nformats like RSS, OPML, Atom and the maturing efforts in the linked \ndata community around JSON-LD.\n\n\n### AMP - Accelerated Mobile Pages\n\nThe backers of AMP (not to be confused with Apache+MySQL+PHP) are largely\npublishers including major news outlets and web media\ncompanies in the US and Europe. This is an abridged list from 2015--\n\n+ BBC\n+ Atlantic Media\n+ Vox Media\n+ Conde Nast\n+ New York Times\n+ Wall Street Journal\n+ The Daily Mail\n+ Huffington Post\n+ Gannet\n+ The Guardian\n+ The Economist\n+ The Financial Times\n\nIn additional to the publishers there is participation by tech companies\nsuch as Google, Pinterest, Twitter, LinkedIn and Wordpress.com.  Accelerated\nMobile Pages offer benefits for web crawlers and search engines supporting\nsurfacing content is clearly and enabling easier distinction from \nadvertisements. \n\n\n### Instant Articles\n\nIn additional to Open Graph Facebook has put forward [Instant Articles](https://developers.facebook.com/docs/instant-articles).\nLike AMP it is targeting content delivery for mobile. Unlike AMP Instant Articles is an\nexplicit binding into Facebook's walled garden only exposing the content on supported\nversions of iOS and Android. You don't see Instant Articles in your Facebook timeline or when  \nyou browse from a desktop web browser.  Unlike the previous\nexamples you actually need to sign up to participate in the Instant Article publishing\nprocess.  Sign up cost is having a Facebook account, being approved by Facebook and compliance\nwith their terms of service. Facebook does provide some publishing tools, publishing controls\nas well as some analytics. They do allow 3rd party ads as well as encourage access to\ntheir advertising network.  Once approved the burden on your content manage process \nappears manageable.  \n\nYou can submit Instant Articles via a modified RSS feed or directly through their API. \nIn this sense the overhead is about the same as that for implementing support for Twitter Cards\nOpen Graph, and AMP. Facebook does a good job of quickly propagating changes to your\nInstant Articles across their platform. That's nice.\n\nWhy go through the trouble? If you're a content producer and your audience lives on Facebook\nFacebook commands the attention of a lot of eye balls.  Instant Articles provides \nanother avenue to reach them.  For some Facebook effectively controls the public view of the \nweb much as America Online and Prodigy did decades ago. [Dave Winer](https://twitter.com/davewiner) \nhas written extensively on how he implemented Instant Article support along with \nsome very reasoned pros and cons for doing so. The landscape is evolving and \n[Dave's river of news](http://scripting.com) is worth following.\n\n\n## Impact on building content\n\nThese approaches require changes in your production of your HTML and RSS sent to the browser.\nTwitter Cards and Open Graph change what you put in the HEAD element of the HTML\npages.  AMP proscribes what you should put in the BODY element of the webpage.\nInstant Articles tweaks your RSS output.  Not surprisingly the major content management \nsystems Wordpress and Drupal have plugins for this.  All can be implemented via your template \nsystem or page generation process.\n\n\n## Whither adopt?\n\nBecause these approaches boil down to content assembly the adoption risk \nis low.  If your audience views Twitter, Facebook or Google search results \nthen it is probably worth doing.  All allow you to continue to publish your \nown content and own your URLs as opposed to being a tenant on one or another \nplatform. That benefits the open web.\n\n",
      "data": {
        "author": "rsdoiel@gmail.com (R. S. Doiel)",
        "copyright": "copyright (c) 2016, R. S. Doiel",
        "date": "2016-05-30",
        "keywords": [
          "structured data",
          "amp",
          "opengraph",
          "twitter",
          "google",
          "facebook",
          "instant pages"
        ],
        "license": "https://creativecommons.org/licenses/by-sa/4.0/",
        "title": "Instant Articles, Accelerated Mobile Pages, Twitter Cards and Open Graph"
      },
      "url": "posts/2016/05/30/amp-cards-and-open-graph.json"
    },
    {
      "content": "\n\nHow to make a Pi-Top more Raspbian\n==================================\n\nBy R. S. Doiel, 2016-07-04\n\nI have a first generation Pi-Top.  I like the idea but found I didn't use it much due to a preference for\nbasic Raspbian. With the recent Pi-TopOS upgrades I realized getting back to basic Raspbian was relatively\nstraight forward.\n\n## The recipe\n\n1. Make sure you're running the latest Pi-TopOS based on Jessie\n2. Login into your Pi-Top normally\n3. From the Pi-Top dashboard select the \"Desktop\" icon\n4. When you see the familiar Raspbian desktop click on the following things\n\t+ Click on the Raspberry Menu (upper left corner)\n\t+ Click on Preferences\n\t+ Click on Raspberry Pi Configuration\n5. I made the following changes to my System configuration\n\t+ Under *Boot* I selected \"To CLI\"\n\t+ I unchecked *login as user \"pi\"*\n6. Restart your Pi Top\n\t+ Click on Raspberry Menu in the upper left of the desktop\n\t+ Click on shutdown\n\t+ Select *reboot*\n7. When you restart you'll see an old school console login, login as the pi user using your Pi-Top password\n8. Remove the following program use the *apt* command\n\t+ ceed-universe\n\t+ pt-dashboard\n\t+ pt-splashscreen\n\n```\n    sudo apt purge ceed-universe pt-dashboard pt-splashscreen\n```\n\nNote: pi-battery, pt-hub-controller, pt-ipc, pt-speaker are hardware drivers specific to your Pi-Top so you probably\nwant to keep them.\n\n\n\n",
      "data": {
        "author": "rsdoiel@gmail.com (R. S. Doiel)",
        "copyright": "copyright (c) 2016, R. S. Doiel",
        "date": "2016-07-04",
        "keywords": [
          "Raspberry Pi",
          "Pi-Top",
          "Rasbian",
          "Raspberry Pi OS",
          ":operating systems"
        ],
        "license": "https://creativecommons.org/licenses/by-sa/4.0/",
        "title": "How to make a Pi-Top more Raspbian"
      },
      "url": "posts/2016/07/04/How-To-Make-A-PiTop-More-Raspbian.json"
    },
    {
      "content": "\n\n# Android, Termux and Dev Environment\n\nBy R. S. Doiel 2016-09-20\n\nRecently I got a new Android 6 tablet. I got a case with a tiny Bluetooth keyboard. I started wondering if I could use it as a development device when on the road. So this is my diary of that test.\n\n## Challenges\n\n1. Find a way to run Bash without rooting my device\n2. See if I could use my normal web toolkit\n\t+ curl\n\t+ jq\n\t+ sed\n\t+ grep\n3. See if I could compile or add my own custom Golang programs\n4. Test setup by running a local static file server, mkpage and update my website\n\n## Searching for Android packages and tools of my toolbox\n\nAfter searching with Duck Duck Go and Google I came across the [termux](https://termux.com). Termux provides a minimal Bash shell environment with support for adding\npackages with _apt_ and _dpkg_.  The repositories visible to *termux* include\nmost of the C tool chain (e.g. clang, make, autoconf, etc) as well as my old Unix favorites _curl_, _grep_, _sed_, _gawk_ and a new addition to my toolkit _jq_.  Additionally you'll find recent versions (as of Sept. 2016) versions of _Golang_, _PHP_, _python_, and _Ruby_.\n\nThis quickly brought me through step 3.  Installing _go_, _git_, and _openssh_ completed what I needed to test static site development with some of the tools in our incubator at [Caltech Library](https://caltechlibrary.github.io).\n\n## Setting up for static site development\n\nAfter configuring _git_, adding my public key to GitHub and running _go get_ on my\ncustom static site tools I confirmed I could build and test static websites from my Android tablet using *Termux*.\n\nHere's the list of packages I installed under *Termux* to provide a suitable shell environment for writing and website constructions.\n\n```shell\n    apt install autoconf automake bash-completion bc binutils-dev bison \\\n        bzip2 clang cmake coreutils ctags curl dialog diffutils dos2unix \\\n        expect ffmpeg findutils gawk git gnutls golang grep gzip \\\n\timagemagick jq less lynx m4 make-dev man-dev nano nodejs \\\n        openssh patch php-dev python readline-dev rlwrap rsync ruby-dev \\\n        sed sensible-utils sharutils sqlite tar texinfo tree unzip vim \\\n        w3m wget zip\n```\n\nThis then allowed me to setup my *golang* environment variables and install\nmy typical custom written tools\n\n```shell\n    export PATH=$HOME/bin:$PATH\n    export GOPATH=$HOME\n    export GOBIN=$HOME/bin\n    go get github.com/rsdoiel/shelltools/...\n    go get github.com/caltechlibrary/mkpage/...\n    go get github.com/caltechlibrary/md2slides/...\n    go get github.com/caltechlibrary/ws/...\n```\n\nFinally pulled down some content to test.\n\n```shell\n    cd\n    mkdir Sites\n    git clone https://github.com/rsdoiel/rsdoiel.github.io.git Sites/rsdoiel.github.io\n    cd  Sites/rsdoiel.github.io\n    ws\n```\n\nThis started the local static site webserver and I pointed by Firefox for Android at http://localhost:8000 and saw a local copy of my personal website. From there I wrote this article and updated it just as if I was working on a Raspberry Pi or standard Linux laptop.\n\n\n",
      "data": {
        "author": "rsdoiel@gmail.com (R. S. Doiel)",
        "copyright": "copyright (c) 2016, R. S. Doiel",
        "date": "2016-09-20",
        "keywords": [
          "Bash",
          "cURL",
          "jq",
          "sed",
          "grep",
          "search",
          "golang",
          "Android"
        ],
        "license": "https://creativecommons.org/licenses/by-sa/4.0/",
        "title": "Android, Termux and Dev Environment"
      },
      "url": "posts/2016/09/20/Android-Termux-Dev-environment.json"
    },
    {
      "content": "\n\nFrom Markdown and Bash to mkpage\n================================\n\nBy R. S. Doiel 2016-08-16\n\nWhen I started maintaining a website on GitHub a few years ago my needs\nwere so simple I hand coded the HTML.  Eventually I adopted \na markdown processor for maintaining the prose. My \"theme\" was a\nCSS file and some HTML fragments to wrap the markdown output. If I needed \ninteractivity I used JavaScript to access content via a web API. \nLife was simple, all I had to learn to get started was Git and how to\npopulate a branch called \"gh-pages\".\n\n\n## Deconstructing Content Management Systems\n\nRecently my website needs have grown. I started experimenting with static\nsite generators thinking an existing system would be the right fit. \nWhat I found were feature rich systems that varied primarily in \nimplementation language and template engine. Even though I wasn't\nrequired to run Apache, MySQL and PHP/Perl/Python/Ruby/Tomcat it felt \nlike the static site generators were racing to fill a complexity \nvacuum. In the end they were interesting to explore but far more\nthan I was willing to run. I believe modern content management systems can\nbe deconstruct into something simpler.\n\nSome of the core elements of modern content management systems are\n\n+ creation and curation of data sources (including metadata)\n+ transforming data sources if needed\n+ mapping a data source to appropriate template set\n+ rendering template sets to produce a final website\n\nModern static site generators leave creation and curation to your \ntext editor and revision control system (e.g. vi and git). \n\nMost static site generators use a simplified markup. A populate one is\ncalled [Markdown](https://en.wikipedia.org/wiki/Markdown). This \"markup\"\nis predictable enough that you can easily convert the results to HTML and\nother useful formats with tools like [pandoc](http://pandoc.org/). In most \nstatic site generators your content is curated in Markdown and when the \npages are built it is rendered to HTML for injection into your website's \ntemplate and theme.\n\nMapping the data sources to templates, combining the templates and rendering \nthe final website is where most systems introduce a large amount of complexity.\nThis is true of static site generators like [Jekill](https://jekyllrb.com) and \n[Hugo](https://gohugo.io).\n\n\n## An experimental deconstruction\n\nI wanted a simple command line tool that would make a single web page.\nIt would take a few data sources and formats and run them through a\ntemplate system. The template system needed to be simple but support\nthe case where data might not be available. It would be nice if it handled\nthe case of repetitious data like that used in tables or lists. Ideally\nI could render many pages from a single template assuming a simple website\nand layout.\n\n### A single page generator\n\n[mkpage](https://github.com/rsdoiel/mkpage) started as an experiment in\nbuilding a simple single page generator. It's responsibilities\ninclude mapping data sources to the template, transforming data if needed\nand rendering the results. After reviewing the websites I've setup in\nthe last year or two I realized I had three common types of data.\n\n1. Plain text or content that did not need further processing\n2. Markdown content (e.g. page content, navigation lists)\n3. Occasionally I include content from JSON feeds\n\nI also realized I only needed to handle three data sources.\n\n1. strings\n2. files\n3. web resources\n\nEach of these sources might provide plain text, markdown or JSON data formats.\n\nThat poses the question of how to express the data format and the data \nsource when mapping the content into a template. The web resources are\neasy in the sense that the web responses include content type information.\nFiles can be simple too as the file extension indicates their\nformat (e.g. \".md\" for Markdown, \".json\" for JSON documents). What remained\nwas how to identify a text string's format.  I opted for a prefix ending in \na colon (e.g. \"text:\" for plain text, \"markdown:\" for markdown \nand \"json:\" for JSON). This mapping allows for a simple key/value\nrelationship to be expressed easily on the command line.\n\n### mkpage in action\n\nDescribing how to build \"mypage.html\" from \"mypage.md\" and \"nav.md\" \n(containing links for navigating the website) is as easy as typing\n\n```shell\n    mkpage \"content=mypage.md\" \"navigation=nav.md\" page.tmpl > mypage.html\n```\n\nIn this example the template is called \"page.tmpl\" and we redirect the \noutput to \"mypage.html\".\n\n\nAdding a custom page title is easy too.\n\n```shell\n    mkpage \"title=text:My Page\" \\\n        \"content=mypage.md' \"navigation=nav.md\" \n        page.tmpl \\\n        > mypage.html\n```\n\nLikewise integrating some JSON data from weather.gov is relatively straight\nforward. The hardest part is discovering the [URL](http://forecast.weather.gov/MapClick.php?lat=34.0522&lon=118.2437&DFcstType=json) \nthat returns JSON!  Notice I have added a weather field and the URL. When data\nis received back from weather.gov it is JSON decoded and then passed to the\ntemplate for rendering using the \"range\" template function.\n\n```shell\n    mkpage \"title=My Page\" \\\n        \"content=mypage.md\" \\\n        \"navigation=nav.md\" \\\n        \"weather=http://forecast.weather.gov/MapClick.php?lat=34.0522&lon=118.2437&DFcstType=json\" \\\n        page.tmpl \\\n        > mypage.html\n```\n\nWhat is *mkpage* doing?\n\n1. Reading the data sources and formats from the command line\n2. Transforming the Markdown and JSON content appropriately\n3. Applying them to the template (e.g. page.tmpl)\n4. Render the results to stdout\n\nBuilding a website then is only a matter of maintaining navigation in\n*nav.md* and identifying the pages needing to be created. I can easily \nautomated that using the Unix find, grep, cut and sort. Also with find \nI can iteratively process each markdown file applying a \ntemplate and rendering the related HTML file.  This can be done for a site \nof a few pages (e.g. about, resume and cv) to more complex websites like \nblogs and repository activities.\n\nHere's an example template that would be suitable for the previous\ncommand line example. It's mostly just HTML and some curly bracket notation \nsprinkled in.\n\n```html\n    <!DOCTYPE html>\n    <html>\n    <head>\n        {{with .title}}<title>{{- . -}}</title>{{end}}\n        <link rel=\"stylesheet\" href=\"css/site.css\">\n    </head>\n    <body>\n        <nav>\n        {{ .navigation }}\n        </nav>\n        <section>\n        {{ .content }}\n        </section>\n        <aside>\n        Weather Demo<br />\n        <ul>\n        {{range .weather.data.text}}\n            <li>{{ . }}</li>\n        {{end}}\n        </ul>\n        </aside>\n\n    </body>\n    </html>\n```\n\nYou can find out more about [mkpage](https://github.com/rsdoiel/mkpage)\n[rsdoiel.github.io/mkpage](https://rsdoiel.github.io/mkpage).\n\nTo learn more about Go's text templates see \n[golang.org/pkg/text/template](https://golang.org/pkg/text/template/). \n\nIf your site generator needs are more than *mkpage* I suggest [Hugo](https://gohugo.io). \nIt's what I would probably reach for if I was building a large complex organizational\nsite or news site.\n\nIf you're looking for an innovative and rich author centric content system\nI suggest Dave Winer's [Fargo](http://fargo.io) outliner and [1999.io](https://1999.io).\n\n\n",
      "data": {
        "author": "rsdoiel@gmail.com (R. S. Doiel)",
        "copyright": "copyright (c) 2016, R. S. Doiel",
        "date": "2016-08-16",
        "keywords": [
          "Bash",
          "Markdown",
          "site generator",
          "mkpage",
          "pandoc"
        ],
        "license": "https://creativecommons.org/licenses/by-sa/4.0/",
        "title": "From Markdown and Bash to mkpage"
      },
      "url": "posts/2016/08/16/From-Markdown-and-Bash-to-mkpage.json"
    },
    {
      "content": "\n\n# Exploring Bash for Windows 10 Pro\n\nBy R. S. Doiel 2016-08-15\n\n    UPDATE (2016-10-27, RSD): Today trying to compile Go 1.7.3 under \n    Windows 10 Pro I've am getting compile errors when the \n    assembler is being built.  I can compile go1.4.3 but see errors \n    in some of the tests results.\n\n## Initial Setup and configuration\n\nI am running Windows 10 Pro (64bit) Anniversary edition under Virtual Box. The VM was upgraded from an earlier version of Windows 10 Pro (64bit). The VM was allocated 4G or ram, 200G disc and simulating 2 cores.  After the upgrade I took the following steps\n\n+ Search with Bing for \"Bash for Windows\" \n    + Bing returns http://www.howtogeek.com/249966/how-to-install-and-use-the-linux-bash-shell-on-windows-10/\n+ Switch on developer mode for Windows\n+ Turned on Linux Subsystem Beta (searched for \"Turning on Features\")\n+ Reboot\n+ Search for \"Bash\" and clicked on \"Run Bash command\"\n+ Answered \"y\"\n+ Waited for download and extracted file system\n+ When prompted setup developer account with username/password\n    + Documentation can be found at https://aka.ms/wsldocs\n+ Exit root install shell\n+ Search for \"Bash\" locally\n+ Launched \"Bash on Ubuntu on Windows\"\n+ Authenticate with your username/password\n\n\n## Setting up Go under Bash for Windows 10\n\nWith Bash installed these are the steps I took to compile Go\nunder Bash on Ubuntu on Windows.\n\n```shell\n    sudo apt-get update && sudo apt-get upgrade -y\n    sudo apt-get autoremove\n    sudo apt-get install build-essential clang git-core unzip zip -y\n    export CGO_ENABLE=0\n    git clone https://github.com/golang/go go1.4\n    git clone https://github.com/golang/go go\n    cd go1.4\n    git checkout go1.4.3\n    cd src\n    ./all.bash\n    cd\n    export PATH=$PATH:$HOME/go1.4/bin\n    cd go\n    git checkout go1.7\n    cd src\n    ./all.bash\n    cd\n    export PATH=$HOME/go/bin:$HOME/bin:$PATH\n    export GOPATH=$HOME\n```\n\nNote some tests failing during compilation in both 1.4.3 and 1.7. They mostly failed\naround network sockets.  This is probably a result of the limitations in the Linux subsystem\nunder Windows.\n\nIf successful you should be able to run `go version` as well as install additional Go based software\nwith the usual `go get ...` syntax.\n\nIn your `.bashrc` or `.profile` add the following\n\n```shell\n    export PATH=$HOME/go/bin:$HOME/bin:$PATH\n    export GOPATH=$HOME\n```\n\n\n## Improved vim setup\n\nI like the vim-go packages for editing Go code in vim. They are easy to setup.\n\n```shell\n     mkdir -p ~/.vim/autoload ~/.vim/bundle \n     curl -LSso ~/.vim/autoload/pathogen.vim https://tpo.pe/pathogen.vim\n     git clone https://github.com/fatih/vim-go.git ~/.vim/bundle/vim-go\n```\n\nExample $HOME/.vimrc\n\n```vimrc\n    execute pathogen#infect()\n    syntax on\n    filetype plugin on\n    set ai\n    set nu\n    set smartindent\n    set tabstop=4\n    set shiftwidth=4\n    set expandtab\n    let &background = ( &background == \"dark\"? \"light\" : \"dark\" )\n    let g:vim_markdown_folding_disabled=1\n```\n\nColor schemes are browsable at [vimcolors.com](http://vimcolors.com). They can be installed in\n$HOME/.vim/colors.\n\n1. git clone and place the colorscheme\n2. place the *.vim file holding the color scheme into $HOME/.vim/colors\n3. start vim and at the : do colorscheme NAME where NAME is the scheme you want to try\n\nYou can find the default shipped color schemes in /usr/share/vim/vimNN/colors where vimNN is the version number\ne.g. /usr/share/vim/vim74/colors.\n\n\n",
      "data": {
        "author": "rsdoiel@gmail.com (R. S. Doiel)",
        "copyright": "copyright (c) 2016, R. S. Doiel",
        "date": "2016-08-15",
        "keywords": [
          "Golang",
          "Windows",
          "Bash",
          "Linux Subsystem"
        ],
        "license": "https://creativecommons.org/licenses/by-sa/4.0/",
        "title": "Exploring Bash for Windows 10 Pro"
      },
      "url": "posts/2016/08/15/Setting-up-Go-under-Bash-for-Windows-10.json"
    }
  ]
}