{
  "page": 1,
  "total_pages": 1,
  "has_more": false,
  "next_page": null,
  "values": [
    {
      "content": "\n# Installing pgloader from source\n\nBy R. S. Doiel, 2024-02-01\n\nI'm working on macOS at the moment but I don't use Home Brew so the instructions to install pgloader are problematic for me. Except I know pgloader is a Lisp program and once upon a time I had three different Lisps running on a previous Mac.  So what follows is my modified instructions for bringing pgloader up on my current Mac Mini running macOS Sonoma 14.3 with Xcode already installed.\n\n## Getting your Lisps in order\n\npgloader is written in common list but the instructions at https://pgloader.readthedocs.io/en/latest/install.html specifically mention compiling with [SBCL](https://sbcl.org) which is one of the Lisps I've used in the past. But SBCL isn't (yet) installed on my machine and SBCL is usually compiled using SBCL but can be compiled using other common lists.  Enter [ECL](https://ecl.common-lisp.dev/), aka Embedded Common-Lisp. ECL compiles via a C compiler including the funky setup that macOS has. This means the prep for my machine should look something like\n\n1. Compile then install ECL\n2. Use ECL to compile SBCL\n3. Install SBCL\n4. Now that we have a working SBCL, follow the instructions to compile pgloader and install\n\nNOTE: pgloader requires some specific configuration of SBCL when SBCL is compiled\n\n## Getting ECL up and running\n\nThis recipe is straight forward. \n\n1. Review ECL's current website, find latest releases\n2. Clone the Git repository from GitLab for ECL\n3. Follow the install documentation and compile ECL then install it\n\nHere's the steps I took in the shell (I'm installing ECL, SBCL in my home directory)\n\n```\ncd\ngit clone https://gitlab.com/embeddable-common-lisp/ecl.git \\\n          src/gitlab.com/embeddable-common-lisp/ecl\ncd src/gitlab.com/embeddable-common-lisp/ecl\n./configure --prefix=$HOME\nmake\nmake install\n```\n\n## Getting SBCL up and running\n\nTo get SBCL up and running I grab the sources using Git then compile it with the options recommended by pgloader as well as the options to compile SBCL with another common lisp, i.e. ECL. (note: the `--xc-host='ecl'`)\n\n```\ncd\ngit clone git://git.code.sf.net/p/sbcl/sbcl src/git.code.sf.net/p/sbcl/sbcl\ncd git clone git://git.code.sf.net/p/sbcl/sbcl\nsh make.sh --with-sb-core-compression --with-sb-thread --xc-host='ecl'\ncd ./tests && sh ./run-tests.sh\ncd ..\ncd ./doc/manual && make\ncd ..\nenv INSTALL_ROOT=$HOME sh install.sh\n```\n\nAt this time SBCL should be available to compile pgloader.\n\n## Install Quicklisp\n\nQuicklisp is a package manager for Lisp. It is used by pgloader so also needs to be installed. We have two lisp on our system but since SBCL is the one I need to work for pgloader I install Quicklisp for SBCL.\n\n1. Check the [Quicklisp website](https://www.quicklisp.org/beta/) and see how things are done (it has been a long time since I did some lisp work)\n2. Follow the [instructions](https://www.quicklisp.org/beta/#installation) on the website to install Quicklisp for SBCL\n\nThis leaves me with the specific steps\n\n1. Use curl to download quicklisp.lisp\n2. Use curl to download the signature file\n3. Verify the signature file\n4. If OK, load into SBCL\n5. From the SBCL repl execute the needed commands\n\n```\ncurl -O https://beta.quicklisp.org/quicklisp.lisp\ncurl -O https://beta.quicklisp.org/quicklisp.lisp.asc\ngpg --verify quicklisp.lisp.asc quicklisp.lisp\nsbcl --load quicklisp.lisp\n```\n\nAt this point you're in SBCL repl. You need to issue the follow command\n\n```\n(quicklisp-quickstart:install)\n(quit)\n```\n\n\n## Compiling pgloader\n\nOnce you have SBCL and Quicklisp working you're now ready to look at the rest of the dependencies. Based on the what other Linux systems required I figure I need to have the following available\n\n- SQLite 3, libsqlite shared library (already installed)\n- unzip (already installed)\n- make (already installed)\n- curl (already installed)\n- gawk (already installed)\n- freetds-dev (not installed)\n- libzip-dev (not installed)\n\nTwo libraries aren't installed on my system. I use Mac Ports so doing a quick search both appear to be available.\n\n```\nsudo port search freetds\nsudo port search libzip\nsudo port install freetds libzip\n```\n\n\nOK, now I think I am ready to build pgloader. Here's what I need to do.\n\n1. Clone the git repo for pgloader\n2. Invoke make with the right options\n3. Test installation\n\n```\ncd\ngit git@github.com:dimitri/pgloader.git src/github.com/dimitri/pgloader\ncd src/github.com/dimitri/pgloader\nmake save\n./build/bin/pgloader -h\n```\n\nIf all works well I should see the help/usage text for pgloader. The binary executable\nis located in `./build/bin` so I can copy this into place in `$HOME/bin/` directory.\n\n```\ncp ./build/bin/pgloader $HOME/bin/\n```\n\nHappy Loading.\n, \"PostgreSQL\"\n\n\n",
      "data": {
        "byline": "R. S. Doiel, 2024-02-01",
        "keywords": [
          "SQL",
          "Postgres",
          "PostgreSQL",
          "MySQL",
          "pgloader",
          "lisp",
          "macos",
          "ecl",
          "sbcl"
        ],
        "number": 6,
        "pubDate": "2024-02-01",
        "series": "SQL Reflections",
        "title": "Installing pgloader from source"
      },
      "url": "posts/2024/02/01/installing-pgloader-from-source.json"
    },
    {
      "content": "\nUpdating Schema in SQLite3\n==========================\n\nBy R. S. Doiel, 2020-04-16\n\n[SQLite3](https://sqlite.org/docs.html) is a handy little\ndatabase as single file tool.  You can interact with the file\nthrough largely standard SQL commands and embed it easily into\napplications via the C libraries that the project supports.\nIt is also available from various popular scripting languages\nlike Python, PHP, and Lua. One of the things I occasionally\nneed to do and always seems to forget it how to is modify a\ntable schema where I need to remove a column[^1]. So here are\nsome of the basics do I can quickly find them later and avoid\nreading various articles tutorials because the search engines\ndoesn't return the page in the SQLite documentation.\n\n[^1]: The SQL `ALTER TABLE table_name DROP COLUMN column_name` does not work in SQLite3\n\nIn the next sections I'll be modeling a simple person object\nwith a id, uname, display_name, role and updated fields.\n\nCreating a person table\n-----------------------\n\n\n```sql\n\nCREATE TABLE IF NOT EXISTS \"person\" \n        (\"id\" INTEGER NOT NULL PRIMARY KEY, \n        \"uname\" VARCHAR(255) NOT NULL, \n        \"role\" VARCHAR(255) NOT NULL, \n        \"display_name\" VARCHAR(255) NOT NULL, \n        \"updated\" INTEGER NOT NULL);\n\n```\n\nAdding a column\n---------------\n\nWe will create a *junk* column which we will remove later.\n\n```sql\n\n.schema person\nALTER TABLE person ADD COLUMN junk VARCHAR(255) NOT NULL;\n.schema person\n\n```\n\nDropping a column\n-----------------\n\nTo drop a column in SQLite you need to actually create\na new table, migrate the data into it then drop the old table\nand finally rename it. It is best to wrap this in a transaction.\n\n```sql\n\nBEGIN TRANSACTION;\n    CREATE TABLE IF NOT EXISTS \"person_new\" \n           (\"id\" INTEGER NOT NULL PRIMARY KEY, \n           \"uname\" VARCHAR(255) NOT NULL, \n           \"role\" VARCHAR(255) NOT NULL, \n           \"display_name\" VARCHAR(255) NOT NULL, \n           \"updated\" INTEGER NOT NULL);\n    INSERT INTO person_new\n           SELECT id, uname, role, display_name, updated\n           FROM person;\n    DROP TABLE person;\n    ALTER TABLE person_new RENAME TO person;\nCOMMIT;\n\n```\n\n\n",
      "data": {
        "author": "rsdoiel@gmail.com (R. S. Doiel)",
        "copyright": "copyright (c) 2021, R. S. Doiel",
        "date": "2021-04-16",
        "keywords": [
          "SQLite",
          "SQL",
          "database"
        ],
        "license": "https://creativecommons.org/licenses/by-sa/4.0/",
        "number": 1,
        "series": "SQL Reflections",
        "title": "Updating Schema in SQLite3"
      },
      "url": "posts/2021/04/16/Updating-Schema-in-SQLite3.json"
    }
  ]
}unter parts. It reminds me of a mashup of ALGO and SQL. Like the unit of compilation, the unit of execution is also procedure, function or trigger. \n\nThe Postgres documentation defines and explains the [PL/pgSQL](https://www.postgresql.org/docs/14/plpgsql.html) and how it works.  This document is just a quick orientation with specific examples to provide context.\n\nHello World\n-----------\n\nHere is a \"helloworld\" procedure definition.\n\n```sql\n    CREATE PROCEDURE helloworld() AS $$\n    DECLARE\n    BEGIN\n       RAISE NOTICE 'Hello WORLD!';\n    END;\n    $$ LANGUAGE plpgsql;\n```\n\nLet's take a look this line by line.\n\n1. CREATE PROCEDURE defines the procedure and the starting and ending delimiter for the procedure (e.g. `AS $$` the procedure's text ends when `$$` is encountered an second time.\n2. DECLARE is the block where you would declare the variables used in the procedure, we have none in this example\n3. The BEGIN starts the actual procedure instructions\n4. The `RAISE NOTICE` line is how you can display output to the console when the procedure is run\n5. The END completes the procedure definition\n6. the `$$ LANGUAGE plpgsql;` concludes the text defining the procedure and tells the database engine that procedure is written in PL/pgSQL.\n\nWe can run the procedure using the \"CALL\" query.\n\n```sql\n    CALL helloworld()\n```\n\nNOTE: If you want to change the procedure you can \"DROP\" it first otherwise you'll get an error that it already exists.\n\n```sql\n    DROP PROCEDURE helloworld;\n```\n\nImproving my workflow\n---------------------\n\nSQL procedures are generally stored in the RDBMs in database environment. You can think of them as records in the system's database. Procedures and functions are created and can be dropped. While they can be manually typed in the database's shell it is easier to maintain them in plain text files outside the RDBM environment.  \n\n1. Write the procedure in a text file.\n2. Load the text file (e.g. FILENAME) into Postgres \n   a. outside the Postgres shell use `psql -f FILENAME` \n   b. inside the Postgres shell used `\\i FILENAME`\n3. Call the procedure to test it\n\nTo turn these steps into a look I use a \"CREATE OR REPLACE\" statement and be able to reload the updated procedure easier see [43.12. Tips for Developing in PL/pgSQL](https://www.postgresql.org/docs/14/plpgsql-development-tips.html).  Note in the revised example the \"-- \" lines are comments.\n\nOur revised [helloworld](helloworld.plpgsql).\n\n```sql\n    --\n    -- Create (or replace) the new \"helloworld\" procedure.\n    -- NOTE: this can be run with \"CALL\"\n    --\n    CREATE OR REPLACE PROCEDURE helloworld() AS $$\n    DECLARE\n    BEGIN\n        RAISE NOTICE 'Hello World!';\n    END;\n    $$ LANGUAGE plpgsql;\n```\n\n\nHi There\n--------\n\n[hithere](hithere.plpgsql) is similar to our helloworld example except it is a function that takes a parameter of the person's name. The function returns a \"VARCHAR\", so this should work as part of a select statement.\n\n```sql\n    --\n    -- This is a \"Hi There\" function. The function takes\n    -- a single parameter and forms a greeting.\n    --\n    CREATE OR REPLACE FUNCTION hithere(name varchar) RETURNS varchar AS $$\n    DECLARE\n      greeting varchar;\n    BEGIN\n        IF name = '' THEN\n            greeting := 'Hi there!';\n        ELSE\n            greeting := 'Hello ' || name || '!';\n        END IF;\n        RETURN greeting;\n    END;\n    $$ LANGUAGE plpgsql;\n```\n\nGiving it a try.\n\n```shell\n    SELECT hithere('Mojo Sam');\n```\n\nFurther reading\n---------------\n\n- [Conditionals](https://www.postgresql.org/docs/14/plpgsql-control-structures.html#PLPGSQL-CONDITIONALS)\n- [Loops](https://www.postgresql.org/docs/14/plpgsql-control-structures.html#PLPGSQL-CONTROL-STRUCTURES-LOOPS)\n- [Calling a procedure](https://www.postgresql.org/docs/14/plpgsql-control-structures.html#PLPGSQL-STATEMENTS-CALLING-PROCEDURE)\n- [Early return from a procedure](https://www.postgresql.org/docs/14/plpgsql-control-structures.html#PLPGSQL-STATEMENTS-RETURNING-PROCEDURE)\n\n",
      "data": {
        "author": "rsdoiel@gmail.com (R. S. Doiel)",
        "byline": "R. S. Doiel, 2022-08-24",
        "keywords": [
          "postgres",
          "sql",
          "psql",
          "plsql",
          "plpgsql"
        ],
        "number": 3,
        "pubDate": "2022-08-24",
        "series": "SQL Reflections",
        "title": "A Quick into to PL/pgSQL"
      },
      "url": "posts/2022/08/24/plpgsql-quick-intro.json"
    },
    {
      "content": "\n# Go and MySQL timestamps\n\nBy R. S. Doiel, 2022-12-12\n\nThe Go [sql](https://pkg.go.dev/database/sql) package provides a nice abstraction for working with SQL databases. The underlying drivers and DBMS can present some quirks that are SQL dialect and driver specific such as the [MySQL driver](github.com/go-sql-driver/mysql).  Sometimes that is not a big deal. [MySQL](https://dev.mysql.com) can maintain a creation timestamp as well as a modified timestamp easily via the SQL schema definition for the field. Unfortunately if you need to work with the MySQL timestamp at a Go level (e.g. display the timestamp in a useful way) the int64 provided via the driver isn't compatible with the `int64` used in Go's `time.Time`. To work around this limitation I've found it necessary to convert the MySQL timestamp to a formatted string using [DATE_FORMAT](https://dev.mysql.com/doc/refman/8.0/en/date-and-time-functions.html#function_date-format \"DATE_FORMAT is a MySQL date/time function returning a string value\") and from the Go side convert the formatted string into a `time.Time` using `time.Parse()`. Below is some Golang pseudo code showing this approach.\n\n```\n// Format used by MySQL strings representing date/times\nconst MySQLTimestamp = \"2006-01-02 15:04:05\"\n\n// GetRecordUpdate takes a configuration with a db attribute previously\n// opened and an id string returning a record populated with id and updated values where updated is an attribute of type time.Time. We use MySQL's\n// `DATE_FORMAT()` function to convert the timestamp into a string and\n// Go's `time.Parse()` to convert the string into a `time.Time` value.\nfunc GetRecordUpdate(cfg, id string) {\n\tstmt := `SELECT id, DATE_FORMAT(updated, \"%Y-%m-%d %H:%i:%s\") FROM some_tabl WHERE id = ?`\n\trow, err := cfg.db.Query(stmt, id)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tdefer row.Close()\n\trecord := new(Record)\n\tif row.Next() {\n\t\tvar updated string\n\t\tif err := row.Scan(&record.ID, &updated); err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\trecord.Updated, err = time.Parse(MySQLTimestamp, updated)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t}\n\terr = row.Err()\n\treturn record, err\n}\n```\n",
      "data": {
        "author": "rsdoiel@sdf.org (R. S. Doiel)",
        "keywords": [
          "golang",
          "sql",
          "timestamps"
        ],
        "pubDate": "2022-12-12",
        "title": "Go and MySQL timestamps"
      },
      "url": "posts/2022/12/12/Go-and-MySQL-Timestamps.json"
    },
    {
      "content": "\n# SQL query to CSV, a missing datatool\n\nBy R. S. Doiel, 2023-01-13\n\nUpdate: 2023-03-13\n\nAt work we maintain allot of metadata related academic and research publications in SQL databases. We use SQL to query the database and export what we need in tab delimited files. Often the exported data includes a column containing publication or article titles.  Titles in library metadata can be a bit messy. They contain a wide set of UTF-8 characters include math symbols and various types of quotation marks. The exported tab delimited data usually needs clean up before you can import it successfully into a spreadsheet.\n\nIn the worst cases we debug what the problem is then write a Python script to handle the tweak to fix things.  This results in allot of extra work and slows down the turn around for getting reports out quickly. This is particularly true of data stored in MySQL 8 (though we also use SQLite 3 and Postgres).\n\nThis got me thinking about how to get a clean export (tab or CSV) from our SQL databases today.  It would be nice if you provided a command line tool with a data source string (e.g. in a config file or the environment), a SQL query and the tool would use that to render a CSV or tab delimited file to standard out or a output file. It would work something like this.\n\n```\n    sql2csv -o eprint_status_report.csv -config=$HOME/.my.cnf \\\n\t    'SELECT eprintid, title, eprint_status FROM eprint' \n```\n\nThe `sql2csv` would take the results of the query and write to the CSV file.\n\nThe nice thing about this approach is that I could support the three relational databases we use -- i.e. MySQL 8, Postgres and SQLite3 with one common tool so my Bash scripts that run the reports would be very simple rather than specialized to one database system or the other.\n\nI hope to experiment with this approach in the next release of [datatools](https://github.com/caltechlibrary/datatools), an open source project maintained at work.\n\n## update\n\nJon Woodring pointed out to me today that both SQLite3 and PostgreSQL clients can output to CSV without need of an external tool. Wish MySQL client did that! Instead MySQL client supports tab delimited output. I'm still concidering sql2csv due to the ammount work I do with MySQL database but I'm not sure if it will make it into to the datatools project or now since I suspect our MySQL usage will decline overtime as more projects are built with PostgreSQL and SQLite3.\n",
      "data": {
        "author": "rsdoiel@sdf.org (R. S. Doiel)",
        "keywords": [
          "sql",
          "csv",
          "tab delimited"
        ],
        "pubDate": "2023-01-03",
        "title": "SQL query to CSV, a missing datatool",
        "updateDate": "2023-03-13"
      },
      "url": "posts/2023/01/03/sql-to-csv-a-missing-datatool.json"
    }
  ]
}